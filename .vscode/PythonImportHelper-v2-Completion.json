[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "textwrap",
        "description": "textwrap",
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "typing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "typing",
        "description": "typing",
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AbstractSet",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "overload",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AbstractSet",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AbstractSet",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "MutableMapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AbstractSet",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AbstractSet",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AsyncIterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AsyncIterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "overload",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "overload",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AsyncIterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "overload",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "flags",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "google",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google",
        "description": "google",
        "detail": "google",
        "documentation": {}
    },
    {
        "label": "generativeai",
        "importPath": "google",
        "description": "google",
        "isExtraImport": true,
        "detail": "google",
        "documentation": {}
    },
    {
        "label": "auth",
        "importPath": "google",
        "description": "google",
        "isExtraImport": true,
        "detail": "google",
        "documentation": {}
    },
    {
        "label": "generativelanguage",
        "importPath": "google.ai",
        "description": "google.ai",
        "isExtraImport": true,
        "detail": "google.ai",
        "documentation": {}
    },
    {
        "label": "grpc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "grpc",
        "description": "grpc",
        "detail": "grpc",
        "documentation": {}
    },
    {
        "label": "jinja2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jinja2",
        "description": "jinja2",
        "detail": "jinja2",
        "documentation": {}
    },
    {
        "label": "pydantic",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pydantic",
        "description": "pydantic",
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "IPython",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "IPython",
        "description": "IPython",
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "PIL.Image",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL.Image",
        "description": "PIL.Image",
        "detail": "PIL.Image",
        "documentation": {}
    },
    {
        "label": "generate_lib",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "public_api",
        "importPath": "tensorflow_docs.api_generator",
        "description": "tensorflow_docs.api_generator",
        "isExtraImport": true,
        "detail": "tensorflow_docs.api_generator",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "abc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "abc",
        "description": "abc",
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "dataclasses",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dataclasses",
        "description": "dataclasses",
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "llmfn_input_utils",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_post_process",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_post_process_cmds",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "prompt_utils",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_inputs_source",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_post_process",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llm_function",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_inputs_source",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llm_function",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_input_utils",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "unique_fn",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_inputs_source",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_input_utils",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_inputs_source",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "prompt_utils",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llm_function",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_inputs_source",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llm_function",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_post_process",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_inputs_source",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llm_function",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_inputs_source",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_post_process",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_post_process_cmds",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "prompt_utils",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "unique_fn",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llm_function",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llm_function",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_inputs_source",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_outputs",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llm_function",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "llmfn_output_row",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "model",
        "importPath": "google.generativeai.notebook.lib",
        "description": "google.generativeai.notebook.lib",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook.lib",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "argument_parser",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "flag_def",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "input_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "output_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "py_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "command",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "command_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "input_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "output_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "command",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "command_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "py_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "command",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "command_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "input_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "output_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "html_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_id",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_id",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "py_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "gspread_client",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env_impl",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "magics_engine",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "argument_parser",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "cmd_line_parser",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "command",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "compare_cmd",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "compile_cmd",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "eval_cmd",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "run_cmd",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "text_model",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "py_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "py_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "command",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "command_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "input_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "output_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_sanitize_url",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "gspread_client",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_id",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "argument_parser",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "argument_parser",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "cmd_line_parser",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "parsed_args_lib",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "argument_parser",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "flag_def",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "html_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_id",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "gspread_client",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "ipython_env",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "magics_engine",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_id",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "model_registry",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "post_process_utils_test_helper",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "py_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_id",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "sheets_sanitize_url",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "input_utils",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "text_model",
        "importPath": "google.generativeai.notebook",
        "description": "google.generativeai.notebook",
        "isExtraImport": true,
        "detail": "google.generativeai.notebook",
        "documentation": {}
    },
    {
        "label": "shlex",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shlex",
        "description": "shlex",
        "detail": "shlex",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "enum",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "enum",
        "description": "enum",
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "credentials",
        "importPath": "google.auth",
        "description": "google.auth",
        "isExtraImport": true,
        "detail": "google.auth",
        "documentation": {}
    },
    {
        "label": "credentials",
        "importPath": "google.auth",
        "description": "google.auth",
        "isExtraImport": true,
        "detail": "google.auth",
        "documentation": {}
    },
    {
        "label": "credentials",
        "importPath": "google.auth",
        "description": "google.auth",
        "isExtraImport": true,
        "detail": "google.auth",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "google.auth",
        "description": "google.auth",
        "isExtraImport": true,
        "detail": "google.auth",
        "documentation": {}
    },
    {
        "label": "ElementTree",
        "importPath": "xml.etree",
        "description": "xml.etree",
        "isExtraImport": true,
        "detail": "xml.etree",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.core",
        "description": "IPython.core",
        "isExtraImport": true,
        "detail": "IPython.core",
        "documentation": {}
    },
    {
        "label": "magic",
        "importPath": "IPython.core",
        "description": "IPython.core",
        "isExtraImport": true,
        "detail": "IPython.core",
        "documentation": {}
    },
    {
        "label": "google.generativeai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "caching",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "operations",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "answer",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "types",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "caching",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "discuss",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "discuss",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "embedding",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "embedding",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "generative_models",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "caching",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "generative_models",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "types",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "retriever",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "permission",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "retriever",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "permission",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "responder",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "retriever",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "retriever",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "string_utils",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "protos",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "text",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "isExtraImport": true,
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "builtins",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "builtins",
        "description": "builtins",
        "detail": "builtins",
        "documentation": {}
    },
    {
        "label": "keyword",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "keyword",
        "description": "keyword",
        "detail": "keyword",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "urllib",
        "description": "urllib",
        "isExtraImport": true,
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "urllib",
        "description": "urllib",
        "isExtraImport": true,
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "client_options",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "gapic_v1",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "operations_v1",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "operation",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "protobuf_helpers",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "operation",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "client_options",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "operation",
        "importPath": "google.api_core",
        "description": "google.api_core",
        "isExtraImport": true,
        "detail": "google.api_core",
        "documentation": {}
    },
    {
        "label": "generation_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "file_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "palm_safety_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "citation_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "content_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "permission_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "permission_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "palm_safety_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "citation_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "safety_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "content_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "retriever_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "caching_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "content_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "discuss_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "palm_safety_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "text_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "content_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "file_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "content_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "generation_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "safety_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "permission_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "retriever_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "retriever_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "text_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "palm_safety_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "generation_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "content_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "content_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "palm_safety_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "file_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "generation_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "content_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "generation_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "content_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "helper_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "permission_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "retriever_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "permission_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "retriever_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "retriever_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "retriever_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "safety_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "palm_safety_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "model_types",
        "importPath": "google.generativeai.types",
        "description": "google.generativeai.types",
        "isExtraImport": true,
        "detail": "google.generativeai.types",
        "documentation": {}
    },
    {
        "label": "typing_extensions",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "deprecated",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncIterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "mimetypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mimetypes",
        "description": "mimetypes",
        "detail": "mimetypes",
        "documentation": {}
    },
    {
        "label": "Status",
        "importPath": "google.rpc.status_pb2",
        "description": "google.rpc.status_pb2",
        "isExtraImport": true,
        "detail": "google.rpc.status_pb2",
        "documentation": {}
    },
    {
        "label": "get_default_file_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_permission_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_permission_async_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_retriever_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_retriever_async_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_generative_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_generative_async_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_cache_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_discuss_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_discuss_async_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_generative_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_generative_async_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_file_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_model_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_retriever_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_retriever_async_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_text_client",
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "isExtraImport": true,
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contextlib",
        "description": "contextlib",
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "redirect_stderr",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "islice",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "types",
        "description": "types",
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "google.protobuf.json_format",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.protobuf.json_format",
        "description": "google.protobuf.json_format",
        "detail": "google.protobuf.json_format",
        "documentation": {}
    },
    {
        "label": "google.api_core.exceptions",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.api_core.exceptions",
        "description": "google.api_core.exceptions",
        "detail": "google.api_core.exceptions",
        "documentation": {}
    },
    {
        "label": "_rename_schema_fields",
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "isExtraImport": true,
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "google.api_core.timeout",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.api_core.timeout",
        "description": "google.api_core.timeout",
        "detail": "google.api_core.timeout",
        "documentation": {}
    },
    {
        "label": "google.api_core.retry",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.api_core.retry",
        "description": "google.api_core.retry",
        "detail": "google.api_core.retry",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "urllib.request",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.request",
        "description": "urllib.request",
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "google.ai.generativelanguage",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.ai.generativelanguage",
        "description": "google.ai.generativelanguage",
        "detail": "google.ai.generativelanguage",
        "documentation": {}
    },
    {
        "label": "field_mask_pb2",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "field_mask_pb2",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "field_mask_pb2",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "field_mask_pb2",
        "importPath": "google.protobuf",
        "description": "google.protobuf",
        "isExtraImport": true,
        "detail": "google.protobuf",
        "documentation": {}
    },
    {
        "label": "flatten_update_paths",
        "importPath": "google.generativeai.utils",
        "description": "google.generativeai.utils",
        "isExtraImport": true,
        "detail": "google.generativeai.utils",
        "documentation": {}
    },
    {
        "label": "flatten_update_paths",
        "importPath": "google.generativeai.utils",
        "description": "google.generativeai.utils",
        "isExtraImport": true,
        "detail": "google.generativeai.utils",
        "documentation": {}
    },
    {
        "label": "flatten_update_paths",
        "importPath": "google.generativeai.utils",
        "description": "google.generativeai.utils",
        "isExtraImport": true,
        "detail": "google.generativeai.utils",
        "documentation": {}
    },
    {
        "label": "idecode_time",
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "isExtraImport": true,
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "idecode_time",
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "isExtraImport": true,
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "proto",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "proto",
        "description": "proto",
        "detail": "proto",
        "documentation": {}
    },
    {
        "label": "MetadataFilter",
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "isExtraImport": true,
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "httplib2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "httplib2",
        "description": "httplib2",
        "detail": "httplib2",
        "documentation": {}
    },
    {
        "label": "google.generativeai.protos",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.generativeai.protos",
        "description": "google.generativeai.protos",
        "detail": "google.generativeai.protos",
        "documentation": {}
    },
    {
        "label": "googleapiclient.http",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "googleapiclient.http",
        "description": "googleapiclient.http",
        "detail": "googleapiclient.http",
        "documentation": {}
    },
    {
        "label": "googleapiclient.discovery",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "googleapiclient.discovery",
        "description": "googleapiclient.discovery",
        "detail": "googleapiclient.discovery",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "reprlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "reprlib",
        "description": "reprlib",
        "detail": "reprlib",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "tqdm.auto",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tqdm.auto",
        "description": "tqdm.auto",
        "detail": "tqdm.auto",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "google.ai.generativelanguage_v1beta.types",
        "description": "google.ai.generativelanguage_v1beta.types",
        "isExtraImport": true,
        "detail": "google.ai.generativelanguage_v1beta.types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "importPath": "google.ai.generativelanguage_v1beta.types",
        "description": "google.ai.generativelanguage_v1beta.types",
        "isExtraImport": true,
        "detail": "google.ai.generativelanguage_v1beta.types",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "parameterized",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "absltest",
        "importPath": "absl.testing",
        "description": "absl.testing",
        "isExtraImport": true,
        "detail": "absl.testing",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "unittest.mock",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "IPython.display",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "IPython.display",
        "description": "IPython.display",
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "pytz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytz",
        "description": "pytz",
        "detail": "pytz",
        "documentation": {}
    },
    {
        "label": "google.protobuf.any_pb2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.protobuf.any_pb2",
        "description": "google.protobuf.any_pb2",
        "detail": "google.protobuf.any_pb2",
        "documentation": {}
    },
    {
        "label": "google.generativeai.operations",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.generativeai.operations",
        "description": "google.generativeai.operations",
        "detail": "google.generativeai.operations",
        "documentation": {}
    },
    {
        "label": "google.api_core.operation",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.api_core.operation",
        "description": "google.api_core.operation",
        "detail": "google.api_core.operation",
        "documentation": {}
    },
    {
        "label": "setuptools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "setuptools",
        "description": "setuptools",
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "gen_api_docs",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def gen_api_docs():\n    \"\"\"Generates api docs for the generative-ai package.\"\"\"\n    for name in dir(google):\n        if name not in (\"generativeai\", \"ai\"):\n            delattr(google, name)\n    google.__name__ = \"google\"\n    google.__doc__ = textwrap.dedent(\n        \"\"\"\\\n        This is the top-level google namespace.\n        \"\"\"",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "def main(_):\n    gen_api_docs()\nif __name__ == \"__main__\":\n    app.run(main)",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "typing.TYPE_CHECKING",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "typing.TYPE_CHECKING = True\nfrom google import generativeai as genai\nfrom tensorflow_docs.api_generator import generate_lib\nfrom tensorflow_docs.api_generator import public_api\nimport yaml\nHERE = pathlib.Path(__file__).parent\nPROJECT_SHORT_NAME = \"genai\"\nPROJECT_FULL_NAME = \"Generative AI - Python\"\n_OUTPUT_DIR = flags.DEFINE_string(\n    \"output_dir\",",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "HERE",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "HERE = pathlib.Path(__file__).parent\nPROJECT_SHORT_NAME = \"genai\"\nPROJECT_FULL_NAME = \"Generative AI - Python\"\n_OUTPUT_DIR = flags.DEFINE_string(\n    \"output_dir\",\n    default=str(HERE / \"api/\"),\n    help=\"Where to write the resulting docs to.\",\n)\n_SEARCH_HINTS = flags.DEFINE_bool(\n    \"search_hints\", True, \"Include metadata search hints in the generated files\"",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "PROJECT_SHORT_NAME",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "PROJECT_SHORT_NAME = \"genai\"\nPROJECT_FULL_NAME = \"Generative AI - Python\"\n_OUTPUT_DIR = flags.DEFINE_string(\n    \"output_dir\",\n    default=str(HERE / \"api/\"),\n    help=\"Where to write the resulting docs to.\",\n)\n_SEARCH_HINTS = flags.DEFINE_bool(\n    \"search_hints\", True, \"Include metadata search hints in the generated files\"\n)",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "PROJECT_FULL_NAME",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "PROJECT_FULL_NAME = \"Generative AI - Python\"\n_OUTPUT_DIR = flags.DEFINE_string(\n    \"output_dir\",\n    default=str(HERE / \"api/\"),\n    help=\"Where to write the resulting docs to.\",\n)\n_SEARCH_HINTS = flags.DEFINE_bool(\n    \"search_hints\", True, \"Include metadata search hints in the generated files\"\n)\n_SITE_PATH = flags.DEFINE_string(\"site_path\", \"/api/python\", \"Path prefix in the _toc.yaml\")",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "_OUTPUT_DIR",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "_OUTPUT_DIR = flags.DEFINE_string(\n    \"output_dir\",\n    default=str(HERE / \"api/\"),\n    help=\"Where to write the resulting docs to.\",\n)\n_SEARCH_HINTS = flags.DEFINE_bool(\n    \"search_hints\", True, \"Include metadata search hints in the generated files\"\n)\n_SITE_PATH = flags.DEFINE_string(\"site_path\", \"/api/python\", \"Path prefix in the _toc.yaml\")\n_CODE_URL_PREFIX = flags.DEFINE_string(",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "_SEARCH_HINTS",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "_SEARCH_HINTS = flags.DEFINE_bool(\n    \"search_hints\", True, \"Include metadata search hints in the generated files\"\n)\n_SITE_PATH = flags.DEFINE_string(\"site_path\", \"/api/python\", \"Path prefix in the _toc.yaml\")\n_CODE_URL_PREFIX = flags.DEFINE_string(\n    \"code_url_prefix\",\n    \"https://github.com/google/generative-ai-python/blob/master/google/generativeai\",\n    \"where to find the project code\",\n)\ndef gen_api_docs():",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "_SITE_PATH",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "_SITE_PATH = flags.DEFINE_string(\"site_path\", \"/api/python\", \"Path prefix in the _toc.yaml\")\n_CODE_URL_PREFIX = flags.DEFINE_string(\n    \"code_url_prefix\",\n    \"https://github.com/google/generative-ai-python/blob/master/google/generativeai\",\n    \"where to find the project code\",\n)\ndef gen_api_docs():\n    \"\"\"Generates api docs for the generative-ai package.\"\"\"\n    for name in dir(google):\n        if name not in (\"generativeai\", \"ai\"):",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "_CODE_URL_PREFIX",
        "kind": 5,
        "importPath": "docs.build_docs",
        "description": "docs.build_docs",
        "peekOfCode": "_CODE_URL_PREFIX = flags.DEFINE_string(\n    \"code_url_prefix\",\n    \"https://github.com/google/generative-ai-python/blob/master/google/generativeai\",\n    \"where to find the project code\",\n)\ndef gen_api_docs():\n    \"\"\"Generates api docs for the generative-ai package.\"\"\"\n    for name in dir(google):\n        if name not in (\"generativeai\", \"ai\"):\n            delattr(google, name)",
        "detail": "docs.build_docs",
        "documentation": {}
    },
    {
        "label": "_PromptInfo",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llm_function",
        "description": "google.generativeai.notebook.lib.llm_function",
        "peekOfCode": "class _PromptInfo:\n    prompt_num: int\n    prompt: str\n    input_num: int\n    prompt_vars: Mapping[str, str]\n    model_input: str\ndef _generate_prompts(\n    prompts: Sequence[str], inputs: llmfn_input_utils.LLMFunctionInputs | None\n) -> Iterable[_PromptInfo]:\n    \"\"\"Generate a tuple of fields needed for processing prompts.",
        "detail": "google.generativeai.notebook.lib.llm_function",
        "documentation": {}
    },
    {
        "label": "LLMFunction",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llm_function",
        "description": "google.generativeai.notebook.lib.llm_function",
        "peekOfCode": "class LLMFunction(\n    Callable[\n        [Union[llmfn_input_utils.LLMFunctionInputs, None]],\n        llmfn_outputs.LLMFnOutputs,\n    ],\n    metaclass=abc.ABCMeta,\n):\n    \"\"\"Base class for LLMFunctionImpl and LLMCompareFunction.\"\"\"\n    def __init__(\n        self,",
        "detail": "google.generativeai.notebook.lib.llm_function",
        "documentation": {}
    },
    {
        "label": "LLMFunctionImpl",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llm_function",
        "description": "google.generativeai.notebook.lib.llm_function",
        "peekOfCode": "class LLMFunctionImpl(LLMFunction):\n    \"\"\"Callable class that executes the contents of a Magics cell.\n    An LLMFunction is constructed from the Magics command line and cell contents\n    specified by the user. It is defined by:\n    - A model instance,\n    - Model arguments\n    - A prompt template (e.g. \"the opposite of hot is {word}\") with an optional\n      keyword placeholder.\n    The LLMFunction takes as its input a sequence of dictionaries containing\n    values for keyword replacement, e.g. [{\"word\": \"hot\"}, {\"word\": \"tall\"}].",
        "detail": "google.generativeai.notebook.lib.llm_function",
        "documentation": {}
    },
    {
        "label": "LLMCompareFunction",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llm_function",
        "description": "google.generativeai.notebook.lib.llm_function",
        "peekOfCode": "class LLMCompareFunction(LLMFunction):\n    \"\"\"LLMFunction for comparisons.\n    LLMCompareFunction runs an input over a pair of LLMFunctions and compares the\n    result.\n    \"\"\"\n    def __init__(\n        self,\n        lhs_name_and_fn: tuple[str, LLMFunction],\n        rhs_name_and_fn: tuple[str, LLMFunction],\n        compare_name_and_fns: Sequence[tuple[str, CompareFn]] | None = None,",
        "detail": "google.generativeai.notebook.lib.llm_function",
        "documentation": {}
    },
    {
        "label": "CompareFn",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llm_function",
        "description": "google.generativeai.notebook.lib.llm_function",
        "peekOfCode": "CompareFn = Callable[\n    [llmfn_output_row.LLMFnOutputRowView, llmfn_output_row.LLMFnOutputRowView],\n    Any,\n]\ndef _is_equal_fn(\n    lhs: llmfn_output_row.LLMFnOutputRowView,\n    rhs: llmfn_output_row.LLMFnOutputRowView,\n) -> bool:\n    \"\"\"Default function used when comparing outputs.\"\"\"\n    return lhs.result_value() == rhs.result_value()",
        "detail": "google.generativeai.notebook.lib.llm_function",
        "documentation": {}
    },
    {
        "label": "to_normalized_inputs",
        "kind": 2,
        "importPath": "google.generativeai.notebook.lib.llmfn_input_utils",
        "description": "google.generativeai.notebook.lib.llmfn_input_utils",
        "peekOfCode": "def to_normalized_inputs(inputs: LLMFunctionInputs) -> _NormalizedInputsList:\n    \"\"\"Handles the different types of `inputs` and returns a normalized form.\"\"\"\n    normalized_inputs: list[Mapping[str, str]] = []\n    if isinstance(inputs, llmfn_inputs_source.LLMFnInputsSource):\n        normalized_inputs.extend(inputs.to_normalized_inputs())\n    elif _is_column_order_values_list(inputs):\n        normalized_inputs.extend(_normalize_column_order_values_list(inputs))\n    else:\n        raise ValueError(\"Unsupported input type {!r}\".format(inputs))\n    return normalized_inputs",
        "detail": "google.generativeai.notebook.lib.llmfn_input_utils",
        "documentation": {}
    },
    {
        "label": "_NormalizedInputsList",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llmfn_input_utils",
        "description": "google.generativeai.notebook.lib.llmfn_input_utils",
        "peekOfCode": "_NormalizedInputsList = llmfn_inputs_source.NormalizedInputsList\n_ColumnOrderValuesList = Mapping[str, Sequence[str]]\nLLMFunctionInputs = Union[_ColumnOrderValuesList, llmfn_inputs_source.LLMFnInputsSource]\ndef _is_column_order_values_list(inputs: Any) -> bool:\n    \"\"\"See if inputs is of the form: {\"key1\": [\"val1\", \"val2\", ...]}.\n    This is similar to the format produced by:\n      pandas.DataFrame.to_dict(orient=\"list\")\n    Args:\n      inputs: The inputs passed into an LLMFunction.\n    Returns:",
        "detail": "google.generativeai.notebook.lib.llmfn_input_utils",
        "documentation": {}
    },
    {
        "label": "_ColumnOrderValuesList",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llmfn_input_utils",
        "description": "google.generativeai.notebook.lib.llmfn_input_utils",
        "peekOfCode": "_ColumnOrderValuesList = Mapping[str, Sequence[str]]\nLLMFunctionInputs = Union[_ColumnOrderValuesList, llmfn_inputs_source.LLMFnInputsSource]\ndef _is_column_order_values_list(inputs: Any) -> bool:\n    \"\"\"See if inputs is of the form: {\"key1\": [\"val1\", \"val2\", ...]}.\n    This is similar to the format produced by:\n      pandas.DataFrame.to_dict(orient=\"list\")\n    Args:\n      inputs: The inputs passed into an LLMFunction.\n    Returns:\n      Whether `inputs` is a column-ordered list of values.",
        "detail": "google.generativeai.notebook.lib.llmfn_input_utils",
        "documentation": {}
    },
    {
        "label": "LLMFunctionInputs",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llmfn_input_utils",
        "description": "google.generativeai.notebook.lib.llmfn_input_utils",
        "peekOfCode": "LLMFunctionInputs = Union[_ColumnOrderValuesList, llmfn_inputs_source.LLMFnInputsSource]\ndef _is_column_order_values_list(inputs: Any) -> bool:\n    \"\"\"See if inputs is of the form: {\"key1\": [\"val1\", \"val2\", ...]}.\n    This is similar to the format produced by:\n      pandas.DataFrame.to_dict(orient=\"list\")\n    Args:\n      inputs: The inputs passed into an LLMFunction.\n    Returns:\n      Whether `inputs` is a column-ordered list of values.\n    \"\"\"",
        "detail": "google.generativeai.notebook.lib.llmfn_input_utils",
        "documentation": {}
    },
    {
        "label": "LLMFnInputsSource",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_inputs_source",
        "description": "google.generativeai.notebook.lib.llmfn_inputs_source",
        "peekOfCode": "class LLMFnInputsSource(abc.ABC):\n    \"\"\"Abstract class representing a source of inputs for LLMFunction.\n    This class could be extended with concrete implementations that read data\n    from external sources, such as Google Sheets.\n    \"\"\"\n    def __init__(self):\n        self._cached_inputs: NormalizedInputsList | None = None\n        self._display_status_fn: Callable[[], None] = lambda: None\n    def to_normalized_inputs(self, suppress_status_msgs: bool = False) -> NormalizedInputsList:\n        \"\"\"Returns a sequence of normalized inputs.",
        "detail": "google.generativeai.notebook.lib.llmfn_inputs_source",
        "documentation": {}
    },
    {
        "label": "NormalizedInputsList",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llmfn_inputs_source",
        "description": "google.generativeai.notebook.lib.llmfn_inputs_source",
        "peekOfCode": "NormalizedInputsList = Sequence[Mapping[str, str]]\nclass LLMFnInputsSource(abc.ABC):\n    \"\"\"Abstract class representing a source of inputs for LLMFunction.\n    This class could be extended with concrete implementations that read data\n    from external sources, such as Google Sheets.\n    \"\"\"\n    def __init__(self):\n        self._cached_inputs: NormalizedInputsList | None = None\n        self._display_status_fn: Callable[[], None] = lambda: None\n    def to_normalized_inputs(self, suppress_status_msgs: bool = False) -> NormalizedInputsList:",
        "detail": "google.generativeai.notebook.lib.llmfn_inputs_source",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRowView",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_output_row",
        "description": "google.generativeai.notebook.lib.llmfn_output_row",
        "peekOfCode": "class LLMFnOutputRowView(Mapping[str, _CELLVALUETYPE], metaclass=abc.ABCMeta):\n    \"\"\"Immutable view of LLMFnOutputRow.\"\"\"\n    # Additional methods (not required by Mapping[str, _CELLVALUETYPE])\n    @abc.abstractmethod\n    def __contains__(self, k: str) -> bool:\n        \"\"\"For expressions like: x in this_instance.\"\"\"\n    @abc.abstractmethod\n    def __str__(self) -> str:\n        \"\"\"For expressions like: str(this_instance).\"\"\"\n    # Own methods.",
        "detail": "google.generativeai.notebook.lib.llmfn_output_row",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRow",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_output_row",
        "description": "google.generativeai.notebook.lib.llmfn_output_row",
        "peekOfCode": "class LLMFnOutputRow(LLMFnOutputRowView):\n    \"\"\"Container that represents a single row in a table of outputs.\n    We represent outputs as a table. This class represents a single row in the\n    table like a dictionary, where the key is the column name and the value is the\n    cell value.\n    A single cell is designated the \"result\". This contains the output of the LLM\n    model after running any post-processing functions specified by the user.\n    In addition to behaving like a dictionary, this class provides additional\n    methods, including:\n    - Getting the value of the \"result\" cell",
        "detail": "google.generativeai.notebook.lib.llmfn_output_row",
        "documentation": {}
    },
    {
        "label": "_CELLVALUETYPE",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llmfn_output_row",
        "description": "google.generativeai.notebook.lib.llmfn_output_row",
        "peekOfCode": "_CELLVALUETYPE = Any\ndef _get_name_of_type(x: type[Any]) -> str:\n    if hasattr(x, \"__name__\"):\n        return x.__name__\n    return str(x)\ndef _validate_is_result_type(value: Any, result_type: type[Any]) -> None:\n    if result_type == Any:\n        return\n    if not isinstance(value, result_type):\n        raise ValueError(",
        "detail": "google.generativeai.notebook.lib.llmfn_output_row",
        "documentation": {}
    },
    {
        "label": "ColumnNames",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_outputs",
        "description": "google.generativeai.notebook.lib.llmfn_outputs",
        "peekOfCode": "class ColumnNames:\n    \"\"\"Names of columns that are used to represent output.\"\"\"\n    PROMPT_NUM = \"Prompt Num\"\n    INPUT_NUM = \"Input Num\"\n    RESULT_NUM = \"Result Num\"\n    # In the code we refer to \"model_input\" as the full keyword-substituted prompt\n    # and \"prompt\" as the template with placeholders.\n    # When displaying the results however we use \"prompt\" since \"model_input\" is\n    # an internal name.\n    MODEL_INPUT = \"Prompt\"",
        "detail": "google.generativeai.notebook.lib.llmfn_outputs",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputEntry",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_outputs",
        "description": "google.generativeai.notebook.lib.llmfn_outputs",
        "peekOfCode": "class LLMFnOutputEntry:\n    \"\"\"The output of a single model input from LLMFunction.\n    A model input is a prompt where the keyword placeholders have been\n    substituted (by `prompt_vars`).\n    E.g. If we have:\n      prompt: \"the opposite of {word} is\"\n      prompt_vars: {\"word\", \"hot\"}\n    Then we will have the following model input:\n      model_input: \"the opposite of hot is\"\n    Note: The model may produce one-or-more results for a given model_input.",
        "detail": "google.generativeai.notebook.lib.llmfn_outputs",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputsBase",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_outputs",
        "description": "google.generativeai.notebook.lib.llmfn_outputs",
        "peekOfCode": "class LLMFnOutputsBase(Sequence[LLMFnOutputEntry]):\n    \"\"\"Parent class for LLMFnOutputs.\n    This class exists mainly to avoid a circular dependency between LLMFnOutputs\n    and LLMFnOutputsSink. Most users should use LLMFnOutputs directly instead.\n    \"\"\"\n    def __init__(\n        self,\n        outputs: Iterable[LLMFnOutputEntry] | None = None,\n    ):\n        \"\"\"Constructor.",
        "detail": "google.generativeai.notebook.lib.llmfn_outputs",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputsSink",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_outputs",
        "description": "google.generativeai.notebook.lib.llmfn_outputs",
        "peekOfCode": "class LLMFnOutputsSink(abc.ABC):\n    \"\"\"Abstract class representing an exporter for the output of LLMFunction.\n    This class could be extended to write to external documents, such as\n    Google Sheets.\n    \"\"\"\n    def write_outputs(self, outputs: LLMFnOutputsBase) -> None:\n        \"\"\"Writes `outputs` to some destination.\"\"\"\nclass LLMFnOutputs(LLMFnOutputsBase):\n    \"\"\"A sequence of LLMFnOutputEntry instances.\n    Notes:",
        "detail": "google.generativeai.notebook.lib.llmfn_outputs",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputs",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_outputs",
        "description": "google.generativeai.notebook.lib.llmfn_outputs",
        "peekOfCode": "class LLMFnOutputs(LLMFnOutputsBase):\n    \"\"\"A sequence of LLMFnOutputEntry instances.\n    Notes:\n    - Each LLMFnOutputEntry represents the results of running one model\n      input (see documentation for LLMFnOutputEntry for what \"model input\"\n      means.)\n    - A single model input may produce more-than-one text results.\n    \"\"\"\n    def __init__(\n        self,",
        "detail": "google.generativeai.notebook.lib.llmfn_outputs",
        "documentation": {}
    },
    {
        "label": "PostProcessExecutionError",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process",
        "description": "google.generativeai.notebook.lib.llmfn_post_process",
        "peekOfCode": "class PostProcessExecutionError(RuntimeError):\n    \"\"\"An error while executing a post-processing command.\"\"\"\n# A batch-process function takes a batch of rows, and returns a sequence of\n# indices representing which rows to keep.\n# This can be used to implement operations such as filtering and sorting.\n#\n# Requires:\n# - Indices must be in the range [0, len(input rows)).\nLLMFnPostProcessBatchReorderFn = Callable[\n    [Sequence[llmfn_output_row.LLMFnOutputRowView]],",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessBatchReorderFn",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process",
        "description": "google.generativeai.notebook.lib.llmfn_post_process",
        "peekOfCode": "LLMFnPostProcessBatchReorderFn = Callable[\n    [Sequence[llmfn_output_row.LLMFnOutputRowView]],\n    Sequence[int],\n]\n# An add function takes a batch of rows and returns a sequence of values to\n# be added as new columns.\n#\n# Requires:\n# - Output sequence must be exactly the same length as number of rows.\nLLMFnPostProcessBatchAddFn = Callable[",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessBatchAddFn",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process",
        "description": "google.generativeai.notebook.lib.llmfn_post_process",
        "peekOfCode": "LLMFnPostProcessBatchAddFn = Callable[\n    [Sequence[llmfn_output_row.LLMFnOutputRowView]], Sequence[Any]\n]\n# A replace function takes a batch of rows and returns a sequence of values\n# to replace the existing results.\n#\n# Requires:\n# - Output sequence must be exactly the same length as number of rows.\n# - Return type must match the result_type of LLMFnOutputRow.\nLLMFnPostProcessBatchReplaceFn = Callable[",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessBatchReplaceFn",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process",
        "description": "google.generativeai.notebook.lib.llmfn_post_process",
        "peekOfCode": "LLMFnPostProcessBatchReplaceFn = Callable[\n    [Sequence[llmfn_output_row.LLMFnOutputRowView]], Sequence[Any]\n]\n# An add function takes a batch of pairs of rows and returns a sequence of\n# values to be added as new columns.\n#\n# This is used for LLMCompareFunction.\n#\n# Requires:\n# - Output sequence must be exactly the same length as number of rows.",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process",
        "documentation": {}
    },
    {
        "label": "LLMCompareFnPostProcessBatchAddFn",
        "kind": 5,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process",
        "description": "google.generativeai.notebook.lib.llmfn_post_process",
        "peekOfCode": "LLMCompareFnPostProcessBatchAddFn = Callable[\n    [\n        Sequence[\n            Tuple[\n                llmfn_output_row.LLMFnOutputRowView,\n                llmfn_output_row.LLMFnOutputRowView,\n            ]\n        ]\n    ],\n    Sequence[Any],",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "description": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "peekOfCode": "class LLMFnPostProcessCommand(abc.ABC):\n    \"\"\"Abstract class representing post-processing commands.\"\"\"\n    @abc.abstractmethod\n    def name(self) -> str:\n        \"\"\"Returns the name of this post-processing command.\"\"\"\nclass LLMFnImplPostProcessCommand(LLMFnPostProcessCommand):\n    \"\"\"Post-processing commands for LLMFunctionImpl.\"\"\"\n    @abc.abstractmethod\n    def run(\n        self, rows: Sequence[llmfn_output_row.LLMFnOutputRowView]",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMFnImplPostProcessCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "description": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "peekOfCode": "class LLMFnImplPostProcessCommand(LLMFnPostProcessCommand):\n    \"\"\"Post-processing commands for LLMFunctionImpl.\"\"\"\n    @abc.abstractmethod\n    def run(\n        self, rows: Sequence[llmfn_output_row.LLMFnOutputRowView]\n    ) -> Sequence[llmfn_output_row.LLMFnOutputRow]:\n        \"\"\"Processes a batch of results and returns a new batch.\n        Args:\n          rows: The rows in a batch. Note that `rows` are not guaranteed to be\n            remain unmodified.",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessReorderCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "description": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "peekOfCode": "class LLMFnPostProcessReorderCommand(LLMFnImplPostProcessCommand):\n    \"\"\"A batch command processes a set of results at once.\n    Note that a \"batch\" represents a set of results coming from a single prompt,\n    as the model may produce more-than-one result for a prompt.\n    \"\"\"\n    def __init__(self, name: str, fn: llmfn_post_process.LLMFnPostProcessBatchReorderFn):\n        self._name = name\n        self._fn = fn\n    def name(self) -> str:\n        return self._name",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessAddCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "description": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "peekOfCode": "class LLMFnPostProcessAddCommand(LLMFnImplPostProcessCommand):\n    \"\"\"A command that adds each row with a new column.\n    This does not change the value of the results cell.\n    \"\"\"\n    def __init__(self, name: str, fn: llmfn_post_process.LLMFnPostProcessBatchAddFn):\n        self._name = name\n        self._fn = fn\n    def name(self) -> str:\n        return self._name\n    def run(",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessReplaceCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "description": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "peekOfCode": "class LLMFnPostProcessReplaceCommand(LLMFnImplPostProcessCommand):\n    \"\"\"A command that modifies the results in each row.\"\"\"\n    def __init__(self, name: str, fn: llmfn_post_process.LLMFnPostProcessBatchReplaceFn):\n        self._name = name\n        self._fn = fn\n    def name(self) -> str:\n        return self._name\n    def run(\n        self,\n        rows: Sequence[llmfn_output_row.LLMFnOutputRowView],",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMCompareFnPostProcessCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "description": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "peekOfCode": "class LLMCompareFnPostProcessCommand(LLMFnPostProcessCommand):\n    \"\"\"Post-processing commands for LLMCompareFunction.\"\"\"\n    @abc.abstractmethod\n    def run(\n        self,\n        rows: Sequence[\n            tuple[\n                llmfn_output_row.LLMFnOutputRowView,\n                llmfn_output_row.LLMFnOutputRowView,\n                llmfn_output_row.LLMFnOutputRowView,",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMCompareFnPostProcessAddCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "description": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "peekOfCode": "class LLMCompareFnPostProcessAddCommand(LLMCompareFnPostProcessCommand):\n    \"\"\"A command that adds each row with a new column.\n    This does not change the value of the results cell.\n    \"\"\"\n    def __init__(\n        self,\n        name: str,\n        fn: llmfn_post_process.LLMCompareFnPostProcessBatchAddFn,\n    ):\n        self._name = name",
        "detail": "google.generativeai.notebook.lib.llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "ModelArguments",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.model",
        "description": "google.generativeai.notebook.lib.model",
        "peekOfCode": "class ModelArguments:\n    \"\"\"Common arguments for models.\n    Attributes:\n      model: The model string to use. If None a default model will be selected.\n      temperature: The temperature. Must be greater-than-or-equal-to zero.\n      candidate_count: Number of candidates to return.\n    \"\"\"\n    model: str | None = None\n    temperature: float | None = None\n    candidate_count: int | None = None",
        "detail": "google.generativeai.notebook.lib.model",
        "documentation": {}
    },
    {
        "label": "ModelResults",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.model",
        "description": "google.generativeai.notebook.lib.model",
        "peekOfCode": "class ModelResults:\n    \"\"\"Results from calling AbstractModel.call_model().\"\"\"\n    model_input: str\n    text_results: Sequence[str]\nclass AbstractModel(abc.ABC):\n    @abc.abstractmethod\n    def call_model(\n        self, model_input: str, model_args: ModelArguments | None = None\n    ) -> ModelResults:\n        \"\"\"Executes the model.\"\"\"",
        "detail": "google.generativeai.notebook.lib.model",
        "documentation": {}
    },
    {
        "label": "AbstractModel",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.model",
        "description": "google.generativeai.notebook.lib.model",
        "peekOfCode": "class AbstractModel(abc.ABC):\n    @abc.abstractmethod\n    def call_model(\n        self, model_input: str, model_args: ModelArguments | None = None\n    ) -> ModelResults:\n        \"\"\"Executes the model.\"\"\"\nclass EchoModel(AbstractModel):\n    \"\"\"Model that returns the original input.\n    This is primarily used for testing.\n    \"\"\"",
        "detail": "google.generativeai.notebook.lib.model",
        "documentation": {}
    },
    {
        "label": "EchoModel",
        "kind": 6,
        "importPath": "google.generativeai.notebook.lib.model",
        "description": "google.generativeai.notebook.lib.model",
        "peekOfCode": "class EchoModel(AbstractModel):\n    \"\"\"Model that returns the original input.\n    This is primarily used for testing.\n    \"\"\"\n    def call_model(\n        self, model_input: str, model_args: ModelArguments | None = None\n    ) -> ModelResults:\n        candidate_count = model_args.candidate_count if model_args else None\n        if candidate_count is None:\n            candidate_count = 1",
        "detail": "google.generativeai.notebook.lib.model",
        "documentation": {}
    },
    {
        "label": "get_placeholders",
        "kind": 2,
        "importPath": "google.generativeai.notebook.lib.prompt_utils",
        "description": "google.generativeai.notebook.lib.prompt_utils",
        "peekOfCode": "def get_placeholders(prompt: str) -> AbstractSet[str]:\n    \"\"\"Returns the placeholders for `prompt`.\n    E.g. Given \"A for {word_one} B for {word_two}\", returns {\"word_one\",\n    \"word_two\"}.\n    Args:\n      prompt: A prompt template with optional placeholders.\n    Returns:\n      A sequence of placeholders in `prompt`.\n    \"\"\"\n    placeholders: list[str] = []",
        "detail": "google.generativeai.notebook.lib.prompt_utils",
        "documentation": {}
    },
    {
        "label": "unique_fn",
        "kind": 2,
        "importPath": "google.generativeai.notebook.lib.unique_fn",
        "description": "google.generativeai.notebook.lib.unique_fn",
        "peekOfCode": "def unique_fn(\n    rows: Sequence[llmfn_output_row.LLMFnOutputRowView],\n) -> Sequence[int]:\n    \"\"\"Returns a list of indices with duplicates removed.\n    E.g. if rows has results [\"hello\", \"hello\", \"world\"], the return value would\n    be [0, 2], indicating that the results at index 1 is a duplicate and should be\n    removed.\n    Args:\n      rows: The input rows\n    Returns:",
        "detail": "google.generativeai.notebook.lib.unique_fn",
        "documentation": {}
    },
    {
        "label": "_ParserBaseException",
        "kind": 6,
        "importPath": "google.generativeai.notebook.argument_parser",
        "description": "google.generativeai.notebook.argument_parser",
        "peekOfCode": "class _ParserBaseException(RuntimeError, metaclass=abc.ABCMeta):\n    \"\"\"Base class for parser exceptions including normal exit.\"\"\"\n    def __init__(self, msgs: Sequence[str], *args, **kwargs):\n        super().__init__(\"\".join(msgs), *args, **kwargs)\n        self._msgs = msgs\n        self._ipython_env: ipython_env.IPythonEnv | None = None\n    def set_ipython_env(self, env: ipython_env.IPythonEnv) -> None:\n        self._ipython_env = env\n    def _ipython_display_(self):\n        self.display(self._ipython_env)",
        "detail": "google.generativeai.notebook.argument_parser",
        "documentation": {}
    },
    {
        "label": "ParserNormalExit",
        "kind": 6,
        "importPath": "google.generativeai.notebook.argument_parser",
        "description": "google.generativeai.notebook.argument_parser",
        "peekOfCode": "class ParserNormalExit(_ParserBaseException):\n    \"\"\"Exception thrown when the parser exits normally.\n    This is usually thrown when the user requests the help message.\n    \"\"\"\n    def display(self, env: ipython_env.IPythonEnv | None) -> None:\n        for msg in self._msgs:\n            print(msg)\nclass ParserError(_ParserBaseException):\n    \"\"\"Exception thrown when there is an error.\"\"\"\n    def display(self, env: ipython_env.IPythonEnv | None) -> None:",
        "detail": "google.generativeai.notebook.argument_parser",
        "documentation": {}
    },
    {
        "label": "ParserError",
        "kind": 6,
        "importPath": "google.generativeai.notebook.argument_parser",
        "description": "google.generativeai.notebook.argument_parser",
        "peekOfCode": "class ParserError(_ParserBaseException):\n    \"\"\"Exception thrown when there is an error.\"\"\"\n    def display(self, env: ipython_env.IPythonEnv | None) -> None:\n        for msg in self._msgs:\n            print(msg)\n        if env is not None:\n            # Highlight to the user that an error has occurred.\n            env.display_html(\"<b style='font-family:courier new'>ERROR</b>\")\nclass ArgumentParser(argparse.ArgumentParser):\n    \"\"\"Customized ArgumentParser for LLM Magics.",
        "detail": "google.generativeai.notebook.argument_parser",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "kind": 6,
        "importPath": "google.generativeai.notebook.argument_parser",
        "description": "google.generativeai.notebook.argument_parser",
        "peekOfCode": "class ArgumentParser(argparse.ArgumentParser):\n    \"\"\"Customized ArgumentParser for LLM Magics.\n    This class overrides the parent argparse.ArgumentParser's error-handling\n    methods to avoid side-effects like printing to stderr. The messages are\n    accumulated and passed into the raised exceptions for the caller to\n    handle them.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._messages: list[str] = []",
        "detail": "google.generativeai.notebook.argument_parser",
        "documentation": {}
    },
    {
        "label": "CmdLineParser",
        "kind": 6,
        "importPath": "google.generativeai.notebook.cmd_line_parser",
        "description": "google.generativeai.notebook.cmd_line_parser",
        "peekOfCode": "class CmdLineParser:\n    \"\"\"Implementation of Magics command line parser.\"\"\"\n    # Commands\n    DEFAULT_CMD = parsed_args_lib.CommandName.RUN_CMD\n    # Post-processing operator.\n    PIPE_OP = \"|\"\n    @classmethod\n    def _split_post_processing_tokens(\n        cls,\n        tokens: Sequence[str],",
        "detail": "google.generativeai.notebook.cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "_MIN_CANDIDATE_COUNT",
        "kind": 5,
        "importPath": "google.generativeai.notebook.cmd_line_parser",
        "description": "google.generativeai.notebook.cmd_line_parser",
        "peekOfCode": "_MIN_CANDIDATE_COUNT = 1\n_MAX_CANDIDATE_COUNT = 8\ndef _validate_input_source_against_placeholders(\n    source: llmfn_inputs_source.LLMFnInputsSource,\n    placeholders: AbstractSet[str],\n) -> None:\n    for inputs in source.to_normalized_inputs():\n        for keyword in placeholders:\n            if keyword not in inputs:\n                raise ValueError('Placeholder \"{}\" not found in input'.format(keyword))",
        "detail": "google.generativeai.notebook.cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "_MAX_CANDIDATE_COUNT",
        "kind": 5,
        "importPath": "google.generativeai.notebook.cmd_line_parser",
        "description": "google.generativeai.notebook.cmd_line_parser",
        "peekOfCode": "_MAX_CANDIDATE_COUNT = 8\ndef _validate_input_source_against_placeholders(\n    source: llmfn_inputs_source.LLMFnInputsSource,\n    placeholders: AbstractSet[str],\n) -> None:\n    for inputs in source.to_normalized_inputs():\n        for keyword in placeholders:\n            if keyword not in inputs:\n                raise ValueError('Placeholder \"{}\" not found in input'.format(keyword))\ndef _get_resolve_input_from_py_var_fn(",
        "detail": "google.generativeai.notebook.cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "Command",
        "kind": 6,
        "importPath": "google.generativeai.notebook.command",
        "description": "google.generativeai.notebook.command",
        "peekOfCode": "class Command(abc.ABC):\n    \"\"\"Base class for implementation of Magics commands like \"run\".\"\"\"\n    @abc.abstractmethod\n    def execute(\n        self,\n        parsed_args: parsed_args_lib.ParsedArgs,\n        cell_content: str,\n        post_processing_fns: Sequence[post_process_utils.ParsedPostProcessExpr],\n    ):\n        \"\"\"Executes the command given `parsed_args` and the `cell_content`.\"\"\"",
        "detail": "google.generativeai.notebook.command",
        "documentation": {}
    },
    {
        "label": "ProcessingCommand",
        "kind": 5,
        "importPath": "google.generativeai.notebook.command",
        "description": "google.generativeai.notebook.command",
        "peekOfCode": "ProcessingCommand = collections.namedtuple(\"ProcessingCommand\", [\"name\", \"fn\"])\nclass Command(abc.ABC):\n    \"\"\"Base class for implementation of Magics commands like \"run\".\"\"\"\n    @abc.abstractmethod\n    def execute(\n        self,\n        parsed_args: parsed_args_lib.ParsedArgs,\n        cell_content: str,\n        post_processing_fns: Sequence[post_process_utils.ParsedPostProcessExpr],\n    ):",
        "detail": "google.generativeai.notebook.command",
        "documentation": {}
    },
    {
        "label": "_GroundTruthLLMFunction",
        "kind": 6,
        "importPath": "google.generativeai.notebook.command_utils",
        "description": "google.generativeai.notebook.command_utils",
        "peekOfCode": "class _GroundTruthLLMFunction(llm_function.LLMFunction):\n    \"\"\"LLMFunction that returns pre-generated ground truth data.\"\"\"\n    def __init__(self, data: Sequence[str]):\n        super().__init__(outputs_ipython_display_fn=None)\n        self._data = data\n    def get_placeholders(self) -> AbstractSet[str]:\n        # Ground truth is fixed and thus has no placeholders.\n        return frozenset({})\n    def _call_impl(\n        self, inputs: llmfn_input_utils.LLMFunctionInputs | None",
        "detail": "google.generativeai.notebook.command_utils",
        "documentation": {}
    },
    {
        "label": "create_llm_function",
        "kind": 2,
        "importPath": "google.generativeai.notebook.command_utils",
        "description": "google.generativeai.notebook.command_utils",
        "peekOfCode": "def create_llm_function(\n    models: model_registry.ModelRegistry,\n    env: ipython_env.IPythonEnv | None,\n    parsed_args: parsed_args_lib.ParsedArgs,\n    cell_content: str,\n    post_processing_fns: Sequence[post_process_utils.ParsedPostProcessExpr],\n) -> llm_function.LLMFunction:\n    \"\"\"Creates an LLMFunction from Command.execute() arguments.\"\"\"\n    prompts: list[str] = [cell_content]\n    llmfn_outputs_display_fn = _get_ipython_display_fn(env) if env else None",
        "detail": "google.generativeai.notebook.command_utils",
        "documentation": {}
    },
    {
        "label": "create_llm_compare_function",
        "kind": 2,
        "importPath": "google.generativeai.notebook.command_utils",
        "description": "google.generativeai.notebook.command_utils",
        "peekOfCode": "def create_llm_compare_function(\n    env: ipython_env.IPythonEnv | None,\n    parsed_args: parsed_args_lib.ParsedArgs,\n    post_processing_fns: Sequence[post_process_utils.ParsedPostProcessExpr],\n) -> llm_function.LLMFunction:\n    \"\"\"Creates an LLMCompareFunction from Command.execute() arguments.\"\"\"\n    llmfn_outputs_display_fn = _get_ipython_display_fn(env) if env else None\n    llm_cmp_fn = llm_function.LLMCompareFunction(\n        lhs_name_and_fn=parsed_args.lhs_name_and_fn,\n        rhs_name_and_fn=parsed_args.rhs_name_and_fn,",
        "detail": "google.generativeai.notebook.command_utils",
        "documentation": {}
    },
    {
        "label": "create_llm_eval_function",
        "kind": 2,
        "importPath": "google.generativeai.notebook.command_utils",
        "description": "google.generativeai.notebook.command_utils",
        "peekOfCode": "def create_llm_eval_function(\n    models: model_registry.ModelRegistry,\n    env: ipython_env.IPythonEnv | None,\n    parsed_args: parsed_args_lib.ParsedArgs,\n    cell_content: str,\n    post_processing_fns: Sequence[post_process_utils.ParsedPostProcessExpr],\n) -> llm_function.LLMFunction:\n    \"\"\"Creates an LLMCompareFunction from Command.execute() arguments.\"\"\"\n    llmfn_outputs_display_fn = _get_ipython_display_fn(env) if env else None\n    # First construct a regular LLMFunction from the cell contents.",
        "detail": "google.generativeai.notebook.command_utils",
        "documentation": {}
    },
    {
        "label": "CompareCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.compare_cmd",
        "description": "google.generativeai.notebook.compare_cmd",
        "peekOfCode": "class CompareCommand(command.Command):\n    \"\"\"Implementation of \"compare\" command.\"\"\"\n    def __init__(\n        self,\n        env: ipython_env.IPythonEnv | None = None,\n    ):\n        \"\"\"Constructor.\n        Args:\n          env: The IPythonEnv environment.\n        \"\"\"",
        "detail": "google.generativeai.notebook.compare_cmd",
        "documentation": {}
    },
    {
        "label": "CompileCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.compile_cmd",
        "description": "google.generativeai.notebook.compile_cmd",
        "peekOfCode": "class CompileCommand(command.Command):\n    \"\"\"Implementation of the \"compile\" command.\"\"\"\n    def __init__(\n        self,\n        models: model_registry.ModelRegistry,\n        env: ipython_env.IPythonEnv | None = None,\n    ):\n        \"\"\"Constructor.\n        Args:\n          models: ModelRegistry instance.",
        "detail": "google.generativeai.notebook.compile_cmd",
        "documentation": {}
    },
    {
        "label": "EvalCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.eval_cmd",
        "description": "google.generativeai.notebook.eval_cmd",
        "peekOfCode": "class EvalCommand(command.Command):\n    \"\"\"Implementation of \"eval\" command.\"\"\"\n    def __init__(\n        self,\n        models: model_registry.ModelRegistry,\n        env: ipython_env.IPythonEnv | None = None,\n    ):\n        \"\"\"Constructor.\n        Args:\n          models: ModelRegistry instance.",
        "detail": "google.generativeai.notebook.eval_cmd",
        "documentation": {}
    },
    {
        "label": "FlagDef",
        "kind": 6,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "class FlagDef(abc.ABC):\n    \"\"\"Abstract base class for flag definitions.\n    Attributes:\n      name: Long name, e.g. \"colors\" will define the flag \"--colors\".\n      required: Whether the flag must be provided on the command line.\n      short_name: Optional short name.\n      parse_type: The type that ArgumentParser should parse the command line\n        argument to.\n      dest_type: The type that the parsed value is converted to. This is used when\n        we want ArgumentParser to parse as one type, then convert to a different",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "_SingleValueStoreAction",
        "kind": 6,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "class _SingleValueStoreAction(argparse.Action):\n    \"\"\"Custom Action for storing a value in an argparse.Namespace.\n    This action checks that the flag is specified at-most once.\n    \"\"\"\n    def __init__(\n        self,\n        option_strings,\n        dest,\n        dest_type: type[Any],\n        parse_to_dest_type_fn: _PARSEFN,",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "_MultiValuesAppendAction",
        "kind": 6,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "class _MultiValuesAppendAction(argparse.Action):\n    \"\"\"Custom Action for appending values in an argparse.Namespace.\n    This action checks that the flag is specified at-most once.\n    \"\"\"\n    def __init__(\n        self,\n        option_strings,\n        dest,\n        dest_type: type[Any],\n        parse_to_dest_type_fn: _PARSEFN,",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "_BooleanValueStoreAction",
        "kind": 6,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "class _BooleanValueStoreAction(argparse.Action):\n    \"\"\"Custom Action for setting a boolean value in argparse.Namespace.\n    The boolean flag expects the default to be False and will set the value to\n    True.\n    This action checks that the flag is specified at-most once.\n    \"\"\"\n    def __init__(\n        self,\n        option_strings,\n        dest,",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "SingleValueFlagDef",
        "kind": 6,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "class SingleValueFlagDef(FlagDef):\n    \"\"\"Definition for a flag that takes a single value.\n    Sample usage:\n      # This defines a flag that can be specified on the command line as:\n      #   --count=10\n      flag = SingleValueFlagDef(name=\"count\", parse_type=int, required=True)\n      flag.add_argument_to_parser(argument_parser)\n    Attributes:\n      default_value: Default value for optional flags.\n    \"\"\"",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "EnumFlagDef",
        "kind": 6,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "class EnumFlagDef(SingleValueFlagDef):\n    \"\"\"Definition for a flag that takes a value from an Enum.\n    Sample usage:\n      # This defines a flag that can be specified on the command line as:\n      #   --color=red\n      flag = SingleValueFlagDef(name=\"color\", enum_type=ColorsEnum,\n                                required=True)\n      flag.add_argument_to_parser(argument_parser)\n    \"\"\"\n    def __init__(self, *args, enum_type: type[enum.Enum], **kwargs):",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "MultiValuesFlagDef",
        "kind": 6,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "class MultiValuesFlagDef(FlagDef):\n    \"\"\"Definition for a flag that takes multiple values.\n    Sample usage:\n      # This defines a flag that can be specified on the command line as:\n      #   --colors=red green blue\n      flag = MultiValuesFlagDef(name=\"colors\", parse_type=str, required=True)\n      flag.add_argument_to_parser(argument_parser)\n    \"\"\"\n    def add_argument_to_parser(self, parser: argparse.ArgumentParser) -> None:\n        args = [\"--\" + self.name]",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "BooleanFlagDef",
        "kind": 6,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "class BooleanFlagDef(FlagDef):\n    \"\"\"Definition for a Boolean flag.\n    A boolean flag is always optional with a default value of False. The flag does\n    not take any values. Specifying the flag on the commandline will set it to\n    True.\n    \"\"\"\n    def _do_additional_validation(self) -> None:\n        if self.dest_type is not None:\n            raise ValueError(\"dest_type cannot be set for BooleanFlagDef\")\n        if self.parse_to_dest_type_fn is not None:",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "_PARSETYPES",
        "kind": 5,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "_PARSETYPES = Union[str, int, float]\n# These are the final result types that the intermediate parsed values will be\n# converted into. It is a superset of _PARSETYPES because we support converting\n# the parsed type into a more precise type, e.g. from str to Enum.\n_DESTTYPES = Union[\n    _PARSETYPES,\n    enum.Enum,\n    Tuple[str, Callable[[str, str], Any]],\n    Sequence[str],  # For --compare_fn\n    llmfn_inputs_source.LLMFnInputsSource,  # For --ground_truth",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "_DESTTYPES",
        "kind": 5,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "_DESTTYPES = Union[\n    _PARSETYPES,\n    enum.Enum,\n    Tuple[str, Callable[[str, str], Any]],\n    Sequence[str],  # For --compare_fn\n    llmfn_inputs_source.LLMFnInputsSource,  # For --ground_truth\n    llmfn_outputs.LLMFnOutputsSink,  # For --inputs  # For --outputs\n]\n# The signature of a function that converts a command line argument from the\n# intermediate parsed type to the result type.",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "_PARSEFN",
        "kind": 5,
        "importPath": "google.generativeai.notebook.flag_def",
        "description": "google.generativeai.notebook.flag_def",
        "peekOfCode": "_PARSEFN = Callable[[_PARSETYPES], _DESTTYPES]\ndef _get_type_name(x: type[Any]) -> str:\n    try:\n        return x.__name__\n    except AttributeError:\n        return str(x)\ndef _validate_flag_name(name: str) -> str:\n    \"\"\"Validation for long and short names for flags.\"\"\"\n    if not name:\n        raise ValueError(\"Cannot be empty\")",
        "detail": "google.generativeai.notebook.flag_def",
        "documentation": {}
    },
    {
        "label": "SpreadsheetNotFoundError",
        "kind": 6,
        "importPath": "google.generativeai.notebook.gspread_client",
        "description": "google.generativeai.notebook.gspread_client",
        "peekOfCode": "class SpreadsheetNotFoundError(RuntimeError):\n    pass\ndef _get_import_error() -> Exception:\n    return RuntimeError('\"gspread\" module not imported, got: {}'.format(_gspread_import_error))\nclass GSpreadClient(abc.ABC):\n    \"\"\"Wrapper around gspread.client.Client.\n    This adds a layer of indirection for us to inject mocks for testing.\n    \"\"\"\n    @abc.abstractmethod\n    def validate(self, sid: sheets_id.SheetsIdentifier) -> None:",
        "detail": "google.generativeai.notebook.gspread_client",
        "documentation": {}
    },
    {
        "label": "GSpreadClient",
        "kind": 6,
        "importPath": "google.generativeai.notebook.gspread_client",
        "description": "google.generativeai.notebook.gspread_client",
        "peekOfCode": "class GSpreadClient(abc.ABC):\n    \"\"\"Wrapper around gspread.client.Client.\n    This adds a layer of indirection for us to inject mocks for testing.\n    \"\"\"\n    @abc.abstractmethod\n    def validate(self, sid: sheets_id.SheetsIdentifier) -> None:\n        \"\"\"Validates that `name` is the name of a Google Sheets document.\n        Raises an exception if false.\n        Args:\n          sid: The identifier for the document.",
        "detail": "google.generativeai.notebook.gspread_client",
        "documentation": {}
    },
    {
        "label": "GSpreadClientImpl",
        "kind": 6,
        "importPath": "google.generativeai.notebook.gspread_client",
        "description": "google.generativeai.notebook.gspread_client",
        "peekOfCode": "class GSpreadClientImpl(GSpreadClient):\n    \"\"\"Concrete implementation of GSpreadClient.\"\"\"\n    def __init__(self, client: Any, env: ipython_env.IPythonEnv | None):\n        \"\"\"Constructor.\n        Args:\n          client: Instance of gspread.client.Client.\n          env: Optional instance of IPythonEnv. This is used to display messages\n            such as the URL of the output Worksheet.\n        \"\"\"\n        self._client = client",
        "detail": "google.generativeai.notebook.gspread_client",
        "documentation": {}
    },
    {
        "label": "NullGSpreadClient",
        "kind": 6,
        "importPath": "google.generativeai.notebook.gspread_client",
        "description": "google.generativeai.notebook.gspread_client",
        "peekOfCode": "class NullGSpreadClient(GSpreadClient):\n    \"\"\"Null-object implementation of GSpreadClient.\n    This class raises an error if any of its methods are called. It is used when\n    the gspread library is not available.\n    \"\"\"\n    def validate(self, sid: sheets_id.SheetsIdentifier) -> None:\n        raise _get_import_error()\n    def get_all_records(\n        self,\n        sid: sheets_id.SheetsIdentifier,",
        "detail": "google.generativeai.notebook.gspread_client",
        "documentation": {}
    },
    {
        "label": "authorize",
        "kind": 2,
        "importPath": "google.generativeai.notebook.gspread_client",
        "description": "google.generativeai.notebook.gspread_client",
        "peekOfCode": "def authorize(creds: credentials.Credentials, env: ipython_env.IPythonEnv | None) -> None:\n    \"\"\"Sets up credential for gspreads.\"\"\"\n    global _gspread_client\n    if gspread is not None:\n        client = gspread.authorize(creds)  # type: ignore\n        _gspread_client = GSpreadClientImpl(client=client, env=env)\n    else:\n        _gspread_client = NullGSpreadClient()\ndef get_client() -> GSpreadClient:\n    if not _gspread_client:",
        "detail": "google.generativeai.notebook.gspread_client",
        "documentation": {}
    },
    {
        "label": "get_client",
        "kind": 2,
        "importPath": "google.generativeai.notebook.gspread_client",
        "description": "google.generativeai.notebook.gspread_client",
        "peekOfCode": "def get_client() -> GSpreadClient:\n    if not _gspread_client:\n        raise RuntimeError(\"Must call authorize() first\")\n    return _gspread_client\ndef testonly_set_client(client: GSpreadClient) -> None:\n    \"\"\"Overrides the global client for testing.\"\"\"\n    global _gspread_client\n    _gspread_client = client",
        "detail": "google.generativeai.notebook.gspread_client",
        "documentation": {}
    },
    {
        "label": "testonly_set_client",
        "kind": 2,
        "importPath": "google.generativeai.notebook.gspread_client",
        "description": "google.generativeai.notebook.gspread_client",
        "peekOfCode": "def testonly_set_client(client: GSpreadClient) -> None:\n    \"\"\"Overrides the global client for testing.\"\"\"\n    global _gspread_client\n    _gspread_client = client",
        "detail": "google.generativeai.notebook.gspread_client",
        "documentation": {}
    },
    {
        "label": "GSpreadException",
        "kind": 5,
        "importPath": "google.generativeai.notebook.gspread_client",
        "description": "google.generativeai.notebook.gspread_client",
        "peekOfCode": "GSpreadException = Exception if gspread is None else gspread.exceptions.GSpreadException  # type: ignore\nclass SpreadsheetNotFoundError(RuntimeError):\n    pass\ndef _get_import_error() -> Exception:\n    return RuntimeError('\"gspread\" module not imported, got: {}'.format(_gspread_import_error))\nclass GSpreadClient(abc.ABC):\n    \"\"\"Wrapper around gspread.client.Client.\n    This adds a layer of indirection for us to inject mocks for testing.\n    \"\"\"\n    @abc.abstractmethod",
        "detail": "google.generativeai.notebook.gspread_client",
        "documentation": {}
    },
    {
        "label": "get_anchor_tag",
        "kind": 2,
        "importPath": "google.generativeai.notebook.html_utils",
        "description": "google.generativeai.notebook.html_utils",
        "peekOfCode": "def get_anchor_tag(url: sheets_id.SheetsURL, text: str) -> str:\n    \"\"\"Returns a HTML string representing an anchor tag.\n    This class uses the xml.etree library to handle HTML escaping.\n    Args:\n      url: The Sheets URL to link to.\n      text: The text body of the link.\n    Returns:\n      A string representing a HTML fragment.\n    \"\"\"\n    tag = ElementTree.Element(",
        "detail": "google.generativeai.notebook.html_utils",
        "documentation": {}
    },
    {
        "label": "_NormalizedInputsSource",
        "kind": 6,
        "importPath": "google.generativeai.notebook.input_utils",
        "description": "google.generativeai.notebook.input_utils",
        "peekOfCode": "class _NormalizedInputsSource(llmfn_inputs_source.LLMFnInputsSource):\n    \"\"\"Wrapper around NormalizedInputsList.\n    By design LLMFunction does not take NormalizedInputsList as input because\n    NormalizedInputsList is an internal representation so we want to minimize\n    exposure to the caller.\n    When we have inputs already in normalized format (e.g. from\n    join_prompt_inputs()) we can wrap it as an LLMFnInputsSource to pass as an\n    input to LLMFunction.\n    \"\"\"\n    def __init__(self, normalized_inputs: llmfn_inputs_source.NormalizedInputsList):",
        "detail": "google.generativeai.notebook.input_utils",
        "documentation": {}
    },
    {
        "label": "get_inputs_source_from_py_var",
        "kind": 2,
        "importPath": "google.generativeai.notebook.input_utils",
        "description": "google.generativeai.notebook.input_utils",
        "peekOfCode": "def get_inputs_source_from_py_var(\n    var_name: str,\n) -> llmfn_inputs_source.LLMFnInputsSource:\n    data = py_utils.get_py_var(var_name)\n    if isinstance(data, llmfn_inputs_source.LLMFnInputsSource):\n        # No conversion needed.\n        return data\n    normalized_inputs = llmfn_input_utils.to_normalized_inputs(data)\n    return _NormalizedInputsSource(normalized_inputs)\ndef join_inputs_sources(",
        "detail": "google.generativeai.notebook.input_utils",
        "documentation": {}
    },
    {
        "label": "join_inputs_sources",
        "kind": 2,
        "importPath": "google.generativeai.notebook.input_utils",
        "description": "google.generativeai.notebook.input_utils",
        "peekOfCode": "def join_inputs_sources(\n    parsed_args: parsed_args_lib.ParsedArgs,\n    suppress_status_msgs: bool = False,\n) -> llmfn_inputs_source.LLMFnInputsSource:\n    \"\"\"Get a single combined input source from `parsed_args.\"\"\"\n    combined_inputs: list[Mapping[str, str]] = []\n    for source in parsed_args.inputs:\n        combined_inputs.extend(\n            source.to_normalized_inputs(suppress_status_msgs=suppress_status_msgs)\n        )",
        "detail": "google.generativeai.notebook.input_utils",
        "documentation": {}
    },
    {
        "label": "IPythonEnv",
        "kind": 6,
        "importPath": "google.generativeai.notebook.ipython_env",
        "description": "google.generativeai.notebook.ipython_env",
        "peekOfCode": "class IPythonEnv(abc.ABC):\n    \"\"\"Abstract base class that provides a wrapper around IPython methods.\"\"\"\n    @abc.abstractmethod\n    def display(self, x: Any) -> None:\n        \"\"\"Wrapper around IPython.core.display.display().\"\"\"\n    @abc.abstractmethod\n    def display_html(self, x: str) -> None:\n        \"\"\"Wrapper to display HTML.\n        This method is equivalent to calling:\n          display.display(display.HTML(x))",
        "detail": "google.generativeai.notebook.ipython_env",
        "documentation": {}
    },
    {
        "label": "IPythonEnvImpl",
        "kind": 6,
        "importPath": "google.generativeai.notebook.ipython_env_impl",
        "description": "google.generativeai.notebook.ipython_env_impl",
        "peekOfCode": "class IPythonEnvImpl(ipython_env.IPythonEnv):\n    \"\"\"Concrete implementation of IPythonEnv.\"\"\"\n    def display(self, x: Any) -> None:\n        ipython_display.display(x)\n    def display_html(self, x: str) -> None:\n        ipython_display.display(ipython_display.HTML(x))",
        "detail": "google.generativeai.notebook.ipython_env_impl",
        "documentation": {}
    },
    {
        "label": "AbstractMagics",
        "kind": 6,
        "importPath": "google.generativeai.notebook.magics",
        "description": "google.generativeai.notebook.magics",
        "peekOfCode": "class AbstractMagics(abc.ABC):\n    \"\"\"Defines interface to Magics class.\"\"\"\n    @abc.abstractmethod\n    def llm(self, cell_line: str | None, cell_body: str | None):\n        \"\"\"Perform various LLM-related operations.\n        Args:\n          cell_line: String to pass to the MagicsEngine.\n          cell_body: Contents of the cell body.\n        \"\"\"\n        raise NotImplementedError()",
        "detail": "google.generativeai.notebook.magics",
        "documentation": {}
    },
    {
        "label": "MagicsImpl",
        "kind": 6,
        "importPath": "google.generativeai.notebook.magics",
        "description": "google.generativeai.notebook.magics",
        "peekOfCode": "class MagicsImpl(AbstractMagics):\n    \"\"\"Actual class implementing the magics functionality.\n    We use a separate class to ensure a single, global instance\n    of the magics class.\n    \"\"\"\n    def __init__(self):\n        self._engine = magics_engine.MagicsEngine(env=_get_ipython_env())\n    def llm(self, cell_line: str | None, cell_body: str | None):\n        \"\"\"Perform various LLM-related operations.\n        Args:",
        "detail": "google.generativeai.notebook.magics",
        "documentation": {}
    },
    {
        "label": "Magics",
        "kind": 6,
        "importPath": "google.generativeai.notebook.magics",
        "description": "google.generativeai.notebook.magics",
        "peekOfCode": "class Magics(magic.Magics):\n    \"\"\"Class to register the magic with Colab.\n    Objects of this class delegate all calls to a single,\n    global instance.\n    \"\"\"\n    # Global instance\n    _instance = None\n    @classmethod\n    def get_instance(cls) -> AbstractMagics:\n        \"\"\"Retrieve global instance of the Magics object.\"\"\"",
        "detail": "google.generativeai.notebook.magics",
        "documentation": {}
    },
    {
        "label": "authorize",
        "kind": 2,
        "importPath": "google.generativeai.notebook.magics",
        "description": "google.generativeai.notebook.magics",
        "peekOfCode": "def authorize(creds: credentials.Credentials) -> None:\n    \"\"\"Sets up credentials.\n    This is used for interacting Google APIs, such as Google Sheets.\n    Args:\n      creds: The credentials that will be used (e.g. to read from Google Sheets.)\n    \"\"\"\n    gspread_client.authorize(creds=creds, env=_get_ipython_env())\nclass AbstractMagics(abc.ABC):\n    \"\"\"Defines interface to Magics class.\"\"\"\n    @abc.abstractmethod",
        "detail": "google.generativeai.notebook.magics",
        "documentation": {}
    },
    {
        "label": "genai.USER_AGENT",
        "kind": 5,
        "importPath": "google.generativeai.notebook.magics",
        "description": "google.generativeai.notebook.magics",
        "peekOfCode": "genai.USER_AGENT = \"genai-py-magic\"\nSheetsInputs = sheets_utils.SheetsInputs\nSheetsOutputs = sheets_utils.SheetsOutputs\n# Decorator functions for post-processing.\npost_process_add_fn = post_process_utils.post_process_add_fn\npost_process_replace_fn = post_process_utils.post_process_replace_fn\n# Globals.\n_ipython_env: ipython_env.IPythonEnv | None = None\ndef _get_ipython_env() -> ipython_env.IPythonEnv:\n    \"\"\"Lazily constructs and returns a global IPythonEnv instance.\"\"\"",
        "detail": "google.generativeai.notebook.magics",
        "documentation": {}
    },
    {
        "label": "SheetsInputs",
        "kind": 5,
        "importPath": "google.generativeai.notebook.magics",
        "description": "google.generativeai.notebook.magics",
        "peekOfCode": "SheetsInputs = sheets_utils.SheetsInputs\nSheetsOutputs = sheets_utils.SheetsOutputs\n# Decorator functions for post-processing.\npost_process_add_fn = post_process_utils.post_process_add_fn\npost_process_replace_fn = post_process_utils.post_process_replace_fn\n# Globals.\n_ipython_env: ipython_env.IPythonEnv | None = None\ndef _get_ipython_env() -> ipython_env.IPythonEnv:\n    \"\"\"Lazily constructs and returns a global IPythonEnv instance.\"\"\"\n    global _ipython_env",
        "detail": "google.generativeai.notebook.magics",
        "documentation": {}
    },
    {
        "label": "SheetsOutputs",
        "kind": 5,
        "importPath": "google.generativeai.notebook.magics",
        "description": "google.generativeai.notebook.magics",
        "peekOfCode": "SheetsOutputs = sheets_utils.SheetsOutputs\n# Decorator functions for post-processing.\npost_process_add_fn = post_process_utils.post_process_add_fn\npost_process_replace_fn = post_process_utils.post_process_replace_fn\n# Globals.\n_ipython_env: ipython_env.IPythonEnv | None = None\ndef _get_ipython_env() -> ipython_env.IPythonEnv:\n    \"\"\"Lazily constructs and returns a global IPythonEnv instance.\"\"\"\n    global _ipython_env\n    if _ipython_env is None:",
        "detail": "google.generativeai.notebook.magics",
        "documentation": {}
    },
    {
        "label": "post_process_add_fn",
        "kind": 5,
        "importPath": "google.generativeai.notebook.magics",
        "description": "google.generativeai.notebook.magics",
        "peekOfCode": "post_process_add_fn = post_process_utils.post_process_add_fn\npost_process_replace_fn = post_process_utils.post_process_replace_fn\n# Globals.\n_ipython_env: ipython_env.IPythonEnv | None = None\ndef _get_ipython_env() -> ipython_env.IPythonEnv:\n    \"\"\"Lazily constructs and returns a global IPythonEnv instance.\"\"\"\n    global _ipython_env\n    if _ipython_env is None:\n        _ipython_env = ipython_env_impl.IPythonEnvImpl()\n    return _ipython_env",
        "detail": "google.generativeai.notebook.magics",
        "documentation": {}
    },
    {
        "label": "post_process_replace_fn",
        "kind": 5,
        "importPath": "google.generativeai.notebook.magics",
        "description": "google.generativeai.notebook.magics",
        "peekOfCode": "post_process_replace_fn = post_process_utils.post_process_replace_fn\n# Globals.\n_ipython_env: ipython_env.IPythonEnv | None = None\ndef _get_ipython_env() -> ipython_env.IPythonEnv:\n    \"\"\"Lazily constructs and returns a global IPythonEnv instance.\"\"\"\n    global _ipython_env\n    if _ipython_env is None:\n        _ipython_env = ipython_env_impl.IPythonEnvImpl()\n    return _ipython_env\ndef authorize(creds: credentials.Credentials) -> None:",
        "detail": "google.generativeai.notebook.magics",
        "documentation": {}
    },
    {
        "label": "MagicsEngine",
        "kind": 6,
        "importPath": "google.generativeai.notebook.magics_engine",
        "description": "google.generativeai.notebook.magics_engine",
        "peekOfCode": "class MagicsEngine:\n    \"\"\"Implementation of functionality used by Magics.\n    This class provides the implementation for Magics, decoupled from the\n    details of integrating with Colab Magics such as registration.\n    \"\"\"\n    def __init__(\n        self,\n        registry: model_registry.ModelRegistry | None = None,\n        env: ipython_env.IPythonEnv | None = None,\n    ):",
        "detail": "google.generativeai.notebook.magics_engine",
        "documentation": {}
    },
    {
        "label": "ModelName",
        "kind": 6,
        "importPath": "google.generativeai.notebook.model_registry",
        "description": "google.generativeai.notebook.model_registry",
        "peekOfCode": "class ModelName(enum.Enum):\n    ECHO_MODEL = \"echo\"\n    TEXT_MODEL = \"text\"\nclass ModelRegistry:\n    \"\"\"Registry that instantiates and caches models.\"\"\"\n    DEFAULT_MODEL = ModelName.TEXT_MODEL\n    def __init__(self):\n        self._model_cache: dict[ModelName, model_lib.AbstractModel] = {}\n        self._model_constructors: dict[ModelName, Callable[[], model_lib.AbstractModel]] = {\n            ModelName.ECHO_MODEL: model_lib.EchoModel,",
        "detail": "google.generativeai.notebook.model_registry",
        "documentation": {}
    },
    {
        "label": "ModelRegistry",
        "kind": 6,
        "importPath": "google.generativeai.notebook.model_registry",
        "description": "google.generativeai.notebook.model_registry",
        "peekOfCode": "class ModelRegistry:\n    \"\"\"Registry that instantiates and caches models.\"\"\"\n    DEFAULT_MODEL = ModelName.TEXT_MODEL\n    def __init__(self):\n        self._model_cache: dict[ModelName, model_lib.AbstractModel] = {}\n        self._model_constructors: dict[ModelName, Callable[[], model_lib.AbstractModel]] = {\n            ModelName.ECHO_MODEL: model_lib.EchoModel,\n            ModelName.TEXT_MODEL: text_model.TextModel,\n        }\n    def get_model(self, model_name: ModelName) -> model_lib.AbstractModel:",
        "detail": "google.generativeai.notebook.model_registry",
        "documentation": {}
    },
    {
        "label": "_PyVarOutputsSink",
        "kind": 6,
        "importPath": "google.generativeai.notebook.output_utils",
        "description": "google.generativeai.notebook.output_utils",
        "peekOfCode": "class _PyVarOutputsSink(llmfn_outputs.LLMFnOutputsSink):\n    \"\"\"Sink that writes results to a Python variable.\"\"\"\n    def __init__(self, var_name: str):\n        self._var_name = var_name\n    def write_outputs(self, outputs: llmfn_outputs.LLMFnOutputsBase) -> None:\n        # Clone our results so that they are all independent.\n        py_utils.set_py_var(self._var_name, copy.deepcopy(outputs))\ndef get_outputs_sink_from_py_var(\n    var_name: str,\n) -> llmfn_outputs.LLMFnOutputsSink:",
        "detail": "google.generativeai.notebook.output_utils",
        "documentation": {}
    },
    {
        "label": "get_outputs_sink_from_py_var",
        "kind": 2,
        "importPath": "google.generativeai.notebook.output_utils",
        "description": "google.generativeai.notebook.output_utils",
        "peekOfCode": "def get_outputs_sink_from_py_var(\n    var_name: str,\n) -> llmfn_outputs.LLMFnOutputsSink:\n    # The output variable `var_name` will be created if it does not already\n    # exist.\n    if py_utils.has_py_var(var_name):\n        data = py_utils.get_py_var(var_name)\n        if isinstance(data, llmfn_outputs.LLMFnOutputsSink):\n            return data\n    return _PyVarOutputsSink(var_name)",
        "detail": "google.generativeai.notebook.output_utils",
        "documentation": {}
    },
    {
        "label": "write_to_outputs",
        "kind": 2,
        "importPath": "google.generativeai.notebook.output_utils",
        "description": "google.generativeai.notebook.output_utils",
        "peekOfCode": "def write_to_outputs(\n    results: llmfn_outputs.LLMFnOutputs,\n    parsed_args: parsed_args_lib.ParsedArgs,\n) -> None:\n    \"\"\"Writes `results` to the sinks provided.\n    Args:\n      results: The results to export.\n      parsed_args: Arguments parsed from the command line.\n    \"\"\"\n    for sink in parsed_args.outputs:",
        "detail": "google.generativeai.notebook.output_utils",
        "documentation": {}
    },
    {
        "label": "CommandName",
        "kind": 6,
        "importPath": "google.generativeai.notebook.parsed_args_lib",
        "description": "google.generativeai.notebook.parsed_args_lib",
        "peekOfCode": "class CommandName(enum.Enum):\n    RUN_CMD = \"run\"\n    COMPILE_CMD = \"compile\"\n    COMPARE_CMD = \"compare\"\n    EVAL_CMD = \"eval\"\n@dataclasses.dataclass(frozen=True)\nclass ParsedArgs:\n    \"\"\"The results of parsing the command line.\"\"\"\n    cmd: CommandName\n    # For run, compile and eval commands.",
        "detail": "google.generativeai.notebook.parsed_args_lib",
        "documentation": {}
    },
    {
        "label": "ParsedArgs",
        "kind": 6,
        "importPath": "google.generativeai.notebook.parsed_args_lib",
        "description": "google.generativeai.notebook.parsed_args_lib",
        "peekOfCode": "class ParsedArgs:\n    \"\"\"The results of parsing the command line.\"\"\"\n    cmd: CommandName\n    # For run, compile and eval commands.\n    model_args: model_lib.ModelArguments\n    model_type: model_registry.ModelName | None = None\n    unique: bool = False\n    # For run, compare and eval commands.\n    inputs: Sequence[llmfn_inputs_source.LLMFnInputsSource] = dataclasses.field(\n        default_factory=list",
        "detail": "google.generativeai.notebook.parsed_args_lib",
        "documentation": {}
    },
    {
        "label": "PostProcessingTokens",
        "kind": 5,
        "importPath": "google.generativeai.notebook.parsed_args_lib",
        "description": "google.generativeai.notebook.parsed_args_lib",
        "peekOfCode": "PostProcessingTokens = Sequence[Sequence[str]]\n# The type of function taken by the \"compare_fn\" flag.\n# It takes the text_results of the left- and right-hand side functions as\n# inputs and returns a comparison result.\nTextResultCompareFn = Callable[[str, str], Any]\nclass CommandName(enum.Enum):\n    RUN_CMD = \"run\"\n    COMPILE_CMD = \"compile\"\n    COMPARE_CMD = \"compare\"\n    EVAL_CMD = \"eval\"",
        "detail": "google.generativeai.notebook.parsed_args_lib",
        "documentation": {}
    },
    {
        "label": "TextResultCompareFn",
        "kind": 5,
        "importPath": "google.generativeai.notebook.parsed_args_lib",
        "description": "google.generativeai.notebook.parsed_args_lib",
        "peekOfCode": "TextResultCompareFn = Callable[[str, str], Any]\nclass CommandName(enum.Enum):\n    RUN_CMD = \"run\"\n    COMPILE_CMD = \"compile\"\n    COMPARE_CMD = \"compare\"\n    EVAL_CMD = \"eval\"\n@dataclasses.dataclass(frozen=True)\nclass ParsedArgs:\n    \"\"\"The results of parsing the command line.\"\"\"\n    cmd: CommandName",
        "detail": "google.generativeai.notebook.parsed_args_lib",
        "documentation": {}
    },
    {
        "label": "PostProcessParseError",
        "kind": 6,
        "importPath": "google.generativeai.notebook.post_process_utils",
        "description": "google.generativeai.notebook.post_process_utils",
        "peekOfCode": "class PostProcessParseError(RuntimeError):\n    \"\"\"An error parsing the post-processing tokens.\"\"\"\nclass ParsedPostProcessExpr(abc.ABC):\n    \"\"\"A post-processing expression parsed from the command line.\"\"\"\n    @abc.abstractmethod\n    def name(self) -> str:\n        \"\"\"Returns the name of this expression.\"\"\"\n    @abc.abstractmethod\n    def add_to_llm_function(self, llm_fn: llm_function.LLMFunction) -> llm_function.LLMFunction:\n        \"\"\"Adds this parsed expression to `llm_fn` as a post-processing command.\"\"\"",
        "detail": "google.generativeai.notebook.post_process_utils",
        "documentation": {}
    },
    {
        "label": "ParsedPostProcessExpr",
        "kind": 6,
        "importPath": "google.generativeai.notebook.post_process_utils",
        "description": "google.generativeai.notebook.post_process_utils",
        "peekOfCode": "class ParsedPostProcessExpr(abc.ABC):\n    \"\"\"A post-processing expression parsed from the command line.\"\"\"\n    @abc.abstractmethod\n    def name(self) -> str:\n        \"\"\"Returns the name of this expression.\"\"\"\n    @abc.abstractmethod\n    def add_to_llm_function(self, llm_fn: llm_function.LLMFunction) -> llm_function.LLMFunction:\n        \"\"\"Adds this parsed expression to `llm_fn` as a post-processing command.\"\"\"\nclass _ParsedPostProcessAddExpr(\n    ParsedPostProcessExpr, llmfn_post_process.LLMFnPostProcessBatchAddFn",
        "detail": "google.generativeai.notebook.post_process_utils",
        "documentation": {}
    },
    {
        "label": "_ParsedPostProcessAddExpr",
        "kind": 6,
        "importPath": "google.generativeai.notebook.post_process_utils",
        "description": "google.generativeai.notebook.post_process_utils",
        "peekOfCode": "class _ParsedPostProcessAddExpr(\n    ParsedPostProcessExpr, llmfn_post_process.LLMFnPostProcessBatchAddFn\n):\n    \"\"\"An expression that returns the value of a new column to add to a row.\"\"\"\n    def __init__(self, name: str, fn: Callable[[str], Any]):\n        \"\"\"Constructor.\n        Args:\n          name: The name of the expression. The name of the new column will be\n            derived from this.\n          fn: A function that takes the result of a row and returns a new value to",
        "detail": "google.generativeai.notebook.post_process_utils",
        "documentation": {}
    },
    {
        "label": "_ParsedPostProcessReplaceExpr",
        "kind": 6,
        "importPath": "google.generativeai.notebook.post_process_utils",
        "description": "google.generativeai.notebook.post_process_utils",
        "peekOfCode": "class _ParsedPostProcessReplaceExpr(\n    ParsedPostProcessExpr, llmfn_post_process.LLMFnPostProcessBatchReplaceFn\n):\n    \"\"\"An expression that returns the new result value for a row.\"\"\"\n    def __init__(self, name: str, fn: Callable[[str], str]):\n        \"\"\"Constructor.\n        Args:\n          name: The name of the expression.\n          fn: A function that takes the result of a row and returns the new result.\n        \"\"\"",
        "detail": "google.generativeai.notebook.post_process_utils",
        "documentation": {}
    },
    {
        "label": "post_process_add_fn",
        "kind": 2,
        "importPath": "google.generativeai.notebook.post_process_utils",
        "description": "google.generativeai.notebook.post_process_utils",
        "peekOfCode": "def post_process_add_fn(fn: Callable[[str], Any]):\n    return _ParsedPostProcessAddExpr(name=fn.__name__, fn=fn)\ndef post_process_replace_fn(fn: Callable[[str], str]):\n    return _ParsedPostProcessReplaceExpr(name=fn.__name__, fn=fn)\ndef validate_one_post_processing_expression(\n    tokens: Sequence[str],\n) -> None:\n    if not tokens:\n        raise PostProcessParseError(\"Cannot have empty post-processing expression\")\n    if len(tokens) > 1:",
        "detail": "google.generativeai.notebook.post_process_utils",
        "documentation": {}
    },
    {
        "label": "post_process_replace_fn",
        "kind": 2,
        "importPath": "google.generativeai.notebook.post_process_utils",
        "description": "google.generativeai.notebook.post_process_utils",
        "peekOfCode": "def post_process_replace_fn(fn: Callable[[str], str]):\n    return _ParsedPostProcessReplaceExpr(name=fn.__name__, fn=fn)\ndef validate_one_post_processing_expression(\n    tokens: Sequence[str],\n) -> None:\n    if not tokens:\n        raise PostProcessParseError(\"Cannot have empty post-processing expression\")\n    if len(tokens) > 1:\n        raise PostProcessParseError(\"Post-processing expression should be a single token\")\ndef _resolve_one_post_processing_expression(",
        "detail": "google.generativeai.notebook.post_process_utils",
        "documentation": {}
    },
    {
        "label": "validate_one_post_processing_expression",
        "kind": 2,
        "importPath": "google.generativeai.notebook.post_process_utils",
        "description": "google.generativeai.notebook.post_process_utils",
        "peekOfCode": "def validate_one_post_processing_expression(\n    tokens: Sequence[str],\n) -> None:\n    if not tokens:\n        raise PostProcessParseError(\"Cannot have empty post-processing expression\")\n    if len(tokens) > 1:\n        raise PostProcessParseError(\"Post-processing expression should be a single token\")\ndef _resolve_one_post_processing_expression(\n    tokens: Sequence[str],\n) -> tuple[str, Any]:",
        "detail": "google.generativeai.notebook.post_process_utils",
        "documentation": {}
    },
    {
        "label": "resolve_post_processing_tokens",
        "kind": 2,
        "importPath": "google.generativeai.notebook.post_process_utils",
        "description": "google.generativeai.notebook.post_process_utils",
        "peekOfCode": "def resolve_post_processing_tokens(\n    tokens: Sequence[Sequence[str]],\n) -> Sequence[ParsedPostProcessExpr]:\n    \"\"\"Resolves post-processing tokens into ParsedPostProcessExprs.\n    E.g. Given [[\"add_length\"], [\"to_upper\"]] as input, this function will return\n    a sequence of ParsedPostProcessExprs that will execute add_length() and\n    to_upper() on each entry of the LLM output as post-processing operations.\n    Raises:\n      PostProcessParseError: An error parsing or resolving the tokens.\n    Args:",
        "detail": "google.generativeai.notebook.post_process_utils",
        "documentation": {}
    },
    {
        "label": "add_length",
        "kind": 2,
        "importPath": "google.generativeai.notebook.post_process_utils_test_helper",
        "description": "google.generativeai.notebook.post_process_utils_test_helper",
        "peekOfCode": "def add_length(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_replace_fn\ndef to_upper(x: str) -> str:\n    return x.upper()",
        "detail": "google.generativeai.notebook.post_process_utils_test_helper",
        "documentation": {}
    },
    {
        "label": "add_length_decorated",
        "kind": 2,
        "importPath": "google.generativeai.notebook.post_process_utils_test_helper",
        "description": "google.generativeai.notebook.post_process_utils_test_helper",
        "peekOfCode": "def add_length_decorated(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_replace_fn\ndef to_upper(x: str) -> str:\n    return x.upper()",
        "detail": "google.generativeai.notebook.post_process_utils_test_helper",
        "documentation": {}
    },
    {
        "label": "to_upper",
        "kind": 2,
        "importPath": "google.generativeai.notebook.post_process_utils_test_helper",
        "description": "google.generativeai.notebook.post_process_utils_test_helper",
        "peekOfCode": "def to_upper(x: str) -> str:\n    return x.upper()",
        "detail": "google.generativeai.notebook.post_process_utils_test_helper",
        "documentation": {}
    },
    {
        "label": "validate_var_name",
        "kind": 2,
        "importPath": "google.generativeai.notebook.py_utils",
        "description": "google.generativeai.notebook.py_utils",
        "peekOfCode": "def validate_var_name(var_name: str) -> None:\n    \"\"\"Validates that the variable name is a valid identifier.\"\"\"\n    if not var_name.isidentifier():\n        raise ValueError('Invalid Python variable name, got \"{}\"'.format(var_name))\n    if keyword.iskeyword(var_name):\n        raise ValueError('Cannot use Python keywords, got \"{}\"'.format(var_name))\ndef get_main_module():\n    return sys.modules[\"__main__\"]\ndef get_py_var(var_name: str) -> Any:\n    \"\"\"Retrieves the value of `var_name` from the global environment.\"\"\"",
        "detail": "google.generativeai.notebook.py_utils",
        "documentation": {}
    },
    {
        "label": "get_main_module",
        "kind": 2,
        "importPath": "google.generativeai.notebook.py_utils",
        "description": "google.generativeai.notebook.py_utils",
        "peekOfCode": "def get_main_module():\n    return sys.modules[\"__main__\"]\ndef get_py_var(var_name: str) -> Any:\n    \"\"\"Retrieves the value of `var_name` from the global environment.\"\"\"\n    validate_var_name(var_name)\n    g_vars = vars(get_main_module())\n    if var_name in g_vars:\n        return g_vars[var_name]\n    elif var_name in vars(builtins):\n        return vars(builtins)[var_name]",
        "detail": "google.generativeai.notebook.py_utils",
        "documentation": {}
    },
    {
        "label": "get_py_var",
        "kind": 2,
        "importPath": "google.generativeai.notebook.py_utils",
        "description": "google.generativeai.notebook.py_utils",
        "peekOfCode": "def get_py_var(var_name: str) -> Any:\n    \"\"\"Retrieves the value of `var_name` from the global environment.\"\"\"\n    validate_var_name(var_name)\n    g_vars = vars(get_main_module())\n    if var_name in g_vars:\n        return g_vars[var_name]\n    elif var_name in vars(builtins):\n        return vars(builtins)[var_name]\n    raise NameError('\"{}\" not found'.format(var_name))\ndef has_py_var(var_name: str) -> bool:",
        "detail": "google.generativeai.notebook.py_utils",
        "documentation": {}
    },
    {
        "label": "has_py_var",
        "kind": 2,
        "importPath": "google.generativeai.notebook.py_utils",
        "description": "google.generativeai.notebook.py_utils",
        "peekOfCode": "def has_py_var(var_name: str) -> bool:\n    \"\"\"Returns true if `var_name` is defined in the global environment.\"\"\"\n    try:\n        validate_var_name(var_name)\n        _ = get_py_var(var_name)\n    except ValueError:\n        return False\n    except NameError:\n        return False\n    return True",
        "detail": "google.generativeai.notebook.py_utils",
        "documentation": {}
    },
    {
        "label": "set_py_var",
        "kind": 2,
        "importPath": "google.generativeai.notebook.py_utils",
        "description": "google.generativeai.notebook.py_utils",
        "peekOfCode": "def set_py_var(var_name: str, val: Any) -> None:\n    \"\"\"Sets the value of `var_name` in the global environment.\"\"\"\n    validate_var_name(var_name)\n    g_vars = vars(get_main_module())\n    g_vars[var_name] = val",
        "detail": "google.generativeai.notebook.py_utils",
        "documentation": {}
    },
    {
        "label": "RunCommand",
        "kind": 6,
        "importPath": "google.generativeai.notebook.run_cmd",
        "description": "google.generativeai.notebook.run_cmd",
        "peekOfCode": "class RunCommand(command.Command):\n    \"\"\"Implementation of the \"run\" command.\"\"\"\n    def __init__(\n        self,\n        models: model_registry.ModelRegistry,\n        env: ipython_env.IPythonEnv | None = None,\n    ):\n        \"\"\"Constructor.\n        Args:\n          models: ModelRegistry instance.",
        "detail": "google.generativeai.notebook.run_cmd",
        "documentation": {}
    },
    {
        "label": "SheetsURL",
        "kind": 6,
        "importPath": "google.generativeai.notebook.sheets_id",
        "description": "google.generativeai.notebook.sheets_id",
        "peekOfCode": "class SheetsURL:\n    \"\"\"Class that enforces safety by ensuring that URLs are sanitized.\"\"\"\n    def __init__(self, url: str):\n        self._url: str = sheets_sanitize_url.sanitize_sheets_url(url)\n    def __str__(self) -> str:\n        return self._url\nclass SheetsKey:\n    \"\"\"Class that enforces safety by ensuring that keys are sanitized.\"\"\"\n    def __init__(self, key: str):\n        self._key: str = _sanitize_key(key)",
        "detail": "google.generativeai.notebook.sheets_id",
        "documentation": {}
    },
    {
        "label": "SheetsKey",
        "kind": 6,
        "importPath": "google.generativeai.notebook.sheets_id",
        "description": "google.generativeai.notebook.sheets_id",
        "peekOfCode": "class SheetsKey:\n    \"\"\"Class that enforces safety by ensuring that keys are sanitized.\"\"\"\n    def __init__(self, key: str):\n        self._key: str = _sanitize_key(key)\n    def __str__(self) -> str:\n        return self._key\nclass SheetsIdentifier:\n    \"\"\"Encapsulates a means to identify a Sheets document.\n    The gspread library provides three ways to look up a Sheets document: by name,\n    by url and by key. An instance of this class represents exactly one of the",
        "detail": "google.generativeai.notebook.sheets_id",
        "documentation": {}
    },
    {
        "label": "SheetsIdentifier",
        "kind": 6,
        "importPath": "google.generativeai.notebook.sheets_id",
        "description": "google.generativeai.notebook.sheets_id",
        "peekOfCode": "class SheetsIdentifier:\n    \"\"\"Encapsulates a means to identify a Sheets document.\n    The gspread library provides three ways to look up a Sheets document: by name,\n    by url and by key. An instance of this class represents exactly one of the\n    methods.\n    \"\"\"\n    def __init__(\n        self,\n        name: str | None = None,\n        key: SheetsKey | None = None,",
        "detail": "google.generativeai.notebook.sheets_id",
        "documentation": {}
    },
    {
        "label": "sanitize_sheets_url",
        "kind": 2,
        "importPath": "google.generativeai.notebook.sheets_sanitize_url",
        "description": "google.generativeai.notebook.sheets_sanitize_url",
        "peekOfCode": "def sanitize_sheets_url(url: str) -> str:\n    \"\"\"Sanitize a Sheets URL.\n    Run some saftey checks to check whether `url` is a Sheets URL. This is not a\n    general-purpose URL sanitizer. Rather, it makes use of the fact that we know\n    the URL has to be for Sheets so we can make a few assumptions about (e.g. the\n    domain).\n    Args:\n      url: The url to sanitize.\n    Returns:\n      The sanitized url.",
        "detail": "google.generativeai.notebook.sheets_sanitize_url",
        "documentation": {}
    },
    {
        "label": "SheetsInputs",
        "kind": 6,
        "importPath": "google.generativeai.notebook.sheets_utils",
        "description": "google.generativeai.notebook.sheets_utils",
        "peekOfCode": "class SheetsInputs(llmfn_inputs_source.LLMFnInputsSource):\n    \"\"\"Inputs to an LLMFunction from Google Sheets.\"\"\"\n    def __init__(self, sid: sheets_id.SheetsIdentifier, worksheet_id: int = 0):\n        super().__init__()\n        self._sid = sid\n        self._worksheet_id = worksheet_id\n    def _to_normalized_inputs_impl(\n        self,\n    ) -> tuple[Sequence[Mapping[str, str]], Callable[[], None]]:\n        return gspread_client.get_client().get_all_records(",
        "detail": "google.generativeai.notebook.sheets_utils",
        "documentation": {}
    },
    {
        "label": "SheetsOutputs",
        "kind": 6,
        "importPath": "google.generativeai.notebook.sheets_utils",
        "description": "google.generativeai.notebook.sheets_utils",
        "peekOfCode": "class SheetsOutputs(llmfn_outputs.LLMFnOutputsSink):\n    \"\"\"Writes outputs from an LLMFunction to Google Sheets.\"\"\"\n    def __init__(self, sid: sheets_id.SheetsIdentifier):\n        self._sid = sid\n    def write_outputs(self, outputs: llmfn_outputs.LLMFnOutputsBase) -> None:\n        # Transpose `outputs` into a list of rows.\n        outputs_dict = outputs.as_dict()\n        outputs_rows: list[Sequence[Any]] = []\n        outputs_rows.append(list(outputs_dict.keys()))\n        outputs_rows.extend([list(x) for x in zip(*outputs_dict.values())])",
        "detail": "google.generativeai.notebook.sheets_utils",
        "documentation": {}
    },
    {
        "label": "get_sheets_id_from_str",
        "kind": 2,
        "importPath": "google.generativeai.notebook.sheets_utils",
        "description": "google.generativeai.notebook.sheets_utils",
        "peekOfCode": "def get_sheets_id_from_str(value: str) -> sheets_id.SheetsIdentifier:\n    if sid := _try_sheet_id_as_url(value):\n        return sid\n    if sid := _try_sheet_id_as_key(value):\n        return sid\n    if sid := _try_sheet_id_as_name(value):\n        return sid\n    raise RuntimeError('No Sheets found with \"{}\" as URL, key or name'.format(value))\nclass SheetsInputs(llmfn_inputs_source.LLMFnInputsSource):\n    \"\"\"Inputs to an LLMFunction from Google Sheets.\"\"\"",
        "detail": "google.generativeai.notebook.sheets_utils",
        "documentation": {}
    },
    {
        "label": "TextModel",
        "kind": 6,
        "importPath": "google.generativeai.notebook.text_model",
        "description": "google.generativeai.notebook.text_model",
        "peekOfCode": "class TextModel(model_lib.AbstractModel):\n    \"\"\"Concrete model that uses the generate_content service.\"\"\"\n    def _generate_text(\n        self,\n        prompt: str,\n        model: str | None = None,\n        temperature: float | None = None,\n        candidate_count: int | None = None,\n    ) -> generation_types.GenerateContentResponse:\n        gen_config = {}",
        "detail": "google.generativeai.notebook.text_model",
        "documentation": {}
    },
    {
        "label": "_DEFAULT_MODEL",
        "kind": 5,
        "importPath": "google.generativeai.notebook.text_model",
        "description": "google.generativeai.notebook.text_model",
        "peekOfCode": "_DEFAULT_MODEL = \"models/gemini-pro\"\nclass TextModel(model_lib.AbstractModel):\n    \"\"\"Concrete model that uses the generate_content service.\"\"\"\n    def _generate_text(\n        self,\n        prompt: str,\n        model: str | None = None,\n        temperature: float | None = None,\n        candidate_count: int | None = None,\n    ) -> generation_types.GenerateContentResponse:",
        "detail": "google.generativeai.notebook.text_model",
        "documentation": {}
    },
    {
        "label": "to_finish_reason",
        "kind": 2,
        "importPath": "google.generativeai.types.answer_types",
        "description": "google.generativeai.types.answer_types",
        "peekOfCode": "def to_finish_reason(x: FinishReasonOptions) -> FinishReason:\n    if isinstance(x, str):\n        x = x.lower()\n    return _FINISH_REASONS[x]",
        "detail": "google.generativeai.types.answer_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.answer_types",
        "description": "google.generativeai.types.answer_types",
        "peekOfCode": "__all__ = [\"Answer\"]\nFinishReason = protos.Candidate.FinishReason\nFinishReasonOptions = Union[int, str, FinishReason]\n_FINISH_REASONS: dict[FinishReasonOptions, FinishReason] = {\n    FinishReason.FINISH_REASON_UNSPECIFIED: FinishReason.FINISH_REASON_UNSPECIFIED,\n    0: FinishReason.FINISH_REASON_UNSPECIFIED,\n    \"finish_reason_unspecified\": FinishReason.FINISH_REASON_UNSPECIFIED,\n    \"unspecified\": FinishReason.FINISH_REASON_UNSPECIFIED,\n    FinishReason.STOP: FinishReason.STOP,\n    1: FinishReason.STOP,",
        "detail": "google.generativeai.types.answer_types",
        "documentation": {}
    },
    {
        "label": "FinishReason",
        "kind": 5,
        "importPath": "google.generativeai.types.answer_types",
        "description": "google.generativeai.types.answer_types",
        "peekOfCode": "FinishReason = protos.Candidate.FinishReason\nFinishReasonOptions = Union[int, str, FinishReason]\n_FINISH_REASONS: dict[FinishReasonOptions, FinishReason] = {\n    FinishReason.FINISH_REASON_UNSPECIFIED: FinishReason.FINISH_REASON_UNSPECIFIED,\n    0: FinishReason.FINISH_REASON_UNSPECIFIED,\n    \"finish_reason_unspecified\": FinishReason.FINISH_REASON_UNSPECIFIED,\n    \"unspecified\": FinishReason.FINISH_REASON_UNSPECIFIED,\n    FinishReason.STOP: FinishReason.STOP,\n    1: FinishReason.STOP,\n    \"finish_reason_stop\": FinishReason.STOP,",
        "detail": "google.generativeai.types.answer_types",
        "documentation": {}
    },
    {
        "label": "FinishReasonOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.answer_types",
        "description": "google.generativeai.types.answer_types",
        "peekOfCode": "FinishReasonOptions = Union[int, str, FinishReason]\n_FINISH_REASONS: dict[FinishReasonOptions, FinishReason] = {\n    FinishReason.FINISH_REASON_UNSPECIFIED: FinishReason.FINISH_REASON_UNSPECIFIED,\n    0: FinishReason.FINISH_REASON_UNSPECIFIED,\n    \"finish_reason_unspecified\": FinishReason.FINISH_REASON_UNSPECIFIED,\n    \"unspecified\": FinishReason.FINISH_REASON_UNSPECIFIED,\n    FinishReason.STOP: FinishReason.STOP,\n    1: FinishReason.STOP,\n    \"finish_reason_stop\": FinishReason.STOP,\n    \"stop\": FinishReason.STOP,",
        "detail": "google.generativeai.types.answer_types",
        "documentation": {}
    },
    {
        "label": "TTL",
        "kind": 6,
        "importPath": "google.generativeai.types.caching_types",
        "description": "google.generativeai.types.caching_types",
        "peekOfCode": "class TTL(TypedDict):\n    # Represents datetime.datetime.now() + desired ttl\n    seconds: int\n    nanos: int\nclass ExpireTime(TypedDict):\n    # Represents seconds of UTC time since Unix epoch\n    seconds: int\n    nanos: int\nTTLTypes = Union[TTL, int, datetime.timedelta]\nExpireTimeTypes = Union[ExpireTime, int, datetime.datetime]",
        "detail": "google.generativeai.types.caching_types",
        "documentation": {}
    },
    {
        "label": "ExpireTime",
        "kind": 6,
        "importPath": "google.generativeai.types.caching_types",
        "description": "google.generativeai.types.caching_types",
        "peekOfCode": "class ExpireTime(TypedDict):\n    # Represents seconds of UTC time since Unix epoch\n    seconds: int\n    nanos: int\nTTLTypes = Union[TTL, int, datetime.timedelta]\nExpireTimeTypes = Union[ExpireTime, int, datetime.datetime]\ndef to_optional_ttl(ttl: TTLTypes | None) -> TTL | None:\n    if ttl is None:\n        return None\n    elif isinstance(ttl, datetime.timedelta):",
        "detail": "google.generativeai.types.caching_types",
        "documentation": {}
    },
    {
        "label": "to_optional_ttl",
        "kind": 2,
        "importPath": "google.generativeai.types.caching_types",
        "description": "google.generativeai.types.caching_types",
        "peekOfCode": "def to_optional_ttl(ttl: TTLTypes | None) -> TTL | None:\n    if ttl is None:\n        return None\n    elif isinstance(ttl, datetime.timedelta):\n        return {\n            \"seconds\": int(ttl.total_seconds()),\n            \"nanos\": int(ttl.microseconds * 1000),\n        }\n    elif isinstance(ttl, dict):\n        return ttl",
        "detail": "google.generativeai.types.caching_types",
        "documentation": {}
    },
    {
        "label": "to_optional_expire_time",
        "kind": 2,
        "importPath": "google.generativeai.types.caching_types",
        "description": "google.generativeai.types.caching_types",
        "peekOfCode": "def to_optional_expire_time(expire_time: ExpireTimeTypes | None) -> ExpireTime | None:\n    if expire_time is None:\n        return expire_time\n    elif isinstance(expire_time, datetime.datetime):\n        timestamp = expire_time.timestamp()\n        seconds = int(timestamp)\n        nanos = int((seconds % 1) * 1000)\n        return {\n            \"seconds\": seconds,\n            \"nanos\": nanos,",
        "detail": "google.generativeai.types.caching_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.caching_types",
        "description": "google.generativeai.types.caching_types",
        "peekOfCode": "__all__ = [\n    \"ExpireTime\",\n    \"TTL\",\n    \"TTLTypes\",\n    \"ExpireTimeTypes\",\n]\nclass TTL(TypedDict):\n    # Represents datetime.datetime.now() + desired ttl\n    seconds: int\n    nanos: int",
        "detail": "google.generativeai.types.caching_types",
        "documentation": {}
    },
    {
        "label": "TTLTypes",
        "kind": 5,
        "importPath": "google.generativeai.types.caching_types",
        "description": "google.generativeai.types.caching_types",
        "peekOfCode": "TTLTypes = Union[TTL, int, datetime.timedelta]\nExpireTimeTypes = Union[ExpireTime, int, datetime.datetime]\ndef to_optional_ttl(ttl: TTLTypes | None) -> TTL | None:\n    if ttl is None:\n        return None\n    elif isinstance(ttl, datetime.timedelta):\n        return {\n            \"seconds\": int(ttl.total_seconds()),\n            \"nanos\": int(ttl.microseconds * 1000),\n        }",
        "detail": "google.generativeai.types.caching_types",
        "documentation": {}
    },
    {
        "label": "ExpireTimeTypes",
        "kind": 5,
        "importPath": "google.generativeai.types.caching_types",
        "description": "google.generativeai.types.caching_types",
        "peekOfCode": "ExpireTimeTypes = Union[ExpireTime, int, datetime.datetime]\ndef to_optional_ttl(ttl: TTLTypes | None) -> TTL | None:\n    if ttl is None:\n        return None\n    elif isinstance(ttl, datetime.timedelta):\n        return {\n            \"seconds\": int(ttl.total_seconds()),\n            \"nanos\": int(ttl.microseconds * 1000),\n        }\n    elif isinstance(ttl, dict):",
        "detail": "google.generativeai.types.caching_types",
        "documentation": {}
    },
    {
        "label": "CitationSourceDict",
        "kind": 6,
        "importPath": "google.generativeai.types.citation_types",
        "description": "google.generativeai.types.citation_types",
        "peekOfCode": "class CitationSourceDict(TypedDict):\n    start_index: int | None\n    end_index: int | None\n    uri: str | None\n    license: str | None\n    __doc__ = string_utils.strip_oneof(protos.CitationSource.__doc__)\nclass CitationMetadataDict(TypedDict):\n    citation_sources: List[CitationSourceDict | None]\n    __doc__ = string_utils.strip_oneof(protos.CitationMetadata.__doc__)",
        "detail": "google.generativeai.types.citation_types",
        "documentation": {}
    },
    {
        "label": "CitationMetadataDict",
        "kind": 6,
        "importPath": "google.generativeai.types.citation_types",
        "description": "google.generativeai.types.citation_types",
        "peekOfCode": "class CitationMetadataDict(TypedDict):\n    citation_sources: List[CitationSourceDict | None]\n    __doc__ = string_utils.strip_oneof(protos.CitationMetadata.__doc__)",
        "detail": "google.generativeai.types.citation_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.citation_types",
        "description": "google.generativeai.types.citation_types",
        "peekOfCode": "__all__ = [\n    \"CitationMetadataDict\",\n    \"CitationSourceDict\",\n]\nclass CitationSourceDict(TypedDict):\n    start_index: int | None\n    end_index: int | None\n    uri: str | None\n    license: str | None\n    __doc__ = string_utils.strip_oneof(protos.CitationSource.__doc__)",
        "detail": "google.generativeai.types.citation_types",
        "documentation": {}
    },
    {
        "label": "BlobDict",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class BlobDict(TypedDict):\n    mime_type: str\n    data: bytes\ndef _convert_dict(d: Mapping) -> protos.Content | protos.Part | protos.Blob:\n    if is_content_dict(d):\n        content = dict(d)\n        if isinstance(parts := content[\"parts\"], str):\n            content[\"parts\"] = [parts]\n        content[\"parts\"] = [to_part(part) for part in content[\"parts\"]]\n        return protos.Content(content)",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "PartDict",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class PartDict(TypedDict):\n    text: str\n    inline_data: BlobType\n# When you need a `Part` accept a part object, part-dict, blob or string\nPartType = Union[\n    protos.Part,\n    PartDict,\n    BlobType,\n    str,\n    protos.FunctionCall,",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "ContentDict",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class ContentDict(TypedDict):\n    parts: list[PartType]\n    role: str\ndef is_content_dict(d):\n    return \"parts\" in d\n# When you need a message accept a `Content` object or dict, a list of parts,\n# or a single part\nContentType = Union[protos.Content, ContentDict, Iterable[PartType], PartType]\n# For generate_content, we're not guessing roles for [[parts],[parts],[parts]] yet.\nStrictContentType = Union[protos.Content, ContentDict]",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "FunctionDeclaration",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class FunctionDeclaration:\n    def __init__(self, *, name: str, description: str, parameters: dict[str, Any] | None = None):\n        \"\"\"A  class wrapping a `protos.FunctionDeclaration`, describes a function for `genai.GenerativeModel`'s `tools`.\"\"\"\n        self._proto = protos.FunctionDeclaration(\n            name=name, description=description, parameters=_rename_schema_fields(parameters)\n        )\n    @property\n    def name(self) -> str:\n        return self._proto.name\n    @property",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "CallableFunctionDeclaration",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class CallableFunctionDeclaration(FunctionDeclaration):\n    \"\"\"An extension of `FunctionDeclaration` that can be built from a python function, and is callable.\n    Note: The python function must have type annotations.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        name: str,\n        description: str,\n        parameters: dict[str, Any] | None = None,",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "Tool",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class Tool:\n    \"\"\"A wrapper for `protos.Tool`, Contains a collection of related `FunctionDeclaration` objects.\"\"\"\n    def __init__(self, function_declarations: Iterable[FunctionDeclarationType]):\n        # The main path doesn't use this but is seems useful.\n        self._function_declarations = [_make_function_declaration(f) for f in function_declarations]\n        self._index = {}\n        for fd in self._function_declarations:\n            name = fd.name\n            if name in self._index:\n                raise ValueError(\"\")",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "ToolDict",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class ToolDict(TypedDict):\n    function_declarations: list[FunctionDeclarationType]\nToolType = Union[\n    Tool, protos.Tool, ToolDict, Iterable[FunctionDeclarationType], FunctionDeclarationType\n]\ndef _make_tool(tool: ToolType) -> Tool:\n    if isinstance(tool, Tool):\n        return tool\n    elif isinstance(tool, protos.Tool):\n        return Tool(function_declarations=tool.function_declarations)",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "FunctionLibrary",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class FunctionLibrary:\n    \"\"\"A container for a set of `Tool` objects, manages lookup and execution of their functions.\"\"\"\n    def __init__(self, tools: Iterable[ToolType]):\n        tools = _make_tools(tools)\n        self._tools = list(tools)\n        self._index = {}\n        for tool in self._tools:\n            for declaration in tool.function_declarations:\n                name = declaration.name\n                if name in self._index:",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "FunctionCallingConfigDict",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class FunctionCallingConfigDict(TypedDict):\n    mode: FunctionCallingModeType\n    allowed_function_names: list[str]\nFunctionCallingConfigType = Union[\n    FunctionCallingModeType, FunctionCallingConfigDict, protos.FunctionCallingConfig\n]\ndef to_function_calling_config(obj: FunctionCallingConfigType) -> protos.FunctionCallingConfig:\n    if isinstance(obj, protos.FunctionCallingConfig):\n        return obj\n    elif isinstance(obj, (FunctionCallingMode, str, int)):",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "ToolConfigDict",
        "kind": 6,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "class ToolConfigDict:\n    function_calling_config: FunctionCallingConfigType\nToolConfigType = Union[ToolConfigDict, protos.ToolConfig]\ndef to_tool_config(obj: ToolConfigType) -> protos.ToolConfig:\n    if isinstance(obj, protos.ToolConfig):\n        return obj\n    elif isinstance(obj, dict):\n        fcc = obj.pop(\"function_calling_config\")\n        fcc = to_function_calling_config(fcc)\n        obj[\"function_calling_config\"] = fcc",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "pil_to_blob",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def pil_to_blob(img):\n    bytesio = io.BytesIO()\n    if isinstance(img, PIL.PngImagePlugin.PngImageFile) or img.mode == \"RGBA\":\n        img.save(bytesio, format=\"PNG\")\n        mime_type = \"image/png\"\n    else:\n        img.save(bytesio, format=\"JPEG\")\n        mime_type = \"image/jpeg\"\n    bytesio.seek(0)\n    data = bytesio.read()",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "image_to_blob",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def image_to_blob(image) -> protos.Blob:\n    if PIL is not None:\n        if isinstance(image, PIL.Image.Image):\n            return pil_to_blob(image)\n    if IPython is not None:\n        if isinstance(image, IPython.display.Image):\n            name = image.filename\n            if name is None:\n                raise ValueError(\n                    \"Conversion failed. The `IPython.display.Image` can only be converted if \"",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "is_blob_dict",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def is_blob_dict(d):\n    return \"mime_type\" in d and \"data\" in d\nif typing.TYPE_CHECKING:\n    BlobType = Union[\n        protos.Blob, BlobDict, PIL.Image.Image, IPython.display.Image\n    ]  # Any for the images\nelse:\n    BlobType = Union[protos.Blob, BlobDict, Any]\ndef to_blob(blob: BlobType) -> protos.Blob:\n    if isinstance(blob, Mapping):",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "to_blob",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def to_blob(blob: BlobType) -> protos.Blob:\n    if isinstance(blob, Mapping):\n        blob = _convert_dict(blob)\n    if isinstance(blob, protos.Blob):\n        return blob\n    elif isinstance(blob, IMAGE_TYPES):\n        return image_to_blob(blob)\n    else:\n        if isinstance(blob, Mapping):\n            raise KeyError(",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "is_part_dict",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def is_part_dict(d):\n    keys = list(d.keys())\n    if len(keys) != 1:\n        return False\n    key = keys[0]\n    return key in [\"text\", \"inline_data\", \"function_call\", \"function_response\", \"file_data\"]\ndef to_part(part: PartType):\n    if isinstance(part, Mapping):\n        part = _convert_dict(part)\n    if isinstance(part, protos.Part):",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "to_part",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def to_part(part: PartType):\n    if isinstance(part, Mapping):\n        part = _convert_dict(part)\n    if isinstance(part, protos.Part):\n        return part\n    elif isinstance(part, str):\n        return protos.Part(text=part)\n    elif isinstance(part, protos.FileData):\n        return protos.Part(file_data=part)\n    elif isinstance(part, (protos.File, file_types.File)):",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "is_content_dict",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def is_content_dict(d):\n    return \"parts\" in d\n# When you need a message accept a `Content` object or dict, a list of parts,\n# or a single part\nContentType = Union[protos.Content, ContentDict, Iterable[PartType], PartType]\n# For generate_content, we're not guessing roles for [[parts],[parts],[parts]] yet.\nStrictContentType = Union[protos.Content, ContentDict]\ndef to_content(content: ContentType):\n    if not content:\n        raise ValueError(",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "to_content",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def to_content(content: ContentType):\n    if not content:\n        raise ValueError(\n            \"Invalid input: 'content' argument must not be empty. Please provide a non-empty value.\"\n        )\n    if isinstance(content, Mapping):\n        content = _convert_dict(content)\n    if isinstance(content, protos.Content):\n        return content\n    elif isinstance(content, Iterable) and not isinstance(content, str):",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "strict_to_content",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def strict_to_content(content: StrictContentType):\n    if isinstance(content, Mapping):\n        content = _convert_dict(content)\n    if isinstance(content, protos.Content):\n        return content\n    else:\n        raise TypeError(\n            \"Invalid input type. Expected a `protos.Content` or a `dict` with a 'parts' key.\\n\"\n            f\"However, received an object of type: {type(content)}.\\n\"\n            f\"Object Value: {content}\"",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "to_contents",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def to_contents(contents: ContentsType) -> list[protos.Content]:\n    if contents is None:\n        return []\n    if isinstance(contents, Iterable) and not isinstance(contents, (str, Mapping)):\n        try:\n            # strict_to_content so [[parts], [parts]] doesn't assume roles.\n            contents = [strict_to_content(c) for c in contents]\n            return contents\n        except TypeError:\n            # If you get a TypeError here it's probably because that was a list",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "unpack_defs",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def unpack_defs(schema, defs):\n    properties = schema[\"properties\"]\n    for name, value in properties.items():\n        ref_key = value.get(\"$ref\", None)\n        if ref_key is not None:\n            ref = defs[ref_key.split(\"defs/\")[-1]]\n            unpack_defs(ref, defs)\n            properties[name] = ref\n            continue\n        anyof = value.get(\"anyOf\", None)",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "strip_titles",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def strip_titles(schema):\n    title = schema.pop(\"title\", None)\n    properties = schema.get(\"properties\", None)\n    if properties is not None:\n        for name, value in properties.items():\n            strip_titles(value)\n    items = schema.get(\"items\", None)\n    if items is not None:\n        strip_titles(items)\ndef add_object_type(schema):",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "add_object_type",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def add_object_type(schema):\n    properties = schema.get(\"properties\", None)\n    if properties is not None:\n        schema.pop(\"required\", None)\n        schema[\"type\"] = \"object\"\n        for name, value in properties.items():\n            add_object_type(value)\n    items = schema.get(\"items\", None)\n    if items is not None:\n        add_object_type(items)",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "convert_to_nullable",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def convert_to_nullable(schema):\n    anyof = schema.pop(\"anyOf\", None)\n    if anyof is not None:\n        if len(anyof) != 2:\n            raise ValueError(\n                \"Invalid input: Type Unions are not supported, except for `Optional` types. \"\n                \"Please provide an `Optional` type or a non-Union type.\"\n            )\n        a, b = anyof\n        if a == {\"type\": \"null\"}:",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "to_function_library",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def to_function_library(lib: FunctionLibraryType | None) -> FunctionLibrary | None:\n    if lib is None:\n        return lib\n    elif isinstance(lib, FunctionLibrary):\n        return lib\n    else:\n        return FunctionLibrary(tools=lib)\nFunctionCallingMode = protos.FunctionCallingConfig.Mode\n# fmt: off\n_FUNCTION_CALLING_MODE = {",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "to_function_calling_mode",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def to_function_calling_mode(x: FunctionCallingModeType) -> FunctionCallingMode:\n    if isinstance(x, str):\n        x = x.lower()\n    return _FUNCTION_CALLING_MODE[x]\nclass FunctionCallingConfigDict(TypedDict):\n    mode: FunctionCallingModeType\n    allowed_function_names: list[str]\nFunctionCallingConfigType = Union[\n    FunctionCallingModeType, FunctionCallingConfigDict, protos.FunctionCallingConfig\n]",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "to_function_calling_config",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def to_function_calling_config(obj: FunctionCallingConfigType) -> protos.FunctionCallingConfig:\n    if isinstance(obj, protos.FunctionCallingConfig):\n        return obj\n    elif isinstance(obj, (FunctionCallingMode, str, int)):\n        obj = {\"mode\": to_function_calling_mode(obj)}\n    elif isinstance(obj, dict):\n        obj = obj.copy()\n        mode = obj.pop(\"mode\")\n        obj[\"mode\"] = to_function_calling_mode(mode)\n    else:",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "to_tool_config",
        "kind": 2,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "def to_tool_config(obj: ToolConfigType) -> protos.ToolConfig:\n    if isinstance(obj, protos.ToolConfig):\n        return obj\n    elif isinstance(obj, dict):\n        fcc = obj.pop(\"function_calling_config\")\n        fcc = to_function_calling_config(fcc)\n        obj[\"function_calling_config\"] = fcc\n        return protos.ToolConfig(**obj)\n    else:\n        raise TypeError(",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "__all__ = [\n    \"BlobDict\",\n    \"BlobType\",\n    \"PartDict\",\n    \"PartType\",\n    \"ContentDict\",\n    \"ContentType\",\n    \"StrictContentType\",\n    \"ContentsType\",\n    \"FunctionDeclaration\",",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "PartType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "PartType = Union[\n    protos.Part,\n    PartDict,\n    BlobType,\n    str,\n    protos.FunctionCall,\n    protos.FunctionResponse,\n    file_types.FileDataType,\n]\ndef is_part_dict(d):",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "ContentType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "ContentType = Union[protos.Content, ContentDict, Iterable[PartType], PartType]\n# For generate_content, we're not guessing roles for [[parts],[parts],[parts]] yet.\nStrictContentType = Union[protos.Content, ContentDict]\ndef to_content(content: ContentType):\n    if not content:\n        raise ValueError(\n            \"Invalid input: 'content' argument must not be empty. Please provide a non-empty value.\"\n        )\n    if isinstance(content, Mapping):\n        content = _convert_dict(content)",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "StrictContentType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "StrictContentType = Union[protos.Content, ContentDict]\ndef to_content(content: ContentType):\n    if not content:\n        raise ValueError(\n            \"Invalid input: 'content' argument must not be empty. Please provide a non-empty value.\"\n        )\n    if isinstance(content, Mapping):\n        content = _convert_dict(content)\n    if isinstance(content, protos.Content):\n        return content",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "ContentsType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "ContentsType = Union[ContentType, Iterable[StrictContentType], None]\ndef to_contents(contents: ContentsType) -> list[protos.Content]:\n    if contents is None:\n        return []\n    if isinstance(contents, Iterable) and not isinstance(contents, (str, Mapping)):\n        try:\n            # strict_to_content so [[parts], [parts]] doesn't assume roles.\n            contents = [strict_to_content(c) for c in contents]\n            return contents\n        except TypeError:",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "StructType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "StructType = dict[str, \"ValueType\"]\nValueType = Union[float, str, bool, StructType, list[\"ValueType\"], None]\nclass CallableFunctionDeclaration(FunctionDeclaration):\n    \"\"\"An extension of `FunctionDeclaration` that can be built from a python function, and is callable.\n    Note: The python function must have type annotations.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        name: str,",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "ValueType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "ValueType = Union[float, str, bool, StructType, list[\"ValueType\"], None]\nclass CallableFunctionDeclaration(FunctionDeclaration):\n    \"\"\"An extension of `FunctionDeclaration` that can be built from a python function, and is callable.\n    Note: The python function must have type annotations.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        name: str,\n        description: str,",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "FunctionDeclarationType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "FunctionDeclarationType = Union[\n    FunctionDeclaration,\n    protos.FunctionDeclaration,\n    dict[str, Any],\n    Callable[..., Any],\n]\ndef _make_function_declaration(\n    fun: FunctionDeclarationType,\n) -> FunctionDeclaration | protos.FunctionDeclaration:\n    if isinstance(fun, (FunctionDeclaration, protos.FunctionDeclaration)):",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "ToolType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "ToolType = Union[\n    Tool, protos.Tool, ToolDict, Iterable[FunctionDeclarationType], FunctionDeclarationType\n]\ndef _make_tool(tool: ToolType) -> Tool:\n    if isinstance(tool, Tool):\n        return tool\n    elif isinstance(tool, protos.Tool):\n        return Tool(function_declarations=tool.function_declarations)\n    elif isinstance(tool, dict):\n        if \"function_declarations\" in tool:",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "ToolsType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "ToolsType = Union[Iterable[ToolType], ToolType]\ndef _make_tools(tools: ToolsType) -> list[Tool]:\n    if isinstance(tools, Iterable) and not isinstance(tools, Mapping):\n        tools = [_make_tool(t) for t in tools]\n        if len(tools) > 1 and all(len(t.function_declarations) == 1 for t in tools):\n            # flatten into a single tool.\n            tools = [_make_tool([t.function_declarations[0] for t in tools])]\n        return tools\n    else:\n        tool = tools",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "FunctionLibraryType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "FunctionLibraryType = Union[FunctionLibrary, ToolsType]\ndef to_function_library(lib: FunctionLibraryType | None) -> FunctionLibrary | None:\n    if lib is None:\n        return lib\n    elif isinstance(lib, FunctionLibrary):\n        return lib\n    else:\n        return FunctionLibrary(tools=lib)\nFunctionCallingMode = protos.FunctionCallingConfig.Mode\n# fmt: off",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "FunctionCallingMode",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "FunctionCallingMode = protos.FunctionCallingConfig.Mode\n# fmt: off\n_FUNCTION_CALLING_MODE = {\n    1: FunctionCallingMode.AUTO,\n    FunctionCallingMode.AUTO: FunctionCallingMode.AUTO,\n    \"mode_auto\": FunctionCallingMode.AUTO,\n    \"auto\": FunctionCallingMode.AUTO,\n    2: FunctionCallingMode.ANY,\n    FunctionCallingMode.ANY: FunctionCallingMode.ANY,\n    \"mode_any\": FunctionCallingMode.ANY,",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "_FUNCTION_CALLING_MODE",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "_FUNCTION_CALLING_MODE = {\n    1: FunctionCallingMode.AUTO,\n    FunctionCallingMode.AUTO: FunctionCallingMode.AUTO,\n    \"mode_auto\": FunctionCallingMode.AUTO,\n    \"auto\": FunctionCallingMode.AUTO,\n    2: FunctionCallingMode.ANY,\n    FunctionCallingMode.ANY: FunctionCallingMode.ANY,\n    \"mode_any\": FunctionCallingMode.ANY,\n    \"any\": FunctionCallingMode.ANY,\n    3: FunctionCallingMode.NONE,",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "FunctionCallingModeType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "FunctionCallingModeType = Union[FunctionCallingMode, str, int]\ndef to_function_calling_mode(x: FunctionCallingModeType) -> FunctionCallingMode:\n    if isinstance(x, str):\n        x = x.lower()\n    return _FUNCTION_CALLING_MODE[x]\nclass FunctionCallingConfigDict(TypedDict):\n    mode: FunctionCallingModeType\n    allowed_function_names: list[str]\nFunctionCallingConfigType = Union[\n    FunctionCallingModeType, FunctionCallingConfigDict, protos.FunctionCallingConfig",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "FunctionCallingConfigType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "FunctionCallingConfigType = Union[\n    FunctionCallingModeType, FunctionCallingConfigDict, protos.FunctionCallingConfig\n]\ndef to_function_calling_config(obj: FunctionCallingConfigType) -> protos.FunctionCallingConfig:\n    if isinstance(obj, protos.FunctionCallingConfig):\n        return obj\n    elif isinstance(obj, (FunctionCallingMode, str, int)):\n        obj = {\"mode\": to_function_calling_mode(obj)}\n    elif isinstance(obj, dict):\n        obj = obj.copy()",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "ToolConfigType",
        "kind": 5,
        "importPath": "google.generativeai.types.content_types",
        "description": "google.generativeai.types.content_types",
        "peekOfCode": "ToolConfigType = Union[ToolConfigDict, protos.ToolConfig]\ndef to_tool_config(obj: ToolConfigType) -> protos.ToolConfig:\n    if isinstance(obj, protos.ToolConfig):\n        return obj\n    elif isinstance(obj, dict):\n        fcc = obj.pop(\"function_calling_config\")\n        fcc = to_function_calling_config(fcc)\n        obj[\"function_calling_config\"] = fcc\n        return protos.ToolConfig(**obj)\n    else:",
        "detail": "google.generativeai.types.content_types",
        "documentation": {}
    },
    {
        "label": "TokenCount",
        "kind": 6,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "class TokenCount(TypedDict):\n    token_count: int\nclass MessageDict(TypedDict):\n    \"\"\"A dict representation of a `protos.Message`.\"\"\"\n    author: str\n    content: str\n    citation_metadata: Optional[citation_types.CitationMetadataDict]\nMessageOptions = Union[str, MessageDict, protos.Message]\nMESSAGE_OPTIONS = (str, dict, protos.Message)\nMessagesOptions = Union[",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "MessageDict",
        "kind": 6,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "class MessageDict(TypedDict):\n    \"\"\"A dict representation of a `protos.Message`.\"\"\"\n    author: str\n    content: str\n    citation_metadata: Optional[citation_types.CitationMetadataDict]\nMessageOptions = Union[str, MessageDict, protos.Message]\nMESSAGE_OPTIONS = (str, dict, protos.Message)\nMessagesOptions = Union[\n    MessageOptions,\n    Iterable[MessageOptions],",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "ExampleDict",
        "kind": 6,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "class ExampleDict(TypedDict):\n    \"\"\"A dict representation of a `protos.Example`.\"\"\"\n    input: MessageOptions\n    output: MessageOptions\nExampleOptions = Union[\n    Tuple[MessageOptions, MessageOptions],\n    Iterable[MessageOptions],\n    ExampleDict,\n    protos.Example,\n]",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "MessagePromptDict",
        "kind": 6,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "class MessagePromptDict(TypedDict, total=False):\n    \"\"\"A dict representation of a `protos.MessagePrompt`.\"\"\"\n    context: str\n    examples: ExamplesOptions\n    messages: MessagesOptions\nMessagePromptOptions = Union[\n    str,\n    protos.Message,\n    Iterable[Union[str, protos.Message]],\n    MessagePromptDict,",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "ResponseDict",
        "kind": 6,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "class ResponseDict(TypedDict):\n    \"\"\"A dict representation of a `protos.GenerateMessageResponse`.\"\"\"\n    messages: List[MessageDict]\n    candidates: List[MessageDict]\n@string_utils.prettyprint\n@dataclasses.dataclass(init=False)\nclass ChatResponse(abc.ABC):\n    \"\"\"A chat response from the model.\n    * Use `response.last` (settable) for easy access to the text of the last response.\n        (`messages[-1]['content']`)",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "ChatResponse",
        "kind": 6,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "class ChatResponse(abc.ABC):\n    \"\"\"A chat response from the model.\n    * Use `response.last` (settable) for easy access to the text of the last response.\n        (`messages[-1]['content']`)\n    * Use `response.messages` to access the message history (including `.last`).\n    * Use `response.candidates` to access all the responses generated by the model.\n    Other attributes are just saved from the arguments to `genai.chat`, so you\n    can easily continue a conversation:\n    ```\n    import google.generativeai as genai",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "AuthorError",
        "kind": 6,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "class AuthorError(Exception):\n    \"\"\"Raised by the `chat` (or `reply`) functions when the author list can't be normalized.\"\"\"\n    pass",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "__all__ = [\n    \"MessageDict\",\n    \"MessageOptions\",\n    \"MessagesOptions\",\n    \"ExampleDict\",\n    \"ExampleOptions\",\n    \"ExamplesOptions\",\n    \"MessagePromptDict\",\n    \"MessagePromptOptions\",\n    \"ResponseDict\",",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "MessageOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "MessageOptions = Union[str, MessageDict, protos.Message]\nMESSAGE_OPTIONS = (str, dict, protos.Message)\nMessagesOptions = Union[\n    MessageOptions,\n    Iterable[MessageOptions],\n]\nMESSAGES_OPTIONS = (MESSAGE_OPTIONS, Iterable)\nclass ExampleDict(TypedDict):\n    \"\"\"A dict representation of a `protos.Example`.\"\"\"\n    input: MessageOptions",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "MESSAGE_OPTIONS",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "MESSAGE_OPTIONS = (str, dict, protos.Message)\nMessagesOptions = Union[\n    MessageOptions,\n    Iterable[MessageOptions],\n]\nMESSAGES_OPTIONS = (MESSAGE_OPTIONS, Iterable)\nclass ExampleDict(TypedDict):\n    \"\"\"A dict representation of a `protos.Example`.\"\"\"\n    input: MessageOptions\n    output: MessageOptions",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "MessagesOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "MessagesOptions = Union[\n    MessageOptions,\n    Iterable[MessageOptions],\n]\nMESSAGES_OPTIONS = (MESSAGE_OPTIONS, Iterable)\nclass ExampleDict(TypedDict):\n    \"\"\"A dict representation of a `protos.Example`.\"\"\"\n    input: MessageOptions\n    output: MessageOptions\nExampleOptions = Union[",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "MESSAGES_OPTIONS",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "MESSAGES_OPTIONS = (MESSAGE_OPTIONS, Iterable)\nclass ExampleDict(TypedDict):\n    \"\"\"A dict representation of a `protos.Example`.\"\"\"\n    input: MessageOptions\n    output: MessageOptions\nExampleOptions = Union[\n    Tuple[MessageOptions, MessageOptions],\n    Iterable[MessageOptions],\n    ExampleDict,\n    protos.Example,",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "ExampleOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "ExampleOptions = Union[\n    Tuple[MessageOptions, MessageOptions],\n    Iterable[MessageOptions],\n    ExampleDict,\n    protos.Example,\n]\nEXAMPLE_OPTIONS = (protos.Example, dict, Iterable)\nExamplesOptions = Union[ExampleOptions, Iterable[ExampleOptions]]\nclass MessagePromptDict(TypedDict, total=False):\n    \"\"\"A dict representation of a `protos.MessagePrompt`.\"\"\"",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "EXAMPLE_OPTIONS",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "EXAMPLE_OPTIONS = (protos.Example, dict, Iterable)\nExamplesOptions = Union[ExampleOptions, Iterable[ExampleOptions]]\nclass MessagePromptDict(TypedDict, total=False):\n    \"\"\"A dict representation of a `protos.MessagePrompt`.\"\"\"\n    context: str\n    examples: ExamplesOptions\n    messages: MessagesOptions\nMessagePromptOptions = Union[\n    str,\n    protos.Message,",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "ExamplesOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "ExamplesOptions = Union[ExampleOptions, Iterable[ExampleOptions]]\nclass MessagePromptDict(TypedDict, total=False):\n    \"\"\"A dict representation of a `protos.MessagePrompt`.\"\"\"\n    context: str\n    examples: ExamplesOptions\n    messages: MessagesOptions\nMessagePromptOptions = Union[\n    str,\n    protos.Message,\n    Iterable[Union[str, protos.Message]],",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "MessagePromptOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "MessagePromptOptions = Union[\n    str,\n    protos.Message,\n    Iterable[Union[str, protos.Message]],\n    MessagePromptDict,\n    protos.MessagePrompt,\n]\nMESSAGE_PROMPT_KEYS = {\"context\", \"examples\", \"messages\"}\nclass ResponseDict(TypedDict):\n    \"\"\"A dict representation of a `protos.GenerateMessageResponse`.\"\"\"",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "MESSAGE_PROMPT_KEYS",
        "kind": 5,
        "importPath": "google.generativeai.types.discuss_types",
        "description": "google.generativeai.types.discuss_types",
        "peekOfCode": "MESSAGE_PROMPT_KEYS = {\"context\", \"examples\", \"messages\"}\nclass ResponseDict(TypedDict):\n    \"\"\"A dict representation of a `protos.GenerateMessageResponse`.\"\"\"\n    messages: List[MessageDict]\n    candidates: List[MessageDict]\n@string_utils.prettyprint\n@dataclasses.dataclass(init=False)\nclass ChatResponse(abc.ABC):\n    \"\"\"A chat response from the model.\n    * Use `response.last` (settable) for easy access to the text of the last response.",
        "detail": "google.generativeai.types.discuss_types",
        "documentation": {}
    },
    {
        "label": "File",
        "kind": 6,
        "importPath": "google.generativeai.types.file_types",
        "description": "google.generativeai.types.file_types",
        "peekOfCode": "class File:\n    def __init__(self, proto: protos.File | File | dict):\n        if isinstance(proto, File):\n            proto = proto.to_proto()\n        self._proto = protos.File(proto)\n    def to_proto(self) -> protos.File:\n        return self._proto\n    @property\n    def name(self) -> str:\n        return self._proto.name",
        "detail": "google.generativeai.types.file_types",
        "documentation": {}
    },
    {
        "label": "FileDataDict",
        "kind": 6,
        "importPath": "google.generativeai.types.file_types",
        "description": "google.generativeai.types.file_types",
        "peekOfCode": "class FileDataDict(TypedDict):\n    mime_type: str\n    file_uri: str\nFileDataType = Union[FileDataDict, protos.FileData, protos.File, File]\ndef to_file_data(file_data: FileDataType):\n    if isinstance(file_data, dict):\n        if \"file_uri\" in file_data:\n            file_data = protos.FileData(file_data)\n        else:\n            file_data = protos.File(file_data)",
        "detail": "google.generativeai.types.file_types",
        "documentation": {}
    },
    {
        "label": "to_file_data",
        "kind": 2,
        "importPath": "google.generativeai.types.file_types",
        "description": "google.generativeai.types.file_types",
        "peekOfCode": "def to_file_data(file_data: FileDataType):\n    if isinstance(file_data, dict):\n        if \"file_uri\" in file_data:\n            file_data = protos.FileData(file_data)\n        else:\n            file_data = protos.File(file_data)\n    if isinstance(file_data, File):\n        file_data = file_data.to_proto()\n    if isinstance(file_data, protos.File):\n        file_data = protos.FileData(",
        "detail": "google.generativeai.types.file_types",
        "documentation": {}
    },
    {
        "label": "FileDataType",
        "kind": 5,
        "importPath": "google.generativeai.types.file_types",
        "description": "google.generativeai.types.file_types",
        "peekOfCode": "FileDataType = Union[FileDataDict, protos.FileData, protos.File, File]\ndef to_file_data(file_data: FileDataType):\n    if isinstance(file_data, dict):\n        if \"file_uri\" in file_data:\n            file_data = protos.FileData(file_data)\n        else:\n            file_data = protos.File(file_data)\n    if isinstance(file_data, File):\n        file_data = file_data.to_proto()\n    if isinstance(file_data, protos.File):",
        "detail": "google.generativeai.types.file_types",
        "documentation": {}
    },
    {
        "label": "BlockedPromptException",
        "kind": 6,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "class BlockedPromptException(Exception):\n    pass\nclass StopCandidateException(Exception):\n    pass\nclass IncompleteIterationError(Exception):\n    pass\nclass BrokenResponseError(Exception):\n    pass\nclass GenerationConfigDict(TypedDict, total=False):\n    # TODO(markdaoust): Python 3.11+ use `NotRequired`, ref: https://peps.python.org/pep-0655/",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "StopCandidateException",
        "kind": 6,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "class StopCandidateException(Exception):\n    pass\nclass IncompleteIterationError(Exception):\n    pass\nclass BrokenResponseError(Exception):\n    pass\nclass GenerationConfigDict(TypedDict, total=False):\n    # TODO(markdaoust): Python 3.11+ use `NotRequired`, ref: https://peps.python.org/pep-0655/\n    candidate_count: int\n    stop_sequences: Iterable[str]",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "IncompleteIterationError",
        "kind": 6,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "class IncompleteIterationError(Exception):\n    pass\nclass BrokenResponseError(Exception):\n    pass\nclass GenerationConfigDict(TypedDict, total=False):\n    # TODO(markdaoust): Python 3.11+ use `NotRequired`, ref: https://peps.python.org/pep-0655/\n    candidate_count: int\n    stop_sequences: Iterable[str]\n    max_output_tokens: int\n    temperature: float",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "BrokenResponseError",
        "kind": 6,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "class BrokenResponseError(Exception):\n    pass\nclass GenerationConfigDict(TypedDict, total=False):\n    # TODO(markdaoust): Python 3.11+ use `NotRequired`, ref: https://peps.python.org/pep-0655/\n    candidate_count: int\n    stop_sequences: Iterable[str]\n    max_output_tokens: int\n    temperature: float\n    response_mime_type: str\n    response_schema: protos.Schema | Mapping[str, Any]  # fmt: off",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "GenerationConfigDict",
        "kind": 6,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "class GenerationConfigDict(TypedDict, total=False):\n    # TODO(markdaoust): Python 3.11+ use `NotRequired`, ref: https://peps.python.org/pep-0655/\n    candidate_count: int\n    stop_sequences: Iterable[str]\n    max_output_tokens: int\n    temperature: float\n    response_mime_type: str\n    response_schema: protos.Schema | Mapping[str, Any]  # fmt: off\n@dataclasses.dataclass\nclass GenerationConfig:",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "GenerationConfig",
        "kind": 6,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "class GenerationConfig:\n    \"\"\"A simple dataclass used to configure the generation parameters of `GenerativeModel.generate_content`.\n    Attributes:\n        candidate_count:\n            Number of generated responses to return.\n        stop_sequences:\n            The set of character sequences (up\n            to 5) that will stop output generation. If\n            specified, the API will stop at the first\n            appearance of a stop sequence. The stop sequence",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "BaseGenerateContentResponse",
        "kind": 6,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "class BaseGenerateContentResponse:\n    def __init__(\n        self,\n        done: bool,\n        iterator: (\n            None\n            | Iterable[protos.GenerateContentResponse]\n            | AsyncIterable[protos.GenerateContentResponse]\n        ),\n        result: protos.GenerateContentResponse,",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "GenerateContentResponse",
        "kind": 6,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "class GenerateContentResponse(BaseGenerateContentResponse):\n    @classmethod\n    def from_iterator(cls, iterator: Iterable[protos.GenerateContentResponse]):\n        iterator = iter(iterator)\n        with rewrite_stream_error():\n            response = next(iterator)\n        return cls(\n            done=False,\n            iterator=iterator,\n            result=response,",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "AsyncGenerateContentResponse",
        "kind": 6,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "class AsyncGenerateContentResponse(BaseGenerateContentResponse):\n    @classmethod\n    async def from_aiterator(cls, iterator: AsyncIterable[protos.GenerateContentResponse]):\n        iterator = aiter(iterator)  # type: ignore\n        with rewrite_stream_error():\n            response = await anext(iterator)  # type: ignore\n        return cls(\n            done=False,\n            iterator=iterator,\n            result=response,",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "to_generation_config_dict",
        "kind": 2,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "def to_generation_config_dict(generation_config: GenerationConfigType):\n    if generation_config is None:\n        return {}\n    elif isinstance(generation_config, protos.GenerationConfig):\n        schema = generation_config.response_schema\n        generation_config = type(generation_config).to_dict(\n            generation_config\n        )  # pytype: disable=attribute-error\n        generation_config[\"response_schema\"] = schema\n        return generation_config",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "rewrite_stream_error",
        "kind": 2,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "def rewrite_stream_error():\n    try:\n        yield\n    except (google.protobuf.json_format.ParseError, AttributeError) as e:\n        raise google.api_core.exceptions.BadRequest(\n            \"Unknown error trying to retrieve streaming response. \"\n            \"Please retry with `stream=False` for more details.\"\n        )\nGENERATE_CONTENT_RESPONSE_DOC = \"\"\"Instances of this class manage the response of the `generate_content` method.\n    These are returned by `GenerativeModel.generate_content` and `ChatSession.send_message`.",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "__all__ = [\n    \"AsyncGenerateContentResponse\",\n    \"BlockedPromptException\",\n    \"StopCandidateException\",\n    \"IncompleteIterationError\",\n    \"BrokenResponseError\",\n    \"GenerationConfigDict\",\n    \"GenerationConfigType\",\n    \"GenerationConfig\",\n    \"GenerateContentResponse\",",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "GenerationConfigType",
        "kind": 5,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "GenerationConfigType = Union[protos.GenerationConfig, GenerationConfigDict, GenerationConfig]\ndef _normalize_schema(generation_config):\n    # Convert response_schema to protos.Schema for request\n    response_schema = generation_config.get(\"response_schema\", None)\n    if response_schema is None:\n        return\n    if isinstance(response_schema, protos.Schema):\n        return\n    if isinstance(response_schema, type):\n        response_schema = content_types._schema_for_class(response_schema)",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "_INCOMPLETE_ITERATION_MESSAGE",
        "kind": 5,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "_INCOMPLETE_ITERATION_MESSAGE = \"\"\"\\\nPlease let the response complete iteration before accessing the final accumulated\nattributes (or call `response.resolve()`)\"\"\"\nclass BaseGenerateContentResponse:\n    def __init__(\n        self,\n        done: bool,\n        iterator: (\n            None\n            | Iterable[protos.GenerateContentResponse]",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "GENERATE_CONTENT_RESPONSE_DOC",
        "kind": 5,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "GENERATE_CONTENT_RESPONSE_DOC = \"\"\"Instances of this class manage the response of the `generate_content` method.\n    These are returned by `GenerativeModel.generate_content` and `ChatSession.send_message`.\n    This object is based on the low level `protos.GenerateContentResponse` class which just has `prompt_feedback`\n    and `candidates` attributes. This class adds several quick accessors for common use cases.\n    The same object type is returned for both `stream=True/False`.\n    ### Streaming\n    When you pass `stream=True` to `GenerativeModel.generate_content` or `ChatSession.send_message`,\n    iterate over this object to receive chunks of the response:\n    ```\n    response = model.generate_content(..., stream=True):",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "ASYNC_GENERATE_CONTENT_RESPONSE_DOC",
        "kind": 5,
        "importPath": "google.generativeai.types.generation_types",
        "description": "google.generativeai.types.generation_types",
        "peekOfCode": "ASYNC_GENERATE_CONTENT_RESPONSE_DOC = (\n    \"\"\"This is the async version of `genai.GenerateContentResponse`.\"\"\"\n)\n@string_utils.set_doc(GENERATE_CONTENT_RESPONSE_DOC)\nclass GenerateContentResponse(BaseGenerateContentResponse):\n    @classmethod\n    def from_iterator(cls, iterator: Iterable[protos.GenerateContentResponse]):\n        iterator = iter(iterator)\n        with rewrite_stream_error():\n            response = next(iterator)",
        "detail": "google.generativeai.types.generation_types",
        "documentation": {}
    },
    {
        "label": "RequestOptionsDict",
        "kind": 6,
        "importPath": "google.generativeai.types.helper_types",
        "description": "google.generativeai.types.helper_types",
        "peekOfCode": "class RequestOptionsDict(TypedDict, total=False):\n    retry: google.api_core.retry.Retry\n    timeout: Union[int, float, google.api_core.timeout.TimeToDeadlineTimeout]\n@dataclasses.dataclass(init=False)\nclass RequestOptions(collections.abc.Mapping):\n    \"\"\"Request options\n    >>> import google.generativeai as genai\n    >>> from google.generativeai.types import RequestOptions\n    >>> from google.api_core import retry\n    >>>",
        "detail": "google.generativeai.types.helper_types",
        "documentation": {}
    },
    {
        "label": "RequestOptions",
        "kind": 6,
        "importPath": "google.generativeai.types.helper_types",
        "description": "google.generativeai.types.helper_types",
        "peekOfCode": "class RequestOptions(collections.abc.Mapping):\n    \"\"\"Request options\n    >>> import google.generativeai as genai\n    >>> from google.generativeai.types import RequestOptions\n    >>> from google.api_core import retry\n    >>>\n    >>> model = genai.GenerativeModel()\n    >>> response = model.generate_content('Hello',\n    ...     request_options=RequestOptions(\n    ...         retry=retry.Retry(initial=10, multiplier=2, maximum=60, timeout=300)))",
        "detail": "google.generativeai.types.helper_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.helper_types",
        "description": "google.generativeai.types.helper_types",
        "peekOfCode": "__all__ = [\"RequestOptions\", \"RequestOptionsType\"]\nclass RequestOptionsDict(TypedDict, total=False):\n    retry: google.api_core.retry.Retry\n    timeout: Union[int, float, google.api_core.timeout.TimeToDeadlineTimeout]\n@dataclasses.dataclass(init=False)\nclass RequestOptions(collections.abc.Mapping):\n    \"\"\"Request options\n    >>> import google.generativeai as genai\n    >>> from google.generativeai.types import RequestOptions\n    >>> from google.api_core import retry",
        "detail": "google.generativeai.types.helper_types",
        "documentation": {}
    },
    {
        "label": "RequestOptionsType",
        "kind": 5,
        "importPath": "google.generativeai.types.helper_types",
        "description": "google.generativeai.types.helper_types",
        "peekOfCode": "RequestOptionsType = Union[RequestOptions, RequestOptionsDict]",
        "detail": "google.generativeai.types.helper_types",
        "documentation": {}
    },
    {
        "label": "Model",
        "kind": 6,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "class Model:\n    \"\"\"A dataclass representation of a `protos.Model`.\n    Attributes:\n        name: The resource name of the `Model`. Format: `models/{model}` with a `{model}` naming\n           convention of: \"{base_model_id}-{version}\". For example: `models/chat-bison-001`.\n        base_model_id: The base name of the model. For example: `chat-bison`.\n        version:  The major version number of the model. For example: `001`.\n        display_name: The human-readable name of the model. E.g. `\"Chat Bison\"`. The name can be up\n           to 128 characters long and can consist of any UTF-8 characters.\n        description: A short description of the model.",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TunedModel",
        "kind": 6,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "class TunedModel:\n    \"\"\"A dataclass representation of a `protos.TunedModel`.\"\"\"\n    name: str | None = None\n    source_model: str | None = None\n    base_model: str | None = None\n    display_name: str = \"\"\n    description: str = \"\"\n    temperature: float | None = None\n    top_p: float | None = None\n    top_k: float | None = None",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TuningTask",
        "kind": 6,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "class TuningTask:\n    start_time: datetime.datetime | None = None\n    complete_time: datetime.datetime | None = None\n    snapshots: list[TuningSnapshot] = dataclasses.field(default_factory=list)\n    hyperparameters: Hyperparameters | None = None\nclass TuningExampleDict(TypedDict):\n    text_input: str\n    output: str\nTuningExampleOptions = Union[TuningExampleDict, protos.TuningExample, tuple[str, str], list[str]]\n# TODO(markdaoust): gs:// URLS? File-type argument for files without extension?",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TuningExampleDict",
        "kind": 6,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "class TuningExampleDict(TypedDict):\n    text_input: str\n    output: str\nTuningExampleOptions = Union[TuningExampleDict, protos.TuningExample, tuple[str, str], list[str]]\n# TODO(markdaoust): gs:// URLS? File-type argument for files without extension?\nTuningDataOptions = Union[\n    pathlib.Path,\n    str,\n    protos.Dataset,\n    Mapping[str, Iterable[str]],",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TuningSnapshot",
        "kind": 6,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "class TuningSnapshot:\n    step: int\n    epoch: int\n    mean_score: float\n    compute_time: datetime.datetime\n@string_utils.prettyprint\n@dataclasses.dataclass\nclass Hyperparameters:\n    epoch_count: int = 0\n    batch_size: int = 0",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "Hyperparameters",
        "kind": 6,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "class Hyperparameters:\n    epoch_count: int = 0\n    batch_size: int = 0\n    learning_rate: float = 0.0\nBaseModelNameOptions = Union[str, Model, protos.Model]\nTunedModelNameOptions = Union[str, TunedModel, protos.TunedModel]\nAnyModelNameOptions = Union[str, Model, protos.Model, TunedModel, protos.TunedModel]\nModelNameOptions = AnyModelNameOptions\ndef make_model_name(name: AnyModelNameOptions):\n    if isinstance(name, (Model, protos.Model, TunedModel, protos.TunedModel)):",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TokenCount",
        "kind": 6,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "class TokenCount:\n    \"\"\"A dataclass representation of a `protos.TokenCountResponse`.\n    Attributes:\n        token_count: The number of tokens returned by the model's tokenizer for the `input_text`.\n        token_count_limit:\n    \"\"\"\n    token_count: int\n    token_count_limit: int\n    def over_limit(self):\n        return self.token_count > self.token_count_limit",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "valid_tuned_model_name",
        "kind": 2,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "def valid_tuned_model_name(name: str) -> bool:\n    return re.match(_TUNED_MODEL_VALID_NAME, name) is not None\n# fmt: off\n_TUNED_MODEL_STATES: dict[TunedModelStateOptions, TunedModelState] = {\n    TunedModelState.ACTIVE: TunedModelState.ACTIVE,\n    int(TunedModelState.ACTIVE): TunedModelState.ACTIVE,\n    \"active\": TunedModelState.ACTIVE,\n    TunedModelState.CREATING: TunedModelState.CREATING,\n    int(TunedModelState.CREATING): TunedModelState.CREATING,\n    \"creating\": TunedModelState.CREATING,",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "to_tuned_model_state",
        "kind": 2,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "def to_tuned_model_state(x: TunedModelStateOptions) -> TunedModelState:\n    if isinstance(x, str):\n        x = x.lower()\n    return _TUNED_MODEL_STATES[x]\n@string_utils.prettyprint\n@dataclasses.dataclass\nclass Model:\n    \"\"\"A dataclass representation of a `protos.Model`.\n    Attributes:\n        name: The resource name of the `Model`. Format: `models/{model}` with a `{model}` naming",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "idecode_time",
        "kind": 2,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "def idecode_time(parent: dict[\"str\", Any], name: str):\n    time = parent.pop(name, None)\n    if time is not None:\n        if \".\" in time:\n            time = re.sub(r\"\\.\\d+\", _fix_microseconds, time)\n            dt = datetime.datetime.strptime(time, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n        else:\n            dt = datetime.datetime.strptime(time, \"%Y-%m-%dT%H:%M:%SZ\")\n        dt = dt.replace(tzinfo=datetime.timezone.utc)\n        parent[name] = dt",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "decode_tuned_model",
        "kind": 2,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "def decode_tuned_model(tuned_model: protos.TunedModel | dict[\"str\", Any]) -> TunedModel:\n    if isinstance(tuned_model, protos.TunedModel):\n        tuned_model = type(tuned_model).to_dict(tuned_model)  # pytype: disable=attribute-error\n    tuned_model[\"state\"] = to_tuned_model_state(tuned_model.pop(\"state\", None))\n    base_model = tuned_model.pop(\"base_model\", None)\n    tuned_model_source = tuned_model.pop(\"tuned_model_source\", None)\n    if base_model is not None:\n        tuned_model[\"base_model\"] = base_model\n        tuned_model[\"source_model\"] = base_model\n    elif tuned_model_source is not None:",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "encode_tuning_data",
        "kind": 2,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "def encode_tuning_data(\n    data: TuningDataOptions, input_key=\"text_input\", output_key=\"output\"\n) -> protos.Dataset:\n    if isinstance(data, protos.Dataset):\n        return data\n    if isinstance(data, str):\n        # Strings are either URLs or system paths.\n        if re.match(r\"^\\w+://\\S+$\", data):\n            data = _normalize_url(data)\n        else:",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "encode_tuning_example",
        "kind": 2,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "def encode_tuning_example(example: TuningExampleOptions, input_key, output_key):\n    if isinstance(example, protos.TuningExample):\n        return example\n    elif isinstance(example, (tuple, list)):\n        a, b = example\n        example = protos.TuningExample(text_input=a, output=b)\n    else:  # dict\n        example = protos.TuningExample(text_input=example[input_key], output=example[output_key])\n    return example\n@string_utils.prettyprint",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "make_model_name",
        "kind": 2,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "def make_model_name(name: AnyModelNameOptions):\n    if isinstance(name, (Model, protos.Model, TunedModel, protos.TunedModel)):\n        name = name.name  # pytype: disable=attribute-error\n    elif isinstance(name, str):\n        name = name\n    else:\n        raise TypeError(\n            \"Invalid input type. Expected one of the following types: `str`, `Model`, or `TunedModel`.\"\n        )\n    if not (name.startswith(\"models/\") or name.startswith(\"tunedModels/\")):",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "__all__ = [\n    \"Model\",\n    \"ModelNameOptions\",\n    \"AnyModelNameOptions\",\n    \"BaseModelNameOptions\",\n    \"TunedModelNameOptions\",\n    \"ModelsIterable\",\n    \"TunedModel\",\n    \"TunedModelState\",\n]",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TunedModelState",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "TunedModelState = protos.TunedModel.State\nTunedModelStateOptions = Union[None, str, int, TunedModelState]\n_TUNED_MODEL_VALID_NAME = r\"[a-z](([a-z0-9-]{0,61}[a-z0-9])?)$\"\nTUNED_MODEL_NAME_ERROR_MSG = \"\"\"The `name` must consist of alphanumeric characters (or -) and be at most 63 characters; The name you entered:\n\\tlen(name)== {length}\n\\tname={name}\n\"\"\"\ndef valid_tuned_model_name(name: str) -> bool:\n    return re.match(_TUNED_MODEL_VALID_NAME, name) is not None\n# fmt: off",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TunedModelStateOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "TunedModelStateOptions = Union[None, str, int, TunedModelState]\n_TUNED_MODEL_VALID_NAME = r\"[a-z](([a-z0-9-]{0,61}[a-z0-9])?)$\"\nTUNED_MODEL_NAME_ERROR_MSG = \"\"\"The `name` must consist of alphanumeric characters (or -) and be at most 63 characters; The name you entered:\n\\tlen(name)== {length}\n\\tname={name}\n\"\"\"\ndef valid_tuned_model_name(name: str) -> bool:\n    return re.match(_TUNED_MODEL_VALID_NAME, name) is not None\n# fmt: off\n_TUNED_MODEL_STATES: dict[TunedModelStateOptions, TunedModelState] = {",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "_TUNED_MODEL_VALID_NAME",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "_TUNED_MODEL_VALID_NAME = r\"[a-z](([a-z0-9-]{0,61}[a-z0-9])?)$\"\nTUNED_MODEL_NAME_ERROR_MSG = \"\"\"The `name` must consist of alphanumeric characters (or -) and be at most 63 characters; The name you entered:\n\\tlen(name)== {length}\n\\tname={name}\n\"\"\"\ndef valid_tuned_model_name(name: str) -> bool:\n    return re.match(_TUNED_MODEL_VALID_NAME, name) is not None\n# fmt: off\n_TUNED_MODEL_STATES: dict[TunedModelStateOptions, TunedModelState] = {\n    TunedModelState.ACTIVE: TunedModelState.ACTIVE,",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TUNED_MODEL_NAME_ERROR_MSG",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "TUNED_MODEL_NAME_ERROR_MSG = \"\"\"The `name` must consist of alphanumeric characters (or -) and be at most 63 characters; The name you entered:\n\\tlen(name)== {length}\n\\tname={name}\n\"\"\"\ndef valid_tuned_model_name(name: str) -> bool:\n    return re.match(_TUNED_MODEL_VALID_NAME, name) is not None\n# fmt: off\n_TUNED_MODEL_STATES: dict[TunedModelStateOptions, TunedModelState] = {\n    TunedModelState.ACTIVE: TunedModelState.ACTIVE,\n    int(TunedModelState.ACTIVE): TunedModelState.ACTIVE,",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TuningExampleOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "TuningExampleOptions = Union[TuningExampleDict, protos.TuningExample, tuple[str, str], list[str]]\n# TODO(markdaoust): gs:// URLS? File-type argument for files without extension?\nTuningDataOptions = Union[\n    pathlib.Path,\n    str,\n    protos.Dataset,\n    Mapping[str, Iterable[str]],\n    Iterable[TuningExampleOptions],\n]\ndef encode_tuning_data(",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TuningDataOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "TuningDataOptions = Union[\n    pathlib.Path,\n    str,\n    protos.Dataset,\n    Mapping[str, Iterable[str]],\n    Iterable[TuningExampleOptions],\n]\ndef encode_tuning_data(\n    data: TuningDataOptions, input_key=\"text_input\", output_key=\"output\"\n) -> protos.Dataset:",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "BaseModelNameOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "BaseModelNameOptions = Union[str, Model, protos.Model]\nTunedModelNameOptions = Union[str, TunedModel, protos.TunedModel]\nAnyModelNameOptions = Union[str, Model, protos.Model, TunedModel, protos.TunedModel]\nModelNameOptions = AnyModelNameOptions\ndef make_model_name(name: AnyModelNameOptions):\n    if isinstance(name, (Model, protos.Model, TunedModel, protos.TunedModel)):\n        name = name.name  # pytype: disable=attribute-error\n    elif isinstance(name, str):\n        name = name\n    else:",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TunedModelNameOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "TunedModelNameOptions = Union[str, TunedModel, protos.TunedModel]\nAnyModelNameOptions = Union[str, Model, protos.Model, TunedModel, protos.TunedModel]\nModelNameOptions = AnyModelNameOptions\ndef make_model_name(name: AnyModelNameOptions):\n    if isinstance(name, (Model, protos.Model, TunedModel, protos.TunedModel)):\n        name = name.name  # pytype: disable=attribute-error\n    elif isinstance(name, str):\n        name = name\n    else:\n        raise TypeError(",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "AnyModelNameOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "AnyModelNameOptions = Union[str, Model, protos.Model, TunedModel, protos.TunedModel]\nModelNameOptions = AnyModelNameOptions\ndef make_model_name(name: AnyModelNameOptions):\n    if isinstance(name, (Model, protos.Model, TunedModel, protos.TunedModel)):\n        name = name.name  # pytype: disable=attribute-error\n    elif isinstance(name, str):\n        name = name\n    else:\n        raise TypeError(\n            \"Invalid input type. Expected one of the following types: `str`, `Model`, or `TunedModel`.\"",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "ModelNameOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "ModelNameOptions = AnyModelNameOptions\ndef make_model_name(name: AnyModelNameOptions):\n    if isinstance(name, (Model, protos.Model, TunedModel, protos.TunedModel)):\n        name = name.name  # pytype: disable=attribute-error\n    elif isinstance(name, str):\n        name = name\n    else:\n        raise TypeError(\n            \"Invalid input type. Expected one of the following types: `str`, `Model`, or `TunedModel`.\"\n        )",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "ModelsIterable",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "ModelsIterable = Iterable[Model]\nTunedModelsIterable = Iterable[TunedModel]\n@string_utils.prettyprint\n@dataclasses.dataclass\nclass TokenCount:\n    \"\"\"A dataclass representation of a `protos.TokenCountResponse`.\n    Attributes:\n        token_count: The number of tokens returned by the model's tokenizer for the `input_text`.\n        token_count_limit:\n    \"\"\"",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "TunedModelsIterable",
        "kind": 5,
        "importPath": "google.generativeai.types.model_types",
        "description": "google.generativeai.types.model_types",
        "peekOfCode": "TunedModelsIterable = Iterable[TunedModel]\n@string_utils.prettyprint\n@dataclasses.dataclass\nclass TokenCount:\n    \"\"\"A dataclass representation of a `protos.TokenCountResponse`.\n    Attributes:\n        token_count: The number of tokens returned by the model's tokenizer for the `input_text`.\n        token_count_limit:\n    \"\"\"\n    token_count: int",
        "detail": "google.generativeai.types.model_types",
        "documentation": {}
    },
    {
        "label": "HarmCategory",
        "kind": 6,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "class HarmCategory:\n    \"\"\"\n    Harm Categories supported by the palm-family models\n    \"\"\"\n    HARM_CATEGORY_UNSPECIFIED = protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED.value\n    HARM_CATEGORY_DEROGATORY = protos.HarmCategory.HARM_CATEGORY_DEROGATORY.value\n    HARM_CATEGORY_TOXICITY = protos.HarmCategory.HARM_CATEGORY_TOXICITY.value\n    HARM_CATEGORY_VIOLENCE = protos.HarmCategory.HARM_CATEGORY_VIOLENCE.value\n    HARM_CATEGORY_SEXUAL = protos.HarmCategory.HARM_CATEGORY_SEXUAL.value\n    HARM_CATEGORY_MEDICAL = protos.HarmCategory.HARM_CATEGORY_MEDICAL.value",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "ContentFilterDict",
        "kind": 6,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "class ContentFilterDict(TypedDict):\n    reason: BlockedReason\n    message: str\n    __doc__ = string_utils.strip_oneof(protos.ContentFilter.__doc__)\ndef convert_filters_to_enums(\n    filters: Iterable[dict],\n) -> List[ContentFilterDict]:\n    result = []\n    for f in filters:\n        f = f.copy()",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "SafetyRatingDict",
        "kind": 6,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "class SafetyRatingDict(TypedDict):\n    category: protos.HarmCategory\n    probability: HarmProbability\n    __doc__ = string_utils.strip_oneof(protos.SafetyRating.__doc__)\ndef convert_rating_to_enum(rating: dict) -> SafetyRatingDict:\n    return {\n        \"category\": protos.HarmCategory(rating[\"category\"]),\n        \"probability\": HarmProbability(rating[\"probability\"]),\n    }\ndef convert_ratings_to_enum(ratings: Iterable[dict]) -> List[SafetyRatingDict]:",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "SafetySettingDict",
        "kind": 6,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "class SafetySettingDict(TypedDict):\n    category: protos.HarmCategory\n    threshold: HarmBlockThreshold\n    __doc__ = string_utils.strip_oneof(protos.SafetySetting.__doc__)\nclass LooseSafetySettingDict(TypedDict):\n    category: HarmCategoryOptions\n    threshold: HarmBlockThresholdOptions\nEasySafetySetting = Mapping[HarmCategoryOptions, HarmBlockThresholdOptions]\nEasySafetySettingDict = dict[HarmCategoryOptions, HarmBlockThresholdOptions]\nSafetySettingOptions = Union[EasySafetySetting, Iterable[LooseSafetySettingDict], None]",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "LooseSafetySettingDict",
        "kind": 6,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "class LooseSafetySettingDict(TypedDict):\n    category: HarmCategoryOptions\n    threshold: HarmBlockThresholdOptions\nEasySafetySetting = Mapping[HarmCategoryOptions, HarmBlockThresholdOptions]\nEasySafetySettingDict = dict[HarmCategoryOptions, HarmBlockThresholdOptions]\nSafetySettingOptions = Union[EasySafetySetting, Iterable[LooseSafetySettingDict], None]\ndef to_easy_safety_dict(settings: SafetySettingOptions) -> EasySafetySettingDict:\n    if settings is None:\n        return {}\n    elif isinstance(settings, Mapping):",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "SafetyFeedbackDict",
        "kind": 6,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "class SafetyFeedbackDict(TypedDict):\n    rating: SafetyRatingDict\n    setting: SafetySettingDict\n    __doc__ = string_utils.strip_oneof(protos.SafetyFeedback.__doc__)\ndef convert_safety_feedback_to_enums(\n    safety_feedback: Iterable[dict],\n) -> List[SafetyFeedbackDict]:\n    result = []\n    for sf in safety_feedback:\n        result.append(",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "to_harm_category",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def to_harm_category(x: HarmCategoryOptions) -> protos.HarmCategory:\n    if isinstance(x, str):\n        x = x.lower()\n    return _HARM_CATEGORIES[x]\nHarmBlockThresholdOptions = Union[str, int, HarmBlockThreshold]\n# fmt: off\n_BLOCK_THRESHOLDS: Dict[HarmBlockThresholdOptions, HarmBlockThreshold] = {\n    HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED: HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    0: HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    \"harm_block_threshold_unspecified\": HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "to_block_threshold",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def to_block_threshold(x: HarmBlockThresholdOptions) -> HarmBlockThreshold:\n    if isinstance(x, str):\n        x = x.lower()\n    return _BLOCK_THRESHOLDS[x]\nclass ContentFilterDict(TypedDict):\n    reason: BlockedReason\n    message: str\n    __doc__ = string_utils.strip_oneof(protos.ContentFilter.__doc__)\ndef convert_filters_to_enums(\n    filters: Iterable[dict],",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "convert_filters_to_enums",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def convert_filters_to_enums(\n    filters: Iterable[dict],\n) -> List[ContentFilterDict]:\n    result = []\n    for f in filters:\n        f = f.copy()\n        f[\"reason\"] = BlockedReason(f[\"reason\"])\n        f = typing.cast(ContentFilterDict, f)\n        result.append(f)\n    return result",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "convert_rating_to_enum",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def convert_rating_to_enum(rating: dict) -> SafetyRatingDict:\n    return {\n        \"category\": protos.HarmCategory(rating[\"category\"]),\n        \"probability\": HarmProbability(rating[\"probability\"]),\n    }\ndef convert_ratings_to_enum(ratings: Iterable[dict]) -> List[SafetyRatingDict]:\n    result = []\n    for r in ratings:\n        result.append(convert_rating_to_enum(r))\n    return result",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "convert_ratings_to_enum",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def convert_ratings_to_enum(ratings: Iterable[dict]) -> List[SafetyRatingDict]:\n    result = []\n    for r in ratings:\n        result.append(convert_rating_to_enum(r))\n    return result\nclass SafetySettingDict(TypedDict):\n    category: protos.HarmCategory\n    threshold: HarmBlockThreshold\n    __doc__ = string_utils.strip_oneof(protos.SafetySetting.__doc__)\nclass LooseSafetySettingDict(TypedDict):",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "to_easy_safety_dict",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def to_easy_safety_dict(settings: SafetySettingOptions) -> EasySafetySettingDict:\n    if settings is None:\n        return {}\n    elif isinstance(settings, Mapping):\n        return {to_harm_category(key): to_block_threshold(value) for key, value in settings.items()}\n    else:  # Iterable\n        return {\n            to_harm_category(d[\"category\"]): to_block_threshold(d[\"threshold\"]) for d in settings\n        }\ndef normalize_safety_settings(",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "normalize_safety_settings",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def normalize_safety_settings(\n    settings: SafetySettingOptions,\n) -> list[SafetySettingDict] | None:\n    if settings is None:\n        return None\n    if isinstance(settings, Mapping):\n        return [\n            {\n                \"category\": to_harm_category(key),\n                \"threshold\": to_block_threshold(value),",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "convert_setting_to_enum",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def convert_setting_to_enum(setting: dict) -> SafetySettingDict:\n    return {\n        \"category\": protos.HarmCategory(setting[\"category\"]),\n        \"threshold\": HarmBlockThreshold(setting[\"threshold\"]),\n    }\nclass SafetyFeedbackDict(TypedDict):\n    rating: SafetyRatingDict\n    setting: SafetySettingDict\n    __doc__ = string_utils.strip_oneof(protos.SafetyFeedback.__doc__)\ndef convert_safety_feedback_to_enums(",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "convert_safety_feedback_to_enums",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def convert_safety_feedback_to_enums(\n    safety_feedback: Iterable[dict],\n) -> List[SafetyFeedbackDict]:\n    result = []\n    for sf in safety_feedback:\n        result.append(\n            {\n                \"rating\": convert_rating_to_enum(sf[\"rating\"]),\n                \"setting\": convert_setting_to_enum(sf[\"setting\"]),\n            }",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "convert_candidate_enums",
        "kind": 2,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "def convert_candidate_enums(candidates):\n    result = []\n    for candidate in candidates:\n        candidate = candidate.copy()\n        candidate[\"safety_ratings\"] = convert_ratings_to_enum(candidate[\"safety_ratings\"])\n        result.append(candidate)\n    return result",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "__all__ = [\n    \"HarmCategory\",\n    \"HarmProbability\",\n    \"HarmBlockThreshold\",\n    \"BlockedReason\",\n    \"ContentFilterDict\",\n    \"SafetyRatingDict\",\n    \"SafetySettingDict\",\n    \"SafetyFeedbackDict\",\n]",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "HarmProbability",
        "kind": 5,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "HarmProbability = protos.SafetyRating.HarmProbability\nHarmBlockThreshold = protos.SafetySetting.HarmBlockThreshold\nBlockedReason = protos.ContentFilter.BlockedReason\nclass HarmCategory:\n    \"\"\"\n    Harm Categories supported by the palm-family models\n    \"\"\"\n    HARM_CATEGORY_UNSPECIFIED = protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED.value\n    HARM_CATEGORY_DEROGATORY = protos.HarmCategory.HARM_CATEGORY_DEROGATORY.value\n    HARM_CATEGORY_TOXICITY = protos.HarmCategory.HARM_CATEGORY_TOXICITY.value",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "HarmBlockThreshold",
        "kind": 5,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "HarmBlockThreshold = protos.SafetySetting.HarmBlockThreshold\nBlockedReason = protos.ContentFilter.BlockedReason\nclass HarmCategory:\n    \"\"\"\n    Harm Categories supported by the palm-family models\n    \"\"\"\n    HARM_CATEGORY_UNSPECIFIED = protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED.value\n    HARM_CATEGORY_DEROGATORY = protos.HarmCategory.HARM_CATEGORY_DEROGATORY.value\n    HARM_CATEGORY_TOXICITY = protos.HarmCategory.HARM_CATEGORY_TOXICITY.value\n    HARM_CATEGORY_VIOLENCE = protos.HarmCategory.HARM_CATEGORY_VIOLENCE.value",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "BlockedReason",
        "kind": 5,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "BlockedReason = protos.ContentFilter.BlockedReason\nclass HarmCategory:\n    \"\"\"\n    Harm Categories supported by the palm-family models\n    \"\"\"\n    HARM_CATEGORY_UNSPECIFIED = protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED.value\n    HARM_CATEGORY_DEROGATORY = protos.HarmCategory.HARM_CATEGORY_DEROGATORY.value\n    HARM_CATEGORY_TOXICITY = protos.HarmCategory.HARM_CATEGORY_TOXICITY.value\n    HARM_CATEGORY_VIOLENCE = protos.HarmCategory.HARM_CATEGORY_VIOLENCE.value\n    HARM_CATEGORY_SEXUAL = protos.HarmCategory.HARM_CATEGORY_SEXUAL.value",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "HarmCategoryOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "HarmCategoryOptions = Union[str, int, HarmCategory]\n# fmt: off\n_HARM_CATEGORIES: Dict[HarmCategoryOptions, protos.HarmCategory] = {\n    protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED: protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    HarmCategory.HARM_CATEGORY_UNSPECIFIED: protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    0: protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    \"harm_category_unspecified\": protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    \"unspecified\": protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    protos.HarmCategory.HARM_CATEGORY_DEROGATORY: protos.HarmCategory.HARM_CATEGORY_DEROGATORY,\n    HarmCategory.HARM_CATEGORY_DEROGATORY: protos.HarmCategory.HARM_CATEGORY_DEROGATORY,",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "HarmBlockThresholdOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "HarmBlockThresholdOptions = Union[str, int, HarmBlockThreshold]\n# fmt: off\n_BLOCK_THRESHOLDS: Dict[HarmBlockThresholdOptions, HarmBlockThreshold] = {\n    HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED: HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    0: HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    \"harm_block_threshold_unspecified\": HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    \"block_threshold_unspecified\": HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    \"unspecified\": HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    HarmBlockThreshold.BLOCK_LOW_AND_ABOVE: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    1: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "EasySafetySetting",
        "kind": 5,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "EasySafetySetting = Mapping[HarmCategoryOptions, HarmBlockThresholdOptions]\nEasySafetySettingDict = dict[HarmCategoryOptions, HarmBlockThresholdOptions]\nSafetySettingOptions = Union[EasySafetySetting, Iterable[LooseSafetySettingDict], None]\ndef to_easy_safety_dict(settings: SafetySettingOptions) -> EasySafetySettingDict:\n    if settings is None:\n        return {}\n    elif isinstance(settings, Mapping):\n        return {to_harm_category(key): to_block_threshold(value) for key, value in settings.items()}\n    else:  # Iterable\n        return {",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "EasySafetySettingDict",
        "kind": 5,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "EasySafetySettingDict = dict[HarmCategoryOptions, HarmBlockThresholdOptions]\nSafetySettingOptions = Union[EasySafetySetting, Iterable[LooseSafetySettingDict], None]\ndef to_easy_safety_dict(settings: SafetySettingOptions) -> EasySafetySettingDict:\n    if settings is None:\n        return {}\n    elif isinstance(settings, Mapping):\n        return {to_harm_category(key): to_block_threshold(value) for key, value in settings.items()}\n    else:  # Iterable\n        return {\n            to_harm_category(d[\"category\"]): to_block_threshold(d[\"threshold\"]) for d in settings",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "SafetySettingOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.palm_safety_types",
        "description": "google.generativeai.types.palm_safety_types",
        "peekOfCode": "SafetySettingOptions = Union[EasySafetySetting, Iterable[LooseSafetySettingDict], None]\ndef to_easy_safety_dict(settings: SafetySettingOptions) -> EasySafetySettingDict:\n    if settings is None:\n        return {}\n    elif isinstance(settings, Mapping):\n        return {to_harm_category(key): to_block_threshold(value) for key, value in settings.items()}\n    else:  # Iterable\n        return {\n            to_harm_category(d[\"category\"]): to_block_threshold(d[\"threshold\"]) for d in settings\n        }",
        "detail": "google.generativeai.types.palm_safety_types",
        "documentation": {}
    },
    {
        "label": "Permission",
        "kind": 6,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "class Permission:\n    \"\"\"\n    A permission to access a resource.\n    \"\"\"\n    name: str\n    role: Role\n    grantee_type: Optional[GranteeType]\n    email_address: Optional[str] = None\n    def delete(\n        self,",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "Permissions",
        "kind": 6,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "class Permissions:\n    def __init__(self, parent):\n        if isinstance(parent, str):\n            self._parent = parent\n        else:\n            self._parent = parent.name\n    @property\n    def parent(self):\n        return self._parent\n    def _make_create_permission_request(",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "to_grantee_type",
        "kind": 2,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "def to_grantee_type(x: GranteeTypeOptions) -> GranteeType:\n    if isinstance(x, str):\n        x = x.lower()\n    return _GRANTEE_TYPE[x]\ndef to_role(x: RoleOptions) -> Role:\n    if isinstance(x, str):\n        x = x.lower()\n    return _ROLE[x]\ndef valid_id(name: str) -> bool:\n    return re.match(_VALID_PERMISSION_ID, name) is not None",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "to_role",
        "kind": 2,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "def to_role(x: RoleOptions) -> Role:\n    if isinstance(x, str):\n        x = x.lower()\n    return _ROLE[x]\ndef valid_id(name: str) -> bool:\n    return re.match(_VALID_PERMISSION_ID, name) is not None\n@string_utils.prettyprint\n@dataclasses.dataclass\nclass Permission:\n    \"\"\"",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "valid_id",
        "kind": 2,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "def valid_id(name: str) -> bool:\n    return re.match(_VALID_PERMISSION_ID, name) is not None\n@string_utils.prettyprint\n@dataclasses.dataclass\nclass Permission:\n    \"\"\"\n    A permission to access a resource.\n    \"\"\"\n    name: str\n    role: Role",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "GranteeType",
        "kind": 5,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "GranteeType = protos.Permission.GranteeType\nRole = protos.Permission.Role\nGranteeTypeOptions = Union[str, int, GranteeType]\nRoleOptions = Union[str, int, Role]\n_GRANTEE_TYPE: dict[GranteeTypeOptions, GranteeType] = {\n    GranteeType.GRANTEE_TYPE_UNSPECIFIED: GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    0: GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    \"grantee_type_unspecified\": GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    \"unspecified\": GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    GranteeType.USER: GranteeType.USER,",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "Role",
        "kind": 5,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "Role = protos.Permission.Role\nGranteeTypeOptions = Union[str, int, GranteeType]\nRoleOptions = Union[str, int, Role]\n_GRANTEE_TYPE: dict[GranteeTypeOptions, GranteeType] = {\n    GranteeType.GRANTEE_TYPE_UNSPECIFIED: GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    0: GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    \"grantee_type_unspecified\": GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    \"unspecified\": GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    GranteeType.USER: GranteeType.USER,\n    1: GranteeType.USER,",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "GranteeTypeOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "GranteeTypeOptions = Union[str, int, GranteeType]\nRoleOptions = Union[str, int, Role]\n_GRANTEE_TYPE: dict[GranteeTypeOptions, GranteeType] = {\n    GranteeType.GRANTEE_TYPE_UNSPECIFIED: GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    0: GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    \"grantee_type_unspecified\": GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    \"unspecified\": GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    GranteeType.USER: GranteeType.USER,\n    1: GranteeType.USER,\n    \"user\": GranteeType.USER,",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "RoleOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "RoleOptions = Union[str, int, Role]\n_GRANTEE_TYPE: dict[GranteeTypeOptions, GranteeType] = {\n    GranteeType.GRANTEE_TYPE_UNSPECIFIED: GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    0: GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    \"grantee_type_unspecified\": GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    \"unspecified\": GranteeType.GRANTEE_TYPE_UNSPECIFIED,\n    GranteeType.USER: GranteeType.USER,\n    1: GranteeType.USER,\n    \"user\": GranteeType.USER,\n    GranteeType.GROUP: GranteeType.GROUP,",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "_VALID_PERMISSION_ID",
        "kind": 5,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "_VALID_PERMISSION_ID = r\"permissions/([a-z0-9]+)$\"\nINVALID_PERMISSION_ID_MSG = \"\"\"`permission_id` must follow the pattern: `permissions/<id>` and must \\\nconsist of only alphanumeric characters. Got: `{permission_id}` instead.\"\"\"\ndef to_grantee_type(x: GranteeTypeOptions) -> GranteeType:\n    if isinstance(x, str):\n        x = x.lower()\n    return _GRANTEE_TYPE[x]\ndef to_role(x: RoleOptions) -> Role:\n    if isinstance(x, str):\n        x = x.lower()",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "INVALID_PERMISSION_ID_MSG",
        "kind": 5,
        "importPath": "google.generativeai.types.permission_types",
        "description": "google.generativeai.types.permission_types",
        "peekOfCode": "INVALID_PERMISSION_ID_MSG = \"\"\"`permission_id` must follow the pattern: `permissions/<id>` and must \\\nconsist of only alphanumeric characters. Got: `{permission_id}` instead.\"\"\"\ndef to_grantee_type(x: GranteeTypeOptions) -> GranteeType:\n    if isinstance(x, str):\n        x = x.lower()\n    return _GRANTEE_TYPE[x]\ndef to_role(x: RoleOptions) -> Role:\n    if isinstance(x, str):\n        x = x.lower()\n    return _ROLE[x]",
        "detail": "google.generativeai.types.permission_types",
        "documentation": {}
    },
    {
        "label": "MetadataFilter",
        "kind": 6,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "class MetadataFilter:\n    key: str\n    conditions: Iterable[Condition]\n    def _to_proto(self):\n        kwargs = {}\n        conditions = []\n        for c in self.conditions:\n            if isinstance(c.value, str):\n                kwargs[\"string_value\"] = c.value\n            elif isinstance(c.value, (int, float)):",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "Condition",
        "kind": 6,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "class Condition:\n    value: str | float\n    operation: Operator\n@string_utils.prettyprint\n@dataclasses.dataclass\nclass CustomMetadata:\n    key: str\n    value: str | Iterable[str] | float\n    def _to_proto(self):\n        kwargs = {}",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "CustomMetadata",
        "kind": 6,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "class CustomMetadata:\n    key: str\n    value: str | Iterable[str] | float\n    def _to_proto(self):\n        kwargs = {}\n        if isinstance(self.value, str):\n            kwargs[\"string_value\"] = self.value\n        elif isinstance(self.value, Iterable):\n            if isinstance(self.value, Mapping):\n                # If already converted to a protos.StringList, get the values",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "ChunkData",
        "kind": 6,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "class ChunkData:\n    string_value: str\n@string_utils.prettyprint\n@dataclasses.dataclass()\nclass Corpus:\n    \"\"\"\n    A `Corpus` is a collection of `Documents`.\n    \"\"\"\n    name: str\n    display_name: str",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "Corpus",
        "kind": 6,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "class Corpus:\n    \"\"\"\n    A `Corpus` is a collection of `Documents`.\n    \"\"\"\n    name: str\n    display_name: str\n    create_time: datetime.datetime\n    update_time: datetime.datetime\n    @property\n    def permissions(self) -> permission_types.Permissions:",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "Document",
        "kind": 6,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "class Document(abc.ABC):\n    \"\"\"\n    A `Document` is a collection of `Chunk`s.\n    \"\"\"\n    name: str\n    display_name: str\n    custom_metadata: list[CustomMetadata]\n    create_time: datetime.datetime\n    update_time: datetime.datetime\n    def create_chunk(",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "RelevantChunk",
        "kind": 6,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "class RelevantChunk:\n    chunk_relevance_score: float\n    chunk: Chunk\n@string_utils.prettyprint\n@dataclasses.dataclass(init=False)\nclass Chunk(abc.ABC):\n    \"\"\"\n    A `Chunk` is part of the `Document`, or the actual text.\n    \"\"\"\n    name: str",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "Chunk",
        "kind": 6,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "class Chunk(abc.ABC):\n    \"\"\"\n    A `Chunk` is part of the `Document`, or the actual text.\n    \"\"\"\n    name: str\n    data: ChunkData\n    custom_metadata: list[CustomMetadata] | None\n    state: State\n    create_time: datetime.datetime | None\n    update_time: datetime.datetime | None",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "valid_name",
        "kind": 2,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "def valid_name(name):\n    return re.match(_VALID_NAME, name) and len(name) < 40\nOperator = protos.Condition.Operator\nState = protos.Chunk.State\nOperatorOptions = Union[str, int, Operator]\nStateOptions = Union[str, int, State]\nChunkOptions = Union[\n    protos.Chunk,\n    str,\n    tuple[str, str],",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "to_operator",
        "kind": 2,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "def to_operator(x: OperatorOptions) -> Operator:\n    if isinstance(x, str):\n        x = x.lower()\n    return _OPERATOR[x]\ndef to_state(x: StateOptions) -> State:\n    if isinstance(x, str):\n        x = x.lower()\n    return _STATE[x]\n@string_utils.prettyprint\n@dataclasses.dataclass",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "to_state",
        "kind": 2,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "def to_state(x: StateOptions) -> State:\n    if isinstance(x, str):\n        x = x.lower()\n    return _STATE[x]\n@string_utils.prettyprint\n@dataclasses.dataclass\nclass MetadataFilter:\n    key: str\n    conditions: Iterable[Condition]\n    def _to_proto(self):",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "make_custom_metadata",
        "kind": 2,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "def make_custom_metadata(cm: CustomMetadataOptions) -> CustomMetadata:\n    if isinstance(cm, CustomMetadata):\n        return cm\n    if isinstance(cm, protos.CustomMetadata):\n        cm = type(cm).to_dict(cm)\n    if isinstance(cm, dict):\n        return CustomMetadata._from_dict(cm)\n    else:\n        raise ValueError(  # nofmt\n            f\"Invalid input: Could not create a 'CustomMetadata' from the provided input. Received type: '{type(cm).__name__}', value: '{cm}'.\"",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "decode_document",
        "kind": 2,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "def decode_document(document):\n    document = type(document).to_dict(document)\n    idecode_time(document, \"create_time\")\n    idecode_time(document, \"update_time\")\n    return Document(**document)\n@string_utils.prettyprint\n@dataclasses.dataclass()\nclass Document(abc.ABC):\n    \"\"\"\n    A `Document` is a collection of `Chunk`s.",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "decode_chunk",
        "kind": 2,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "def decode_chunk(chunk: protos.Chunk) -> Chunk:\n    chunk = type(chunk).to_dict(chunk)\n    idecode_time(chunk, \"create_time\")\n    idecode_time(chunk, \"update_time\")\n    return Chunk(**chunk)\n@string_utils.prettyprint\n@dataclasses.dataclass\nclass RelevantChunk:\n    chunk_relevance_score: float\n    chunk: Chunk",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "_VALID_NAME",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "_VALID_NAME = r\"[a-z0-9]([a-z0-9-]{0,38}[a-z0-9])$\"\nNAME_ERROR_MSG = \"\"\"The `name` must consist of alphanumeric characters (or -) and be 40 or fewer characters; or be empty. The name you entered:\n    len(name)== {length}\n    name={name}\n\"\"\"\ndef valid_name(name):\n    return re.match(_VALID_NAME, name) and len(name) < 40\nOperator = protos.Condition.Operator\nState = protos.Chunk.State\nOperatorOptions = Union[str, int, Operator]",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "NAME_ERROR_MSG",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "NAME_ERROR_MSG = \"\"\"The `name` must consist of alphanumeric characters (or -) and be 40 or fewer characters; or be empty. The name you entered:\n    len(name)== {length}\n    name={name}\n\"\"\"\ndef valid_name(name):\n    return re.match(_VALID_NAME, name) and len(name) < 40\nOperator = protos.Condition.Operator\nState = protos.Chunk.State\nOperatorOptions = Union[str, int, Operator]\nStateOptions = Union[str, int, State]",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "Operator",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "Operator = protos.Condition.Operator\nState = protos.Chunk.State\nOperatorOptions = Union[str, int, Operator]\nStateOptions = Union[str, int, State]\nChunkOptions = Union[\n    protos.Chunk,\n    str,\n    tuple[str, str],\n    tuple[str, str, Any],\n    Mapping[str, Any],",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "State",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "State = protos.Chunk.State\nOperatorOptions = Union[str, int, Operator]\nStateOptions = Union[str, int, State]\nChunkOptions = Union[\n    protos.Chunk,\n    str,\n    tuple[str, str],\n    tuple[str, str, Any],\n    Mapping[str, Any],\n]  # fmt: no",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "OperatorOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "OperatorOptions = Union[str, int, Operator]\nStateOptions = Union[str, int, State]\nChunkOptions = Union[\n    protos.Chunk,\n    str,\n    tuple[str, str],\n    tuple[str, str, Any],\n    Mapping[str, Any],\n]  # fmt: no\nBatchCreateChunkOptions = Union[",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "StateOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "StateOptions = Union[str, int, State]\nChunkOptions = Union[\n    protos.Chunk,\n    str,\n    tuple[str, str],\n    tuple[str, str, Any],\n    Mapping[str, Any],\n]  # fmt: no\nBatchCreateChunkOptions = Union[\n    protos.BatchCreateChunksRequest,",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "ChunkOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "ChunkOptions = Union[\n    protos.Chunk,\n    str,\n    tuple[str, str],\n    tuple[str, str, Any],\n    Mapping[str, Any],\n]  # fmt: no\nBatchCreateChunkOptions = Union[\n    protos.BatchCreateChunksRequest,\n    Mapping[str, str],",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "BatchCreateChunkOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "BatchCreateChunkOptions = Union[\n    protos.BatchCreateChunksRequest,\n    Mapping[str, str],\n    Mapping[str, tuple[str, str]],\n    Iterable[ChunkOptions],\n]  # fmt: no\nUpdateChunkOptions = Union[protos.UpdateChunkRequest, Mapping[str, Any], tuple[str, Any]]\nBatchUpdateChunksOptions = Union[protos.BatchUpdateChunksRequest, Iterable[UpdateChunkOptions]]\nBatchDeleteChunkOptions = Union[list[protos.DeleteChunkRequest], Iterable[str]]\n_OPERATOR: dict[OperatorOptions, Operator] = {",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "UpdateChunkOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "UpdateChunkOptions = Union[protos.UpdateChunkRequest, Mapping[str, Any], tuple[str, Any]]\nBatchUpdateChunksOptions = Union[protos.BatchUpdateChunksRequest, Iterable[UpdateChunkOptions]]\nBatchDeleteChunkOptions = Union[list[protos.DeleteChunkRequest], Iterable[str]]\n_OPERATOR: dict[OperatorOptions, Operator] = {\n    Operator.OPERATOR_UNSPECIFIED: Operator.OPERATOR_UNSPECIFIED,\n    0: Operator.OPERATOR_UNSPECIFIED,\n    \"operator_unspecified\": Operator.OPERATOR_UNSPECIFIED,\n    \"unspecified\": Operator.OPERATOR_UNSPECIFIED,\n    Operator.LESS: Operator.LESS,\n    1: Operator.LESS,",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "BatchUpdateChunksOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "BatchUpdateChunksOptions = Union[protos.BatchUpdateChunksRequest, Iterable[UpdateChunkOptions]]\nBatchDeleteChunkOptions = Union[list[protos.DeleteChunkRequest], Iterable[str]]\n_OPERATOR: dict[OperatorOptions, Operator] = {\n    Operator.OPERATOR_UNSPECIFIED: Operator.OPERATOR_UNSPECIFIED,\n    0: Operator.OPERATOR_UNSPECIFIED,\n    \"operator_unspecified\": Operator.OPERATOR_UNSPECIFIED,\n    \"unspecified\": Operator.OPERATOR_UNSPECIFIED,\n    Operator.LESS: Operator.LESS,\n    1: Operator.LESS,\n    \"operator_less\": Operator.LESS,",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "BatchDeleteChunkOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "BatchDeleteChunkOptions = Union[list[protos.DeleteChunkRequest], Iterable[str]]\n_OPERATOR: dict[OperatorOptions, Operator] = {\n    Operator.OPERATOR_UNSPECIFIED: Operator.OPERATOR_UNSPECIFIED,\n    0: Operator.OPERATOR_UNSPECIFIED,\n    \"operator_unspecified\": Operator.OPERATOR_UNSPECIFIED,\n    \"unspecified\": Operator.OPERATOR_UNSPECIFIED,\n    Operator.LESS: Operator.LESS,\n    1: Operator.LESS,\n    \"operator_less\": Operator.LESS,\n    \"less\": Operator.LESS,",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "CustomMetadataOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.retriever_types",
        "description": "google.generativeai.types.retriever_types",
        "peekOfCode": "CustomMetadataOptions = Union[CustomMetadata, protos.CustomMetadata, dict]\ndef make_custom_metadata(cm: CustomMetadataOptions) -> CustomMetadata:\n    if isinstance(cm, CustomMetadata):\n        return cm\n    if isinstance(cm, protos.CustomMetadata):\n        cm = type(cm).to_dict(cm)\n    if isinstance(cm, dict):\n        return CustomMetadata._from_dict(cm)\n    else:\n        raise ValueError(  # nofmt",
        "detail": "google.generativeai.types.retriever_types",
        "documentation": {}
    },
    {
        "label": "HarmCategory",
        "kind": 6,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "class HarmCategory(proto.Enum):\n    \"\"\"\n    Harm Categories supported by the gemini-family model\n    \"\"\"\n    HARM_CATEGORY_UNSPECIFIED = protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED.value\n    HARM_CATEGORY_HARASSMENT = protos.HarmCategory.HARM_CATEGORY_HARASSMENT.value\n    HARM_CATEGORY_HATE_SPEECH = protos.HarmCategory.HARM_CATEGORY_HATE_SPEECH.value\n    HARM_CATEGORY_SEXUALLY_EXPLICIT = protos.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT.value\n    HARM_CATEGORY_DANGEROUS_CONTENT = protos.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT.value\nHarmCategoryOptions = Union[str, int, HarmCategory]",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "ContentFilterDict",
        "kind": 6,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "class ContentFilterDict(TypedDict):\n    reason: BlockedReason\n    message: str\n    __doc__ = string_utils.strip_oneof(protos.ContentFilter.__doc__)\ndef convert_filters_to_enums(\n    filters: Iterable[dict],\n) -> List[ContentFilterDict]:\n    result = []\n    for f in filters:\n        f = f.copy()",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "SafetyRatingDict",
        "kind": 6,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "class SafetyRatingDict(TypedDict):\n    category: protos.HarmCategory\n    probability: HarmProbability\n    __doc__ = string_utils.strip_oneof(protos.SafetyRating.__doc__)\ndef convert_rating_to_enum(rating: dict) -> SafetyRatingDict:\n    return {\n        \"category\": protos.HarmCategory(rating[\"category\"]),\n        \"probability\": HarmProbability(rating[\"probability\"]),\n    }\ndef convert_ratings_to_enum(ratings: Iterable[dict]) -> List[SafetyRatingDict]:",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "SafetySettingDict",
        "kind": 6,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "class SafetySettingDict(TypedDict):\n    category: protos.HarmCategory\n    threshold: HarmBlockThreshold\n    __doc__ = string_utils.strip_oneof(protos.SafetySetting.__doc__)\nclass LooseSafetySettingDict(TypedDict):\n    category: HarmCategoryOptions\n    threshold: HarmBlockThresholdOptions\nEasySafetySetting = Mapping[HarmCategoryOptions, HarmBlockThresholdOptions]\nEasySafetySettingDict = dict[HarmCategoryOptions, HarmBlockThresholdOptions]\nSafetySettingOptions = Union[",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "LooseSafetySettingDict",
        "kind": 6,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "class LooseSafetySettingDict(TypedDict):\n    category: HarmCategoryOptions\n    threshold: HarmBlockThresholdOptions\nEasySafetySetting = Mapping[HarmCategoryOptions, HarmBlockThresholdOptions]\nEasySafetySettingDict = dict[HarmCategoryOptions, HarmBlockThresholdOptions]\nSafetySettingOptions = Union[\n    HarmBlockThresholdOptions, EasySafetySetting, Iterable[LooseSafetySettingDict], None\n]\ndef _expand_block_threshold(block_threshold: HarmBlockThresholdOptions):\n    block_threshold = to_block_threshold(block_threshold)",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "SafetyFeedbackDict",
        "kind": 6,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "class SafetyFeedbackDict(TypedDict):\n    rating: SafetyRatingDict\n    setting: SafetySettingDict\n    __doc__ = string_utils.strip_oneof(protos.SafetyFeedback.__doc__)\ndef convert_safety_feedback_to_enums(\n    safety_feedback: Iterable[dict],\n) -> List[SafetyFeedbackDict]:\n    result = []\n    for sf in safety_feedback:\n        result.append(",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "to_harm_category",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def to_harm_category(x: HarmCategoryOptions) -> protos.HarmCategory:\n    if isinstance(x, str):\n        x = x.lower()\n    return _HARM_CATEGORIES[x]\nHarmBlockThresholdOptions = Union[str, int, HarmBlockThreshold]\n# fmt: off\n_BLOCK_THRESHOLDS: Dict[HarmBlockThresholdOptions, HarmBlockThreshold] = {\n    HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED: HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    0: HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    \"harm_block_threshold_unspecified\": HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "to_block_threshold",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def to_block_threshold(x: HarmBlockThresholdOptions) -> HarmBlockThreshold:\n    if isinstance(x, str):\n        x = x.lower()\n    return _BLOCK_THRESHOLDS[x]\nclass ContentFilterDict(TypedDict):\n    reason: BlockedReason\n    message: str\n    __doc__ = string_utils.strip_oneof(protos.ContentFilter.__doc__)\ndef convert_filters_to_enums(\n    filters: Iterable[dict],",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "convert_filters_to_enums",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def convert_filters_to_enums(\n    filters: Iterable[dict],\n) -> List[ContentFilterDict]:\n    result = []\n    for f in filters:\n        f = f.copy()\n        f[\"reason\"] = BlockedReason(f[\"reason\"])\n        f = typing.cast(ContentFilterDict, f)\n        result.append(f)\n    return result",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "convert_rating_to_enum",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def convert_rating_to_enum(rating: dict) -> SafetyRatingDict:\n    return {\n        \"category\": protos.HarmCategory(rating[\"category\"]),\n        \"probability\": HarmProbability(rating[\"probability\"]),\n    }\ndef convert_ratings_to_enum(ratings: Iterable[dict]) -> List[SafetyRatingDict]:\n    result = []\n    for r in ratings:\n        result.append(convert_rating_to_enum(r))\n    return result",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "convert_ratings_to_enum",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def convert_ratings_to_enum(ratings: Iterable[dict]) -> List[SafetyRatingDict]:\n    result = []\n    for r in ratings:\n        result.append(convert_rating_to_enum(r))\n    return result\nclass SafetySettingDict(TypedDict):\n    category: protos.HarmCategory\n    threshold: HarmBlockThreshold\n    __doc__ = string_utils.strip_oneof(protos.SafetySetting.__doc__)\nclass LooseSafetySettingDict(TypedDict):",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "to_easy_safety_dict",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def to_easy_safety_dict(settings: SafetySettingOptions) -> EasySafetySettingDict:\n    if settings is None:\n        return {}\n    if isinstance(settings, (int, str, HarmBlockThreshold)):\n        settings = _expand_block_threshold(settings)\n    if isinstance(settings, Mapping):\n        return {to_harm_category(key): to_block_threshold(value) for key, value in settings.items()}\n    else:  # Iterable\n        result = {}\n        for setting in settings:",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "normalize_safety_settings",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def normalize_safety_settings(\n    settings: SafetySettingOptions,\n) -> list[SafetySettingDict] | None:\n    if settings is None:\n        return None\n    if isinstance(settings, (int, str, HarmBlockThreshold)):\n        settings = _expand_block_threshold(settings)\n    if isinstance(settings, Mapping):\n        return [\n            {",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "convert_setting_to_enum",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def convert_setting_to_enum(setting: dict) -> SafetySettingDict:\n    return {\n        \"category\": protos.HarmCategory(setting[\"category\"]),\n        \"threshold\": HarmBlockThreshold(setting[\"threshold\"]),\n    }\nclass SafetyFeedbackDict(TypedDict):\n    rating: SafetyRatingDict\n    setting: SafetySettingDict\n    __doc__ = string_utils.strip_oneof(protos.SafetyFeedback.__doc__)\ndef convert_safety_feedback_to_enums(",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "convert_safety_feedback_to_enums",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def convert_safety_feedback_to_enums(\n    safety_feedback: Iterable[dict],\n) -> List[SafetyFeedbackDict]:\n    result = []\n    for sf in safety_feedback:\n        result.append(\n            {\n                \"rating\": convert_rating_to_enum(sf[\"rating\"]),\n                \"setting\": convert_setting_to_enum(sf[\"setting\"]),\n            }",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "convert_candidate_enums",
        "kind": 2,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "def convert_candidate_enums(candidates):\n    result = []\n    for candidate in candidates:\n        candidate = candidate.copy()\n        candidate[\"safety_ratings\"] = convert_ratings_to_enum(candidate[\"safety_ratings\"])\n        result.append(candidate)\n    return result",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "__all__ = [\n    \"HarmCategory\",\n    \"HarmProbability\",\n    \"HarmBlockThreshold\",\n    \"BlockedReason\",\n    \"ContentFilterDict\",\n    \"SafetyRatingDict\",\n    \"SafetySettingDict\",\n    \"SafetyFeedbackDict\",\n]",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "HarmProbability",
        "kind": 5,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "HarmProbability = protos.SafetyRating.HarmProbability\nHarmBlockThreshold = protos.SafetySetting.HarmBlockThreshold\nBlockedReason = protos.ContentFilter.BlockedReason\nimport proto\nclass HarmCategory(proto.Enum):\n    \"\"\"\n    Harm Categories supported by the gemini-family model\n    \"\"\"\n    HARM_CATEGORY_UNSPECIFIED = protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED.value\n    HARM_CATEGORY_HARASSMENT = protos.HarmCategory.HARM_CATEGORY_HARASSMENT.value",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "HarmBlockThreshold",
        "kind": 5,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "HarmBlockThreshold = protos.SafetySetting.HarmBlockThreshold\nBlockedReason = protos.ContentFilter.BlockedReason\nimport proto\nclass HarmCategory(proto.Enum):\n    \"\"\"\n    Harm Categories supported by the gemini-family model\n    \"\"\"\n    HARM_CATEGORY_UNSPECIFIED = protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED.value\n    HARM_CATEGORY_HARASSMENT = protos.HarmCategory.HARM_CATEGORY_HARASSMENT.value\n    HARM_CATEGORY_HATE_SPEECH = protos.HarmCategory.HARM_CATEGORY_HATE_SPEECH.value",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "BlockedReason",
        "kind": 5,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "BlockedReason = protos.ContentFilter.BlockedReason\nimport proto\nclass HarmCategory(proto.Enum):\n    \"\"\"\n    Harm Categories supported by the gemini-family model\n    \"\"\"\n    HARM_CATEGORY_UNSPECIFIED = protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED.value\n    HARM_CATEGORY_HARASSMENT = protos.HarmCategory.HARM_CATEGORY_HARASSMENT.value\n    HARM_CATEGORY_HATE_SPEECH = protos.HarmCategory.HARM_CATEGORY_HATE_SPEECH.value\n    HARM_CATEGORY_SEXUALLY_EXPLICIT = protos.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT.value",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "HarmCategoryOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "HarmCategoryOptions = Union[str, int, HarmCategory]\n# fmt: off\n_HARM_CATEGORIES: Dict[HarmCategoryOptions, protos.HarmCategory] = {\n    protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED: protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    HarmCategory.HARM_CATEGORY_UNSPECIFIED: protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    0: protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    \"harm_category_unspecified\": protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    \"unspecified\": protos.HarmCategory.HARM_CATEGORY_UNSPECIFIED,\n    7: protos.HarmCategory.HARM_CATEGORY_HARASSMENT,\n    protos.HarmCategory.HARM_CATEGORY_HARASSMENT: protos.HarmCategory.HARM_CATEGORY_HARASSMENT,",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "HarmBlockThresholdOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "HarmBlockThresholdOptions = Union[str, int, HarmBlockThreshold]\n# fmt: off\n_BLOCK_THRESHOLDS: Dict[HarmBlockThresholdOptions, HarmBlockThreshold] = {\n    HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED: HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    0: HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    \"harm_block_threshold_unspecified\": HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    \"block_threshold_unspecified\": HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    \"unspecified\": HarmBlockThreshold.HARM_BLOCK_THRESHOLD_UNSPECIFIED,\n    HarmBlockThreshold.BLOCK_LOW_AND_ABOVE: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    1: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "EasySafetySetting",
        "kind": 5,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "EasySafetySetting = Mapping[HarmCategoryOptions, HarmBlockThresholdOptions]\nEasySafetySettingDict = dict[HarmCategoryOptions, HarmBlockThresholdOptions]\nSafetySettingOptions = Union[\n    HarmBlockThresholdOptions, EasySafetySetting, Iterable[LooseSafetySettingDict], None\n]\ndef _expand_block_threshold(block_threshold: HarmBlockThresholdOptions):\n    block_threshold = to_block_threshold(block_threshold)\n    set(_HARM_CATEGORIES.values())\n    return {category: block_threshold for category in set(_HARM_CATEGORIES.values())}\ndef to_easy_safety_dict(settings: SafetySettingOptions) -> EasySafetySettingDict:",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "EasySafetySettingDict",
        "kind": 5,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "EasySafetySettingDict = dict[HarmCategoryOptions, HarmBlockThresholdOptions]\nSafetySettingOptions = Union[\n    HarmBlockThresholdOptions, EasySafetySetting, Iterable[LooseSafetySettingDict], None\n]\ndef _expand_block_threshold(block_threshold: HarmBlockThresholdOptions):\n    block_threshold = to_block_threshold(block_threshold)\n    set(_HARM_CATEGORIES.values())\n    return {category: block_threshold for category in set(_HARM_CATEGORIES.values())}\ndef to_easy_safety_dict(settings: SafetySettingOptions) -> EasySafetySettingDict:\n    if settings is None:",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "SafetySettingOptions",
        "kind": 5,
        "importPath": "google.generativeai.types.safety_types",
        "description": "google.generativeai.types.safety_types",
        "peekOfCode": "SafetySettingOptions = Union[\n    HarmBlockThresholdOptions, EasySafetySetting, Iterable[LooseSafetySettingDict], None\n]\ndef _expand_block_threshold(block_threshold: HarmBlockThresholdOptions):\n    block_threshold = to_block_threshold(block_threshold)\n    set(_HARM_CATEGORIES.values())\n    return {category: block_threshold for category in set(_HARM_CATEGORIES.values())}\ndef to_easy_safety_dict(settings: SafetySettingOptions) -> EasySafetySettingDict:\n    if settings is None:\n        return {}",
        "detail": "google.generativeai.types.safety_types",
        "documentation": {}
    },
    {
        "label": "TokenCount",
        "kind": 6,
        "importPath": "google.generativeai.types.text_types",
        "description": "google.generativeai.types.text_types",
        "peekOfCode": "class TokenCount(TypedDict):\n    token_count: int\nclass EmbeddingDict(TypedDict):\n    embedding: list[float]\nclass BatchEmbeddingDict(TypedDict):\n    embedding: list[list[float]]\nclass TextCompletion(TypedDict, total=False):\n    output: str\n    safety_ratings: List[palm_safety_types.SafetyRatingDict | None]\n    citation_metadata: citation_types.CitationMetadataDict | None",
        "detail": "google.generativeai.types.text_types",
        "documentation": {}
    },
    {
        "label": "EmbeddingDict",
        "kind": 6,
        "importPath": "google.generativeai.types.text_types",
        "description": "google.generativeai.types.text_types",
        "peekOfCode": "class EmbeddingDict(TypedDict):\n    embedding: list[float]\nclass BatchEmbeddingDict(TypedDict):\n    embedding: list[list[float]]\nclass TextCompletion(TypedDict, total=False):\n    output: str\n    safety_ratings: List[palm_safety_types.SafetyRatingDict | None]\n    citation_metadata: citation_types.CitationMetadataDict | None\n@string_utils.prettyprint\n@dataclasses.dataclass(init=False)",
        "detail": "google.generativeai.types.text_types",
        "documentation": {}
    },
    {
        "label": "BatchEmbeddingDict",
        "kind": 6,
        "importPath": "google.generativeai.types.text_types",
        "description": "google.generativeai.types.text_types",
        "peekOfCode": "class BatchEmbeddingDict(TypedDict):\n    embedding: list[list[float]]\nclass TextCompletion(TypedDict, total=False):\n    output: str\n    safety_ratings: List[palm_safety_types.SafetyRatingDict | None]\n    citation_metadata: citation_types.CitationMetadataDict | None\n@string_utils.prettyprint\n@dataclasses.dataclass(init=False)\nclass Completion(abc.ABC):\n    \"\"\"The result returned by `generativeai.generate_text`.",
        "detail": "google.generativeai.types.text_types",
        "documentation": {}
    },
    {
        "label": "TextCompletion",
        "kind": 6,
        "importPath": "google.generativeai.types.text_types",
        "description": "google.generativeai.types.text_types",
        "peekOfCode": "class TextCompletion(TypedDict, total=False):\n    output: str\n    safety_ratings: List[palm_safety_types.SafetyRatingDict | None]\n    citation_metadata: citation_types.CitationMetadataDict | None\n@string_utils.prettyprint\n@dataclasses.dataclass(init=False)\nclass Completion(abc.ABC):\n    \"\"\"The result returned by `generativeai.generate_text`.\n    Use `GenerateTextResponse.candidates` to access all the completions generated by the model.\n    Attributes:",
        "detail": "google.generativeai.types.text_types",
        "documentation": {}
    },
    {
        "label": "Completion",
        "kind": 6,
        "importPath": "google.generativeai.types.text_types",
        "description": "google.generativeai.types.text_types",
        "peekOfCode": "class Completion(abc.ABC):\n    \"\"\"The result returned by `generativeai.generate_text`.\n    Use `GenerateTextResponse.candidates` to access all the completions generated by the model.\n    Attributes:\n        candidates: A list of candidate text completions generated by the model.\n        result: The output of the first candidate,\n        filters: Indicates the reasons why content may have been blocked.\n          See `types.BlockedReason`.\n        safety_feedback: Indicates which safety settings blocked content in this result.\n    \"\"\"",
        "detail": "google.generativeai.types.text_types",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.types.text_types",
        "description": "google.generativeai.types.text_types",
        "peekOfCode": "__all__ = [\"Completion\"]\nclass TokenCount(TypedDict):\n    token_count: int\nclass EmbeddingDict(TypedDict):\n    embedding: list[float]\nclass BatchEmbeddingDict(TypedDict):\n    embedding: list[list[float]]\nclass TextCompletion(TypedDict, total=False):\n    output: str\n    safety_ratings: List[palm_safety_types.SafetyRatingDict | None]",
        "detail": "google.generativeai.types.text_types",
        "documentation": {}
    },
    {
        "label": "SemanticRetrieverConfigDict",
        "kind": 6,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "class SemanticRetrieverConfigDict(TypedDict):\n    source: SourceNameType\n    query: content_types.ContentsType\n    metadata_filter: Optional[Iterable[MetadataFilter]]\n    max_chunks_count: Optional[int]\n    minimum_relevance_score: Optional[float]\nSemanticRetrieverConfigOptions = Union[\n    SourceNameType,\n    SemanticRetrieverConfigDict,\n    protos.SemanticRetrieverConfig,",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "to_answer_style",
        "kind": 2,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "def to_answer_style(x: AnswerStyleOptions) -> AnswerStyle:\n    if isinstance(x, str):\n        x = x.lower()\n    return _ANSWER_STYLES[x]\nGroundingPassageOptions = (\n    Union[\n        protos.GroundingPassage, tuple[str, content_types.ContentType], content_types.ContentType\n    ],\n)\nGroundingPassagesOptions = Union[",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "generate_answer",
        "kind": 2,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "def generate_answer(\n    *,\n    model: model_types.AnyModelNameOptions = DEFAULT_ANSWER_MODEL,\n    contents: content_types.ContentsType,\n    inline_passages: GroundingPassagesOptions | None = None,\n    semantic_retriever: SemanticRetrieverConfigOptions | None = None,\n    answer_style: AnswerStyle | None = None,\n    safety_settings: safety_types.SafetySettingOptions | None = None,\n    temperature: float | None = None,\n    client: glm.GenerativeServiceClient | None = None,",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "DEFAULT_ANSWER_MODEL",
        "kind": 5,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "DEFAULT_ANSWER_MODEL = \"models/aqa\"\nAnswerStyle = protos.GenerateAnswerRequest.AnswerStyle\nAnswerStyleOptions = Union[int, str, AnswerStyle]\n_ANSWER_STYLES: dict[AnswerStyleOptions, AnswerStyle] = {\n    AnswerStyle.ANSWER_STYLE_UNSPECIFIED: AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    0: AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    \"answer_style_unspecified\": AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    \"unspecified\": AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    AnswerStyle.ABSTRACTIVE: AnswerStyle.ABSTRACTIVE,\n    1: AnswerStyle.ABSTRACTIVE,",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "AnswerStyle",
        "kind": 5,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "AnswerStyle = protos.GenerateAnswerRequest.AnswerStyle\nAnswerStyleOptions = Union[int, str, AnswerStyle]\n_ANSWER_STYLES: dict[AnswerStyleOptions, AnswerStyle] = {\n    AnswerStyle.ANSWER_STYLE_UNSPECIFIED: AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    0: AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    \"answer_style_unspecified\": AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    \"unspecified\": AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    AnswerStyle.ABSTRACTIVE: AnswerStyle.ABSTRACTIVE,\n    1: AnswerStyle.ABSTRACTIVE,\n    \"answer_style_abstractive\": AnswerStyle.ABSTRACTIVE,",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "AnswerStyleOptions",
        "kind": 5,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "AnswerStyleOptions = Union[int, str, AnswerStyle]\n_ANSWER_STYLES: dict[AnswerStyleOptions, AnswerStyle] = {\n    AnswerStyle.ANSWER_STYLE_UNSPECIFIED: AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    0: AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    \"answer_style_unspecified\": AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    \"unspecified\": AnswerStyle.ANSWER_STYLE_UNSPECIFIED,\n    AnswerStyle.ABSTRACTIVE: AnswerStyle.ABSTRACTIVE,\n    1: AnswerStyle.ABSTRACTIVE,\n    \"answer_style_abstractive\": AnswerStyle.ABSTRACTIVE,\n    \"abstractive\": AnswerStyle.ABSTRACTIVE,",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "GroundingPassageOptions",
        "kind": 5,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "GroundingPassageOptions = (\n    Union[\n        protos.GroundingPassage, tuple[str, content_types.ContentType], content_types.ContentType\n    ],\n)\nGroundingPassagesOptions = Union[\n    protos.GroundingPassages,\n    Iterable[GroundingPassageOptions],\n    Mapping[str, content_types.ContentType],\n]",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "GroundingPassagesOptions",
        "kind": 5,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "GroundingPassagesOptions = Union[\n    protos.GroundingPassages,\n    Iterable[GroundingPassageOptions],\n    Mapping[str, content_types.ContentType],\n]\ndef _make_grounding_passages(source: GroundingPassagesOptions) -> protos.GroundingPassages:\n    \"\"\"\n    Converts the `source` into a `protos.GroundingPassage`. A `GroundingPassages` contains a list of\n    `protos.GroundingPassage` objects, which each contain a `protos.Contant` and a string `id`.\n    Args:",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "SourceNameType",
        "kind": 5,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "SourceNameType = Union[\n    str, retriever_types.Corpus, protos.Corpus, retriever_types.Document, protos.Document\n]\nclass SemanticRetrieverConfigDict(TypedDict):\n    source: SourceNameType\n    query: content_types.ContentsType\n    metadata_filter: Optional[Iterable[MetadataFilter]]\n    max_chunks_count: Optional[int]\n    minimum_relevance_score: Optional[float]\nSemanticRetrieverConfigOptions = Union[",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "SemanticRetrieverConfigOptions",
        "kind": 5,
        "importPath": "google.generativeai.answer",
        "description": "google.generativeai.answer",
        "peekOfCode": "SemanticRetrieverConfigOptions = Union[\n    SourceNameType,\n    SemanticRetrieverConfigDict,\n    protos.SemanticRetrieverConfig,\n]\ndef _maybe_get_source_name(source) -> str | None:\n    if isinstance(source, str):\n        return source\n    elif isinstance(\n        source, (retriever_types.Corpus, protos.Corpus, retriever_types.Document, protos.Document)",
        "detail": "google.generativeai.answer",
        "documentation": {}
    },
    {
        "label": "CachedContent",
        "kind": 6,
        "importPath": "google.generativeai.caching",
        "description": "google.generativeai.caching",
        "peekOfCode": "class CachedContent:\n    \"\"\"Cached content resource.\"\"\"\n    def __init__(self, name):\n        \"\"\"Fetches a `CachedContent` resource.\n        Identical to `CachedContent.get`.\n        Args:\n            name: The resource name referring to the cached content.\n        \"\"\"\n        client = get_default_cache_client()\n        if \"cachedContents/\" not in name:",
        "detail": "google.generativeai.caching",
        "documentation": {}
    },
    {
        "label": "_USER_ROLE",
        "kind": 5,
        "importPath": "google.generativeai.caching",
        "description": "google.generativeai.caching",
        "peekOfCode": "_USER_ROLE = \"user\"\n_MODEL_ROLE = \"model\"\nclass CachedContent:\n    \"\"\"Cached content resource.\"\"\"\n    def __init__(self, name):\n        \"\"\"Fetches a `CachedContent` resource.\n        Identical to `CachedContent.get`.\n        Args:\n            name: The resource name referring to the cached content.\n        \"\"\"",
        "detail": "google.generativeai.caching",
        "documentation": {}
    },
    {
        "label": "_MODEL_ROLE",
        "kind": 5,
        "importPath": "google.generativeai.caching",
        "description": "google.generativeai.caching",
        "peekOfCode": "_MODEL_ROLE = \"model\"\nclass CachedContent:\n    \"\"\"Cached content resource.\"\"\"\n    def __init__(self, name):\n        \"\"\"Fetches a `CachedContent` resource.\n        Identical to `CachedContent.get`.\n        Args:\n            name: The resource name referring to the cached content.\n        \"\"\"\n        client = get_default_cache_client()",
        "detail": "google.generativeai.caching",
        "documentation": {}
    },
    {
        "label": "FileServiceClient",
        "kind": 6,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "class FileServiceClient(glm.FileServiceClient):\n    def __init__(self, *args, **kwargs):\n        self._discovery_api = None\n        super().__init__(*args, **kwargs)\n    def _setup_discovery_api(self):\n        api_key = self._client_options.api_key\n        if api_key is None:\n            raise ValueError(\n                \"Invalid operation: Uploading to the File API requires an API key. Please provide a valid API key.\"\n            )",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "FileServiceAsyncClient",
        "kind": 6,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "class FileServiceAsyncClient(glm.FileServiceAsyncClient):\n    async def create_file(self, *args, **kwargs):\n        raise NotImplementedError(\n            \"The `create_file` method is currently not supported for the asynchronous client.\"\n        )\n@dataclasses.dataclass\nclass _ClientManager:\n    client_config: dict[str, Any] = dataclasses.field(default_factory=dict)\n    default_metadata: Sequence[tuple[str, str]] = ()\n    discuss_client: glm.DiscussServiceClient | None = None",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "_ClientManager",
        "kind": 6,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "class _ClientManager:\n    client_config: dict[str, Any] = dataclasses.field(default_factory=dict)\n    default_metadata: Sequence[tuple[str, str]] = ()\n    discuss_client: glm.DiscussServiceClient | None = None\n    discuss_async_client: glm.DiscussServiceAsyncClient | None = None\n    clients: dict[str, Any] = dataclasses.field(default_factory=dict)\n    def configure(\n        self,\n        *,\n        api_key: str | None = None,",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "patch_colab_gce_credentials",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def patch_colab_gce_credentials():\n    get_gce = auth._default._get_gce_credentials\n    if \"COLAB_RELEASE_TAG\" in os.environ:\n        auth._default._get_gce_credentials = lambda *args, **kwargs: (None, None)\n    try:\n        yield\n    finally:\n        auth._default._get_gce_credentials = get_gce\nclass FileServiceClient(glm.FileServiceClient):\n    def __init__(self, *args, **kwargs):",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "configure",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def configure(\n    *,\n    api_key: str | None = None,\n    credentials: ga_credentials.Credentials | dict | None = None,\n    # The user can pass a string to choose `rest` or `grpc` or 'grpc_asyncio'.\n    # See `_transport_registry` in `DiscussServiceClientMeta`.\n    # Since the transport classes align with the client classes it wouldn't make\n    # sense to accept a `Transport` object here even though the client classes can.\n    # We could accept a dict since all the `Transport` classes take the same args,\n    # but that seems rare. Users that need it can just switch to the low level API.",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_cache_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_cache_client() -> glm.CacheServiceClient:\n    return _client_manager.get_default_client(\"cache\")\ndef get_default_discuss_client() -> glm.DiscussServiceClient:\n    return _client_manager.get_default_client(\"discuss\")\ndef get_default_discuss_async_client() -> glm.DiscussServiceAsyncClient:\n    return _client_manager.get_default_client(\"discuss_async\")\ndef get_default_file_client() -> glm.FilesServiceClient:\n    return _client_manager.get_default_client(\"file\")\ndef get_default_file_async_client() -> glm.FilesServiceAsyncClient:\n    return _client_manager.get_default_client(\"file_async\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_discuss_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_discuss_client() -> glm.DiscussServiceClient:\n    return _client_manager.get_default_client(\"discuss\")\ndef get_default_discuss_async_client() -> glm.DiscussServiceAsyncClient:\n    return _client_manager.get_default_client(\"discuss_async\")\ndef get_default_file_client() -> glm.FilesServiceClient:\n    return _client_manager.get_default_client(\"file\")\ndef get_default_file_async_client() -> glm.FilesServiceAsyncClient:\n    return _client_manager.get_default_client(\"file_async\")\ndef get_default_generative_client() -> glm.GenerativeServiceClient:\n    return _client_manager.get_default_client(\"generative\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_discuss_async_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_discuss_async_client() -> glm.DiscussServiceAsyncClient:\n    return _client_manager.get_default_client(\"discuss_async\")\ndef get_default_file_client() -> glm.FilesServiceClient:\n    return _client_manager.get_default_client(\"file\")\ndef get_default_file_async_client() -> glm.FilesServiceAsyncClient:\n    return _client_manager.get_default_client(\"file_async\")\ndef get_default_generative_client() -> glm.GenerativeServiceClient:\n    return _client_manager.get_default_client(\"generative\")\ndef get_default_generative_async_client() -> glm.GenerativeServiceAsyncClient:\n    return _client_manager.get_default_client(\"generative_async\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_file_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_file_client() -> glm.FilesServiceClient:\n    return _client_manager.get_default_client(\"file\")\ndef get_default_file_async_client() -> glm.FilesServiceAsyncClient:\n    return _client_manager.get_default_client(\"file_async\")\ndef get_default_generative_client() -> glm.GenerativeServiceClient:\n    return _client_manager.get_default_client(\"generative\")\ndef get_default_generative_async_client() -> glm.GenerativeServiceAsyncClient:\n    return _client_manager.get_default_client(\"generative_async\")\ndef get_default_text_client() -> glm.TextServiceClient:\n    return _client_manager.get_default_client(\"text\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_file_async_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_file_async_client() -> glm.FilesServiceAsyncClient:\n    return _client_manager.get_default_client(\"file_async\")\ndef get_default_generative_client() -> glm.GenerativeServiceClient:\n    return _client_manager.get_default_client(\"generative\")\ndef get_default_generative_async_client() -> glm.GenerativeServiceAsyncClient:\n    return _client_manager.get_default_client(\"generative_async\")\ndef get_default_text_client() -> glm.TextServiceClient:\n    return _client_manager.get_default_client(\"text\")\ndef get_default_operations_client() -> operations_v1.OperationsClient:\n    return _client_manager.get_default_client(\"operations\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_generative_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_generative_client() -> glm.GenerativeServiceClient:\n    return _client_manager.get_default_client(\"generative\")\ndef get_default_generative_async_client() -> glm.GenerativeServiceAsyncClient:\n    return _client_manager.get_default_client(\"generative_async\")\ndef get_default_text_client() -> glm.TextServiceClient:\n    return _client_manager.get_default_client(\"text\")\ndef get_default_operations_client() -> operations_v1.OperationsClient:\n    return _client_manager.get_default_client(\"operations\")\ndef get_default_model_client() -> glm.ModelServiceAsyncClient:\n    return _client_manager.get_default_client(\"model\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_generative_async_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_generative_async_client() -> glm.GenerativeServiceAsyncClient:\n    return _client_manager.get_default_client(\"generative_async\")\ndef get_default_text_client() -> glm.TextServiceClient:\n    return _client_manager.get_default_client(\"text\")\ndef get_default_operations_client() -> operations_v1.OperationsClient:\n    return _client_manager.get_default_client(\"operations\")\ndef get_default_model_client() -> glm.ModelServiceAsyncClient:\n    return _client_manager.get_default_client(\"model\")\ndef get_default_retriever_client() -> glm.RetrieverClient:\n    return _client_manager.get_default_client(\"retriever\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_text_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_text_client() -> glm.TextServiceClient:\n    return _client_manager.get_default_client(\"text\")\ndef get_default_operations_client() -> operations_v1.OperationsClient:\n    return _client_manager.get_default_client(\"operations\")\ndef get_default_model_client() -> glm.ModelServiceAsyncClient:\n    return _client_manager.get_default_client(\"model\")\ndef get_default_retriever_client() -> glm.RetrieverClient:\n    return _client_manager.get_default_client(\"retriever\")\ndef get_default_retriever_async_client() -> glm.RetrieverAsyncClient:\n    return _client_manager.get_default_client(\"retriever_async\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_operations_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_operations_client() -> operations_v1.OperationsClient:\n    return _client_manager.get_default_client(\"operations\")\ndef get_default_model_client() -> glm.ModelServiceAsyncClient:\n    return _client_manager.get_default_client(\"model\")\ndef get_default_retriever_client() -> glm.RetrieverClient:\n    return _client_manager.get_default_client(\"retriever\")\ndef get_default_retriever_async_client() -> glm.RetrieverAsyncClient:\n    return _client_manager.get_default_client(\"retriever_async\")\ndef get_default_permission_client() -> glm.PermissionServiceClient:\n    return _client_manager.get_default_client(\"permission\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_model_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_model_client() -> glm.ModelServiceAsyncClient:\n    return _client_manager.get_default_client(\"model\")\ndef get_default_retriever_client() -> glm.RetrieverClient:\n    return _client_manager.get_default_client(\"retriever\")\ndef get_default_retriever_async_client() -> glm.RetrieverAsyncClient:\n    return _client_manager.get_default_client(\"retriever_async\")\ndef get_default_permission_client() -> glm.PermissionServiceClient:\n    return _client_manager.get_default_client(\"permission\")\ndef get_default_permission_async_client() -> glm.PermissionServiceAsyncClient:\n    return _client_manager.get_default_client(\"permission_async\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_retriever_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_retriever_client() -> glm.RetrieverClient:\n    return _client_manager.get_default_client(\"retriever\")\ndef get_default_retriever_async_client() -> glm.RetrieverAsyncClient:\n    return _client_manager.get_default_client(\"retriever_async\")\ndef get_default_permission_client() -> glm.PermissionServiceClient:\n    return _client_manager.get_default_client(\"permission\")\ndef get_default_permission_async_client() -> glm.PermissionServiceAsyncClient:\n    return _client_manager.get_default_client(\"permission_async\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_retriever_async_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_retriever_async_client() -> glm.RetrieverAsyncClient:\n    return _client_manager.get_default_client(\"retriever_async\")\ndef get_default_permission_client() -> glm.PermissionServiceClient:\n    return _client_manager.get_default_client(\"permission\")\ndef get_default_permission_async_client() -> glm.PermissionServiceAsyncClient:\n    return _client_manager.get_default_client(\"permission_async\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_permission_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_permission_client() -> glm.PermissionServiceClient:\n    return _client_manager.get_default_client(\"permission\")\ndef get_default_permission_async_client() -> glm.PermissionServiceAsyncClient:\n    return _client_manager.get_default_client(\"permission_async\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "get_default_permission_async_client",
        "kind": 2,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "def get_default_permission_async_client() -> glm.PermissionServiceAsyncClient:\n    return _client_manager.get_default_client(\"permission_async\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "USER_AGENT = \"genai-py\"\nGENAI_API_DISCOVERY_URL = \"https://generativelanguage.googleapis.com/$discovery/rest\"\n@contextlib.contextmanager\ndef patch_colab_gce_credentials():\n    get_gce = auth._default._get_gce_credentials\n    if \"COLAB_RELEASE_TAG\" in os.environ:\n        auth._default._get_gce_credentials = lambda *args, **kwargs: (None, None)\n    try:\n        yield\n    finally:",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "GENAI_API_DISCOVERY_URL",
        "kind": 5,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "GENAI_API_DISCOVERY_URL = \"https://generativelanguage.googleapis.com/$discovery/rest\"\n@contextlib.contextmanager\ndef patch_colab_gce_credentials():\n    get_gce = auth._default._get_gce_credentials\n    if \"COLAB_RELEASE_TAG\" in os.environ:\n        auth._default._get_gce_credentials = lambda *args, **kwargs: (None, None)\n    try:\n        yield\n    finally:\n        auth._default._get_gce_credentials = get_gce",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "_client_manager",
        "kind": 5,
        "importPath": "google.generativeai.client",
        "description": "google.generativeai.client",
        "peekOfCode": "_client_manager = _ClientManager()\n_client_manager.configure()\ndef get_default_cache_client() -> glm.CacheServiceClient:\n    return _client_manager.get_default_client(\"cache\")\ndef get_default_discuss_client() -> glm.DiscussServiceClient:\n    return _client_manager.get_default_client(\"discuss\")\ndef get_default_discuss_async_client() -> glm.DiscussServiceAsyncClient:\n    return _client_manager.get_default_client(\"discuss_async\")\ndef get_default_file_client() -> glm.FilesServiceClient:\n    return _client_manager.get_default_client(\"file\")",
        "detail": "google.generativeai.client",
        "documentation": {}
    },
    {
        "label": "ChatResponse",
        "kind": 6,
        "importPath": "google.generativeai.discuss",
        "description": "google.generativeai.discuss",
        "peekOfCode": "class ChatResponse(discuss_types.ChatResponse):\n    _client: glm.DiscussServiceClient | None = dataclasses.field(default=lambda: None, repr=False)\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n    @property\n    @string_utils.set_doc(discuss_types.ChatResponse.last.__doc__)\n    def last(self) -> str | None:\n        if self.messages[-1]:\n            return self.messages[-1][\"content\"]",
        "detail": "google.generativeai.discuss",
        "documentation": {}
    },
    {
        "label": "chat",
        "kind": 2,
        "importPath": "google.generativeai.discuss",
        "description": "google.generativeai.discuss",
        "peekOfCode": "def chat(\n    *,\n    model: model_types.AnyModelNameOptions | None = \"models/chat-bison-001\",\n    context: str | None = None,\n    examples: discuss_types.ExamplesOptions | None = None,\n    messages: discuss_types.MessagesOptions | None = None,\n    temperature: float | None = None,\n    candidate_count: int | None = None,\n    top_p: float | None = None,\n    top_k: float | None = None,",
        "detail": "google.generativeai.discuss",
        "documentation": {}
    },
    {
        "label": "count_message_tokens",
        "kind": 2,
        "importPath": "google.generativeai.discuss",
        "description": "google.generativeai.discuss",
        "peekOfCode": "def count_message_tokens(\n    *,\n    prompt: discuss_types.MessagePromptOptions = None,\n    context: str | None = None,\n    examples: discuss_types.ExamplesOptions | None = None,\n    messages: discuss_types.MessagesOptions | None = None,\n    model: model_types.AnyModelNameOptions = DEFAULT_DISCUSS_MODEL,\n    client: glm.DiscussServiceAsyncClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> discuss_types.TokenCount:",
        "detail": "google.generativeai.discuss",
        "documentation": {}
    },
    {
        "label": "DEFAULT_DISCUSS_MODEL",
        "kind": 5,
        "importPath": "google.generativeai.discuss",
        "description": "google.generativeai.discuss",
        "peekOfCode": "DEFAULT_DISCUSS_MODEL = \"models/chat-bison-001\"\ndef chat(\n    *,\n    model: model_types.AnyModelNameOptions | None = \"models/chat-bison-001\",\n    context: str | None = None,\n    examples: discuss_types.ExamplesOptions | None = None,\n    messages: discuss_types.MessagesOptions | None = None,\n    temperature: float | None = None,\n    candidate_count: int | None = None,\n    top_p: float | None = None,",
        "detail": "google.generativeai.discuss",
        "documentation": {}
    },
    {
        "label": "to_task_type",
        "kind": 2,
        "importPath": "google.generativeai.embedding",
        "description": "google.generativeai.embedding",
        "peekOfCode": "def to_task_type(x: EmbeddingTaskTypeOptions) -> EmbeddingTaskType:\n    if isinstance(x, str):\n        x = x.lower()\n    return _EMBEDDING_TASK_TYPE[x]\ntry:\n    # python 3.12+\n    _batched = itertools.batched  # type: ignore\nexcept AttributeError:\n    T = TypeVar(\"T\")\n    def _batched(iterable: Iterable[T], n: int) -> Iterable[list[T]]:",
        "detail": "google.generativeai.embedding",
        "documentation": {}
    },
    {
        "label": "embed_content",
        "kind": 2,
        "importPath": "google.generativeai.embedding",
        "description": "google.generativeai.embedding",
        "peekOfCode": "def embed_content(\n    model: model_types.BaseModelNameOptions,\n    content: content_types.ContentType,\n    task_type: EmbeddingTaskTypeOptions | None = None,\n    title: str | None = None,\n    output_dimensionality: int | None = None,\n    client: glm.GenerativeServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> text_types.EmbeddingDict: ...\n@overload",
        "detail": "google.generativeai.embedding",
        "documentation": {}
    },
    {
        "label": "embed_content",
        "kind": 2,
        "importPath": "google.generativeai.embedding",
        "description": "google.generativeai.embedding",
        "peekOfCode": "def embed_content(\n    model: model_types.BaseModelNameOptions,\n    content: Iterable[content_types.ContentType],\n    task_type: EmbeddingTaskTypeOptions | None = None,\n    title: str | None = None,\n    output_dimensionality: int | None = None,\n    client: glm.GenerativeServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> text_types.BatchEmbeddingDict: ...\ndef embed_content(",
        "detail": "google.generativeai.embedding",
        "documentation": {}
    },
    {
        "label": "embed_content",
        "kind": 2,
        "importPath": "google.generativeai.embedding",
        "description": "google.generativeai.embedding",
        "peekOfCode": "def embed_content(\n    model: model_types.BaseModelNameOptions,\n    content: content_types.ContentType | Iterable[content_types.ContentType],\n    task_type: EmbeddingTaskTypeOptions | None = None,\n    title: str | None = None,\n    output_dimensionality: int | None = None,\n    client: glm.GenerativeServiceClient = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> text_types.EmbeddingDict | text_types.BatchEmbeddingDict:\n    \"\"\"Calls the API to create embeddings for content passed in.",
        "detail": "google.generativeai.embedding",
        "documentation": {}
    },
    {
        "label": "DEFAULT_EMB_MODEL",
        "kind": 5,
        "importPath": "google.generativeai.embedding",
        "description": "google.generativeai.embedding",
        "peekOfCode": "DEFAULT_EMB_MODEL = \"models/embedding-001\"\nEMBEDDING_MAX_BATCH_SIZE = 100\nEmbeddingTaskType = protos.TaskType\nEmbeddingTaskTypeOptions = Union[int, str, EmbeddingTaskType]\n_EMBEDDING_TASK_TYPE: dict[EmbeddingTaskTypeOptions, EmbeddingTaskType] = {\n    EmbeddingTaskType.TASK_TYPE_UNSPECIFIED: EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    0: EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    \"task_type_unspecified\": EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    \"unspecified\": EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    EmbeddingTaskType.RETRIEVAL_QUERY: EmbeddingTaskType.RETRIEVAL_QUERY,",
        "detail": "google.generativeai.embedding",
        "documentation": {}
    },
    {
        "label": "EMBEDDING_MAX_BATCH_SIZE",
        "kind": 5,
        "importPath": "google.generativeai.embedding",
        "description": "google.generativeai.embedding",
        "peekOfCode": "EMBEDDING_MAX_BATCH_SIZE = 100\nEmbeddingTaskType = protos.TaskType\nEmbeddingTaskTypeOptions = Union[int, str, EmbeddingTaskType]\n_EMBEDDING_TASK_TYPE: dict[EmbeddingTaskTypeOptions, EmbeddingTaskType] = {\n    EmbeddingTaskType.TASK_TYPE_UNSPECIFIED: EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    0: EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    \"task_type_unspecified\": EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    \"unspecified\": EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    EmbeddingTaskType.RETRIEVAL_QUERY: EmbeddingTaskType.RETRIEVAL_QUERY,\n    1: EmbeddingTaskType.RETRIEVAL_QUERY,",
        "detail": "google.generativeai.embedding",
        "documentation": {}
    },
    {
        "label": "EmbeddingTaskType",
        "kind": 5,
        "importPath": "google.generativeai.embedding",
        "description": "google.generativeai.embedding",
        "peekOfCode": "EmbeddingTaskType = protos.TaskType\nEmbeddingTaskTypeOptions = Union[int, str, EmbeddingTaskType]\n_EMBEDDING_TASK_TYPE: dict[EmbeddingTaskTypeOptions, EmbeddingTaskType] = {\n    EmbeddingTaskType.TASK_TYPE_UNSPECIFIED: EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    0: EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    \"task_type_unspecified\": EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    \"unspecified\": EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    EmbeddingTaskType.RETRIEVAL_QUERY: EmbeddingTaskType.RETRIEVAL_QUERY,\n    1: EmbeddingTaskType.RETRIEVAL_QUERY,\n    \"retrieval_query\": EmbeddingTaskType.RETRIEVAL_QUERY,",
        "detail": "google.generativeai.embedding",
        "documentation": {}
    },
    {
        "label": "EmbeddingTaskTypeOptions",
        "kind": 5,
        "importPath": "google.generativeai.embedding",
        "description": "google.generativeai.embedding",
        "peekOfCode": "EmbeddingTaskTypeOptions = Union[int, str, EmbeddingTaskType]\n_EMBEDDING_TASK_TYPE: dict[EmbeddingTaskTypeOptions, EmbeddingTaskType] = {\n    EmbeddingTaskType.TASK_TYPE_UNSPECIFIED: EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    0: EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    \"task_type_unspecified\": EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    \"unspecified\": EmbeddingTaskType.TASK_TYPE_UNSPECIFIED,\n    EmbeddingTaskType.RETRIEVAL_QUERY: EmbeddingTaskType.RETRIEVAL_QUERY,\n    1: EmbeddingTaskType.RETRIEVAL_QUERY,\n    \"retrieval_query\": EmbeddingTaskType.RETRIEVAL_QUERY,\n    \"query\": EmbeddingTaskType.RETRIEVAL_QUERY,",
        "detail": "google.generativeai.embedding",
        "documentation": {}
    },
    {
        "label": "upload_file",
        "kind": 2,
        "importPath": "google.generativeai.files",
        "description": "google.generativeai.files",
        "peekOfCode": "def upload_file(\n    path: str | pathlib.Path | os.PathLike,\n    *,\n    mime_type: str | None = None,\n    name: str | None = None,\n    display_name: str | None = None,\n    resumable: bool = True,\n) -> file_types.File:\n    \"\"\"Calls the API to upload a file using a supported file service.\n    Args:",
        "detail": "google.generativeai.files",
        "documentation": {}
    },
    {
        "label": "list_files",
        "kind": 2,
        "importPath": "google.generativeai.files",
        "description": "google.generativeai.files",
        "peekOfCode": "def list_files(page_size=100) -> Iterable[file_types.File]:\n    \"\"\"Calls the API to list files using a supported file service.\"\"\"\n    client = get_default_file_client()\n    response = client.list_files(protos.ListFilesRequest(page_size=page_size))\n    for proto in response:\n        yield file_types.File(proto)\ndef get_file(name: str) -> file_types.File:\n    \"\"\"Calls the API to retrieve a specified file using a supported file service.\"\"\"\n    if \"/\" not in name:\n        name = f\"files/{name}\"",
        "detail": "google.generativeai.files",
        "documentation": {}
    },
    {
        "label": "get_file",
        "kind": 2,
        "importPath": "google.generativeai.files",
        "description": "google.generativeai.files",
        "peekOfCode": "def get_file(name: str) -> file_types.File:\n    \"\"\"Calls the API to retrieve a specified file using a supported file service.\"\"\"\n    if \"/\" not in name:\n        name = f\"files/{name}\"\n    client = get_default_file_client()\n    return file_types.File(client.get_file(name=name))\ndef delete_file(name: str | file_types.File | protos.File):\n    \"\"\"Calls the API to permanently delete a specified file using a supported file service.\"\"\"\n    if isinstance(name, (file_types.File, protos.File)):\n        name = name.name",
        "detail": "google.generativeai.files",
        "documentation": {}
    },
    {
        "label": "delete_file",
        "kind": 2,
        "importPath": "google.generativeai.files",
        "description": "google.generativeai.files",
        "peekOfCode": "def delete_file(name: str | file_types.File | protos.File):\n    \"\"\"Calls the API to permanently delete a specified file using a supported file service.\"\"\"\n    if isinstance(name, (file_types.File, protos.File)):\n        name = name.name\n    elif \"/\" not in name:\n        name = f\"files/{name}\"\n    request = protos.DeleteFileRequest(name=name)\n    client = get_default_file_client()\n    client.delete_file(request=request)",
        "detail": "google.generativeai.files",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "google.generativeai.files",
        "description": "google.generativeai.files",
        "peekOfCode": "__all__ = [\"upload_file\", \"get_file\", \"list_files\", \"delete_file\"]\ndef upload_file(\n    path: str | pathlib.Path | os.PathLike,\n    *,\n    mime_type: str | None = None,\n    name: str | None = None,\n    display_name: str | None = None,\n    resumable: bool = True,\n) -> file_types.File:\n    \"\"\"Calls the API to upload a file using a supported file service.",
        "detail": "google.generativeai.files",
        "documentation": {}
    },
    {
        "label": "GenerativeModel",
        "kind": 6,
        "importPath": "google.generativeai.generative_models",
        "description": "google.generativeai.generative_models",
        "peekOfCode": "class GenerativeModel:\n    \"\"\"\n    The `genai.GenerativeModel` class wraps default parameters for calls to\n    `GenerativeModel.generate_content`, `GenerativeModel.count_tokens`, and\n    `GenerativeModel.start_chat`.\n    This family of functionality is designed to support multi-turn conversations, and multimodal\n    requests. What media-types are supported for input and output is model-dependant.\n    >>> import google.generativeai as genai\n    >>> import PIL.Image\n    >>> genai.configure(api_key='YOUR_API_KEY')",
        "detail": "google.generativeai.generative_models",
        "documentation": {}
    },
    {
        "label": "ChatSession",
        "kind": 6,
        "importPath": "google.generativeai.generative_models",
        "description": "google.generativeai.generative_models",
        "peekOfCode": "class ChatSession:\n    \"\"\"Contains an ongoing conversation with the model.\n    >>> model = genai.GenerativeModel('models/gemini-pro')\n    >>> chat = model.start_chat()\n    >>> response = chat.send_message(\"Hello\")\n    >>> print(response.text)\n    >>> response = chat.send_message(\"Hello again\")\n    >>> print(response.text)\n    >>> response = chat.send_message(...\n    This `ChatSession` object collects the messages sent and received, in its",
        "detail": "google.generativeai.generative_models",
        "documentation": {}
    },
    {
        "label": "_USER_ROLE",
        "kind": 5,
        "importPath": "google.generativeai.generative_models",
        "description": "google.generativeai.generative_models",
        "peekOfCode": "_USER_ROLE = \"user\"\n_MODEL_ROLE = \"model\"\nclass GenerativeModel:\n    \"\"\"\n    The `genai.GenerativeModel` class wraps default parameters for calls to\n    `GenerativeModel.generate_content`, `GenerativeModel.count_tokens`, and\n    `GenerativeModel.start_chat`.\n    This family of functionality is designed to support multi-turn conversations, and multimodal\n    requests. What media-types are supported for input and output is model-dependant.\n    >>> import google.generativeai as genai",
        "detail": "google.generativeai.generative_models",
        "documentation": {}
    },
    {
        "label": "_MODEL_ROLE",
        "kind": 5,
        "importPath": "google.generativeai.generative_models",
        "description": "google.generativeai.generative_models",
        "peekOfCode": "_MODEL_ROLE = \"model\"\nclass GenerativeModel:\n    \"\"\"\n    The `genai.GenerativeModel` class wraps default parameters for calls to\n    `GenerativeModel.generate_content`, `GenerativeModel.count_tokens`, and\n    `GenerativeModel.start_chat`.\n    This family of functionality is designed to support multi-turn conversations, and multimodal\n    requests. What media-types are supported for input and output is model-dependant.\n    >>> import google.generativeai as genai\n    >>> import PIL.Image",
        "detail": "google.generativeai.generative_models",
        "documentation": {}
    },
    {
        "label": "get_model",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def get_model(\n    name: model_types.AnyModelNameOptions,\n    *,\n    client=None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> model_types.Model | model_types.TunedModel:\n    \"\"\"Calls the API to fetch a model by name.\n    ```\n    import pprint\n    model = genai.get_model('models/gemini-pro')",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "get_base_model",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def get_base_model(\n    name: model_types.BaseModelNameOptions,\n    *,\n    client=None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> model_types.Model:\n    \"\"\"Calls the API to fetch a base model by name.\n    ```\n    import pprint\n    model = genai.get_base_model('models/chat-bison-001')",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "get_tuned_model",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def get_tuned_model(\n    name: model_types.TunedModelNameOptions,\n    *,\n    client=None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> model_types.TunedModel:\n    \"\"\"Calls the API to fetch a tuned model by name.\n    ```\n    import pprint\n    model = genai.get_tuned_model('tunedModels/gemini-1.0-pro-001')",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "get_base_model_name",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def get_base_model_name(\n    model: model_types.AnyModelNameOptions, client: glm.ModelServiceClient | None = None\n):\n    \"\"\"Calls the API to fetch the base model name of a model.\"\"\"\n    if isinstance(model, str):\n        if model.startswith(\"tunedModels/\"):\n            model = get_model(model, client=client)\n            base_model = model.base_model\n        else:\n            base_model = model",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "list_models",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def list_models(\n    *,\n    page_size: int | None = 50,\n    client: glm.ModelServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> model_types.ModelsIterable:\n    \"\"\"Calls the API to list all available models.\n    ```\n    import pprint\n    for model in genai.list_models():",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "list_tuned_models",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def list_tuned_models(\n    *,\n    page_size: int | None = 50,\n    client: glm.ModelServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> model_types.TunedModelsIterable:\n    \"\"\"Calls the API to list all tuned models.\n    ```\n    import pprint\n    for model in genai.list_tuned_models():",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "create_tuned_model",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def create_tuned_model(\n    source_model: model_types.AnyModelNameOptions,\n    training_data: model_types.TuningDataOptions,\n    *,\n    id: str | None = None,\n    display_name: str | None = None,\n    description: str | None = None,\n    temperature: float | None = None,\n    top_p: float | None = None,\n    top_k: int | None = None,",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "update_tuned_model",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def update_tuned_model(\n    tuned_model: protos.TunedModel,\n    updates: None = None,\n    *,\n    client: glm.ModelServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> model_types.TunedModel:\n    pass\n@typing.overload\ndef update_tuned_model(",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "update_tuned_model",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def update_tuned_model(\n    tuned_model: str,\n    updates: dict[str, Any],\n    *,\n    client: glm.ModelServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> model_types.TunedModel:\n    pass\ndef update_tuned_model(\n    tuned_model: str | protos.TunedModel,",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "update_tuned_model",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def update_tuned_model(\n    tuned_model: str | protos.TunedModel,\n    updates: dict[str, Any] | None = None,\n    *,\n    client: glm.ModelServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> model_types.TunedModel:\n    \"\"\"Calls the API to puch updates to a specified tuned model where only certain attributes are updatable.\"\"\"\n    if request_options is None:\n        request_options = {}",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "delete_tuned_model",
        "kind": 2,
        "importPath": "google.generativeai.models",
        "description": "google.generativeai.models",
        "peekOfCode": "def delete_tuned_model(\n    tuned_model: model_types.TunedModelNameOptions,\n    client: glm.ModelServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> None:\n    \"\"\"Calls the API to delete a specified tuned model\"\"\"\n    if request_options is None:\n        request_options = {}\n    if client is None:\n        client = get_default_model_client()",
        "detail": "google.generativeai.models",
        "documentation": {}
    },
    {
        "label": "CreateTunedModelOperation",
        "kind": 6,
        "importPath": "google.generativeai.operations",
        "description": "google.generativeai.operations",
        "peekOfCode": "class CreateTunedModelOperation(operation_lib.Operation):\n    @classmethod\n    def from_proto(cls, proto, client):\n        \"\"\"\n        result = getattr(proto, 'result', None)\n        if result is not None:\n            if result.value == b'':\n                del proto.result\n        \"\"\"\n        return from_gapic(",
        "detail": "google.generativeai.operations",
        "documentation": {}
    },
    {
        "label": "list_operations",
        "kind": 2,
        "importPath": "google.generativeai.operations",
        "description": "google.generativeai.operations",
        "peekOfCode": "def list_operations(*, client=None) -> Iterator[CreateTunedModelOperation]:\n    \"\"\"Calls the API to list all operations\"\"\"\n    if client is None:\n        client = client_lib.get_default_operations_client()\n    # The client returns an iterator of Operation protos (`Iterator[google.longrunning.operations_pb2.Operation]`)\n    # not a gapic Operation object (`google.api_core.operation.Operation`)\n    operations = (\n        CreateTunedModelOperation.from_proto(op, client)\n        for op in client.list_operations(name=\"\", filter_=\"\")\n    )",
        "detail": "google.generativeai.operations",
        "documentation": {}
    },
    {
        "label": "get_operation",
        "kind": 2,
        "importPath": "google.generativeai.operations",
        "description": "google.generativeai.operations",
        "peekOfCode": "def get_operation(name: str, *, client=None) -> CreateTunedModelOperation:\n    \"\"\"Calls the API to get a specific operation\"\"\"\n    if client is None:\n        client = client_lib.get_default_operations_client()\n    op = client.get_operation(name=name)\n    return CreateTunedModelOperation.from_proto(op, client)\ndef delete_operation(name: str, *, client=None):\n    \"\"\"Calls the API to delete a specific operation\"\"\"\n    # Raises:google.api_core.exceptions.MethodNotImplemented: Not implemented.\n    if client is None:",
        "detail": "google.generativeai.operations",
        "documentation": {}
    },
    {
        "label": "delete_operation",
        "kind": 2,
        "importPath": "google.generativeai.operations",
        "description": "google.generativeai.operations",
        "peekOfCode": "def delete_operation(name: str, *, client=None):\n    \"\"\"Calls the API to delete a specific operation\"\"\"\n    # Raises:google.api_core.exceptions.MethodNotImplemented: Not implemented.\n    if client is None:\n        client = client_lib.get_default_operations_client()\n    return client.delete_operation(name=name)\nclass CreateTunedModelOperation(operation_lib.Operation):\n    @classmethod\n    def from_proto(cls, proto, client):\n        \"\"\"",
        "detail": "google.generativeai.operations",
        "documentation": {}
    },
    {
        "label": "from_gapic",
        "kind": 2,
        "importPath": "google.generativeai.operations",
        "description": "google.generativeai.operations",
        "peekOfCode": "def from_gapic(\n    cls,\n    *,\n    operation,\n    operations_client,\n    result_type,\n    metadata_type,\n    grpc_metadata=None,\n    **kwargs,\n):",
        "detail": "google.generativeai.operations",
        "documentation": {}
    },
    {
        "label": "get_permission",
        "kind": 2,
        "importPath": "google.generativeai.permission",
        "description": "google.generativeai.permission",
        "peekOfCode": "def get_permission(\n    name: str | None = None,\n    *,\n    client: glm.PermissionServiceClient | None = None,\n    resource_name: str | None = None,\n    permission_id: str | int | None = None,\n    resource_type: str | None = None,\n) -> permission_types.Permission:\n    \"\"\"Calls the API to retrieve detailed information about a specific permission based on resource type and permission identifiers\n    Args:",
        "detail": "google.generativeai.permission",
        "documentation": {}
    },
    {
        "label": "FunctionDeclaration",
        "kind": 6,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "class FunctionDeclaration:\n    def __init__(self, *, name: str, description: str, parameters: dict[str, Any] | None = None):\n        \"\"\"A  class wrapping a `protos.FunctionDeclaration`, describes a function for `genai.GenerativeModel`'s `tools`.\"\"\"\n        self._proto = protos.FunctionDeclaration(\n            name=name, description=description, parameters=_rename_schema_fields(parameters)\n        )\n    @property\n    def name(self) -> str:\n        return self._proto.name\n    @property",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "CallableFunctionDeclaration",
        "kind": 6,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "class CallableFunctionDeclaration(FunctionDeclaration):\n    \"\"\"An extension of `FunctionDeclaration` that can be built from a Python function, and is callable.\n    Note: The Python function must have type annotations.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        name: str,\n        description: str,\n        parameters: dict[str, Any] | None = None,",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "Tool",
        "kind": 6,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "class Tool:\n    \"\"\"A wrapper for `protos.Tool`, Contains a collection of related `FunctionDeclaration` objects.\"\"\"\n    def __init__(self, function_declarations: Iterable[FunctionDeclarationType]):\n        # The main path doesn't use this but is seems useful.\n        self._function_declarations = [_make_function_declaration(f) for f in function_declarations]\n        self._index = {}\n        for fd in self._function_declarations:\n            name = fd.name\n            if name in self._index:\n                raise ValueError(\"\")",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "ToolDict",
        "kind": 6,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "class ToolDict(TypedDict):\n    function_declarations: list[FunctionDeclarationType]\nToolType = Union[\n    Tool, protos.Tool, ToolDict, Iterable[FunctionDeclarationType], FunctionDeclarationType\n]\ndef _make_tool(tool: ToolType) -> Tool:\n    if isinstance(tool, Tool):\n        return tool\n    elif isinstance(tool, protos.Tool):\n        return Tool(function_declarations=tool.function_declarations)",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "FunctionLibrary",
        "kind": 6,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "class FunctionLibrary:\n    \"\"\"A container for a set of `Tool` objects, manages lookup and execution of their functions.\"\"\"\n    def __init__(self, tools: Iterable[ToolType]):\n        tools = _make_tools(tools)\n        self._tools = list(tools)\n        self._index = {}\n        for tool in self._tools:\n            for declaration in tool.function_declarations:\n                name = declaration.name\n                if name in self._index:",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "FunctionCallingConfigDict",
        "kind": 6,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "class FunctionCallingConfigDict(TypedDict):\n    mode: FunctionCallingModeType\n    allowed_function_names: list[str]\nFunctionCallingConfigType = Union[\n    FunctionCallingModeType, FunctionCallingConfigDict, protos.FunctionCallingConfig\n]\ndef to_function_calling_config(obj: FunctionCallingConfigType) -> protos.FunctionCallingConfig:\n    if isinstance(obj, protos.FunctionCallingConfig):\n        return obj\n    elif isinstance(obj, (FunctionCallingMode, str, int)):",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "ToolConfigDict",
        "kind": 6,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "class ToolConfigDict:\n    function_calling_config: FunctionCallingConfigType\nToolConfigType = Union[ToolConfigDict, protos.ToolConfig]\ndef to_tool_config(obj: ToolConfigType) -> protos.ToolConfig:\n    if isinstance(obj, protos.ToolConfig):\n        return obj\n    elif isinstance(obj, dict):\n        fcc = obj.pop(\"function_calling_config\")\n        fcc = to_function_calling_config(fcc)\n        obj[\"function_calling_config\"] = fcc",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "to_type",
        "kind": 2,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "def to_type(x: TypeOptions) -> Type:\n    if isinstance(x, str):\n        x = x.lower()\n    return _TYPE_TYPE[x]\ndef _generate_schema(\n    f: Callable[..., Any],\n    *,\n    descriptions: Mapping[str, str] | None = None,\n    required: Sequence[str] | None = None,\n) -> dict[str, Any]:",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "to_function_library",
        "kind": 2,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "def to_function_library(lib: FunctionLibraryType | None) -> FunctionLibrary | None:\n    if lib is None:\n        return lib\n    elif isinstance(lib, FunctionLibrary):\n        return lib\n    else:\n        return FunctionLibrary(tools=lib)\nFunctionCallingMode = protos.FunctionCallingConfig.Mode\n# fmt: off\n_FUNCTION_CALLING_MODE = {",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "to_function_calling_mode",
        "kind": 2,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "def to_function_calling_mode(x: FunctionCallingModeType) -> FunctionCallingMode:\n    if isinstance(x, str):\n        x = x.lower()\n    return _FUNCTION_CALLING_MODE[x]\nclass FunctionCallingConfigDict(TypedDict):\n    mode: FunctionCallingModeType\n    allowed_function_names: list[str]\nFunctionCallingConfigType = Union[\n    FunctionCallingModeType, FunctionCallingConfigDict, protos.FunctionCallingConfig\n]",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "to_function_calling_config",
        "kind": 2,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "def to_function_calling_config(obj: FunctionCallingConfigType) -> protos.FunctionCallingConfig:\n    if isinstance(obj, protos.FunctionCallingConfig):\n        return obj\n    elif isinstance(obj, (FunctionCallingMode, str, int)):\n        obj = {\"mode\": to_function_calling_mode(obj)}\n    elif isinstance(obj, dict):\n        obj = obj.copy()\n        mode = obj.pop(\"mode\")\n        obj[\"mode\"] = to_function_calling_mode(mode)\n    else:",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "to_tool_config",
        "kind": 2,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "def to_tool_config(obj: ToolConfigType) -> protos.ToolConfig:\n    if isinstance(obj, protos.ToolConfig):\n        return obj\n    elif isinstance(obj, dict):\n        fcc = obj.pop(\"function_calling_config\")\n        fcc = to_function_calling_config(fcc)\n        obj[\"function_calling_config\"] = fcc\n        return protos.ToolConfig(**obj)\n    else:\n        raise TypeError(",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "Type",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "Type = protos.Type\nTypeOptions = Union[int, str, Type]\n_TYPE_TYPE: dict[TypeOptions, Type] = {\n    Type.TYPE_UNSPECIFIED: Type.TYPE_UNSPECIFIED,\n    0: Type.TYPE_UNSPECIFIED,\n    \"type_unspecified\": Type.TYPE_UNSPECIFIED,\n    \"unspecified\": Type.TYPE_UNSPECIFIED,\n    Type.STRING: Type.STRING,\n    1: Type.STRING,\n    \"type_string\": Type.STRING,",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "TypeOptions",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "TypeOptions = Union[int, str, Type]\n_TYPE_TYPE: dict[TypeOptions, Type] = {\n    Type.TYPE_UNSPECIFIED: Type.TYPE_UNSPECIFIED,\n    0: Type.TYPE_UNSPECIFIED,\n    \"type_unspecified\": Type.TYPE_UNSPECIFIED,\n    \"unspecified\": Type.TYPE_UNSPECIFIED,\n    Type.STRING: Type.STRING,\n    1: Type.STRING,\n    \"type_string\": Type.STRING,\n    \"string\": Type.STRING,",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "StructType",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "StructType = dict[str, \"ValueType\"]\nValueType = Union[float, str, bool, StructType, list[\"ValueType\"], None]\nclass CallableFunctionDeclaration(FunctionDeclaration):\n    \"\"\"An extension of `FunctionDeclaration` that can be built from a Python function, and is callable.\n    Note: The Python function must have type annotations.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        name: str,",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "ValueType",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "ValueType = Union[float, str, bool, StructType, list[\"ValueType\"], None]\nclass CallableFunctionDeclaration(FunctionDeclaration):\n    \"\"\"An extension of `FunctionDeclaration` that can be built from a Python function, and is callable.\n    Note: The Python function must have type annotations.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        name: str,\n        description: str,",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "FunctionDeclarationType",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "FunctionDeclarationType = Union[\n    FunctionDeclaration,\n    protos.FunctionDeclaration,\n    dict[str, Any],\n    Callable[..., Any],\n]\ndef _make_function_declaration(\n    fun: FunctionDeclarationType,\n) -> FunctionDeclaration | protos.FunctionDeclaration:\n    if isinstance(fun, (FunctionDeclaration, protos.FunctionDeclaration)):",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "ToolType",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "ToolType = Union[\n    Tool, protos.Tool, ToolDict, Iterable[FunctionDeclarationType], FunctionDeclarationType\n]\ndef _make_tool(tool: ToolType) -> Tool:\n    if isinstance(tool, Tool):\n        return tool\n    elif isinstance(tool, protos.Tool):\n        return Tool(function_declarations=tool.function_declarations)\n    elif isinstance(tool, dict):\n        if \"function_declarations\" in tool:",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "ToolsType",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "ToolsType = Union[Iterable[ToolType], ToolType]\ndef _make_tools(tools: ToolsType) -> list[Tool]:\n    if isinstance(tools, Iterable) and not isinstance(tools, Mapping):\n        tools = [_make_tool(t) for t in tools]\n        if len(tools) > 1 and all(len(t.function_declarations) == 1 for t in tools):\n            # flatten into a single tool.\n            tools = [_make_tool([t.function_declarations[0] for t in tools])]\n        return tools\n    else:\n        tool = tools",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "FunctionLibraryType",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "FunctionLibraryType = Union[FunctionLibrary, ToolsType]\ndef to_function_library(lib: FunctionLibraryType | None) -> FunctionLibrary | None:\n    if lib is None:\n        return lib\n    elif isinstance(lib, FunctionLibrary):\n        return lib\n    else:\n        return FunctionLibrary(tools=lib)\nFunctionCallingMode = protos.FunctionCallingConfig.Mode\n# fmt: off",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "FunctionCallingMode",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "FunctionCallingMode = protos.FunctionCallingConfig.Mode\n# fmt: off\n_FUNCTION_CALLING_MODE = {\n    1: FunctionCallingMode.AUTO,\n    FunctionCallingMode.AUTO: FunctionCallingMode.AUTO,\n    \"mode_auto\": FunctionCallingMode.AUTO,\n    \"auto\": FunctionCallingMode.AUTO,\n    2: FunctionCallingMode.ANY,\n    FunctionCallingMode.ANY: FunctionCallingMode.ANY,\n    \"mode_any\": FunctionCallingMode.ANY,",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "_FUNCTION_CALLING_MODE",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "_FUNCTION_CALLING_MODE = {\n    1: FunctionCallingMode.AUTO,\n    FunctionCallingMode.AUTO: FunctionCallingMode.AUTO,\n    \"mode_auto\": FunctionCallingMode.AUTO,\n    \"auto\": FunctionCallingMode.AUTO,\n    2: FunctionCallingMode.ANY,\n    FunctionCallingMode.ANY: FunctionCallingMode.ANY,\n    \"mode_any\": FunctionCallingMode.ANY,\n    \"any\": FunctionCallingMode.ANY,\n    3: FunctionCallingMode.NONE,",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "FunctionCallingModeType",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "FunctionCallingModeType = Union[FunctionCallingMode, str, int]\ndef to_function_calling_mode(x: FunctionCallingModeType) -> FunctionCallingMode:\n    if isinstance(x, str):\n        x = x.lower()\n    return _FUNCTION_CALLING_MODE[x]\nclass FunctionCallingConfigDict(TypedDict):\n    mode: FunctionCallingModeType\n    allowed_function_names: list[str]\nFunctionCallingConfigType = Union[\n    FunctionCallingModeType, FunctionCallingConfigDict, protos.FunctionCallingConfig",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "FunctionCallingConfigType",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "FunctionCallingConfigType = Union[\n    FunctionCallingModeType, FunctionCallingConfigDict, protos.FunctionCallingConfig\n]\ndef to_function_calling_config(obj: FunctionCallingConfigType) -> protos.FunctionCallingConfig:\n    if isinstance(obj, protos.FunctionCallingConfig):\n        return obj\n    elif isinstance(obj, (FunctionCallingMode, str, int)):\n        obj = {\"mode\": to_function_calling_mode(obj)}\n    elif isinstance(obj, dict):\n        obj = obj.copy()",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "ToolConfigType",
        "kind": 5,
        "importPath": "google.generativeai.responder",
        "description": "google.generativeai.responder",
        "peekOfCode": "ToolConfigType = Union[ToolConfigDict, protos.ToolConfig]\ndef to_tool_config(obj: ToolConfigType) -> protos.ToolConfig:\n    if isinstance(obj, protos.ToolConfig):\n        return obj\n    elif isinstance(obj, dict):\n        fcc = obj.pop(\"function_calling_config\")\n        fcc = to_function_calling_config(fcc)\n        obj[\"function_calling_config\"] = fcc\n        return protos.ToolConfig(**obj)\n    else:",
        "detail": "google.generativeai.responder",
        "documentation": {}
    },
    {
        "label": "create_corpus",
        "kind": 2,
        "importPath": "google.generativeai.retriever",
        "description": "google.generativeai.retriever",
        "peekOfCode": "def create_corpus(\n    name: str | None = None,\n    display_name: str | None = None,\n    client: glm.RetrieverServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> retriever_types.Corpus:\n    \"\"\"Calls the API to create a new `Corpus` by specifying either a corpus resource name as an ID or a display name, and returns the created `Corpus`.\n    Args:\n        name: The corpus resource name (ID). The name must be alphanumeric and fewer\n            than 40 characters.",
        "detail": "google.generativeai.retriever",
        "documentation": {}
    },
    {
        "label": "get_corpus",
        "kind": 2,
        "importPath": "google.generativeai.retriever",
        "description": "google.generativeai.retriever",
        "peekOfCode": "def get_corpus(\n    name: str,\n    client: glm.RetrieverServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> retriever_types.Corpus:  # fmt: skip\n    \"\"\"Calls the API to fetch a `Corpus` by name and returns the `Corpus`.\n    Args:\n        name: The `Corpus` name.\n        request_options: Options for the request.\n    Return:",
        "detail": "google.generativeai.retriever",
        "documentation": {}
    },
    {
        "label": "delete_corpus",
        "kind": 2,
        "importPath": "google.generativeai.retriever",
        "description": "google.generativeai.retriever",
        "peekOfCode": "def delete_corpus(\n    name: str,\n    force: bool = False,\n    client: glm.RetrieverServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n):  # fmt: skip\n    \"\"\"Calls the API to remove a `Corpus` from the service, optionally deleting associated `Document`s and objects if the `force` parameter is set to true.\n    Args:\n        name: The `Corpus` name.\n        force: If set to true, any `Document`s and objects related to this `Corpus` will also be deleted.",
        "detail": "google.generativeai.retriever",
        "documentation": {}
    },
    {
        "label": "list_corpora",
        "kind": 2,
        "importPath": "google.generativeai.retriever",
        "description": "google.generativeai.retriever",
        "peekOfCode": "def list_corpora(\n    *,\n    page_size: Optional[int] = None,\n    client: glm.RetrieverServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> Iterable[retriever_types.Corpus]:\n    \"\"\"Calls the API to list all `Corpora` in the service and returns a list of paginated `Corpora`.\n    Args:\n        page_size: Maximum number of `Corpora` to request.\n        page_token: A page token, received from a previous ListCorpora call.",
        "detail": "google.generativeai.retriever",
        "documentation": {}
    },
    {
        "label": "set_doc",
        "kind": 2,
        "importPath": "google.generativeai.string_utils",
        "description": "google.generativeai.string_utils",
        "peekOfCode": "def set_doc(doc):\n    \"\"\"A decorator to set the docstring of a function.\"\"\"\n    def inner(f):\n        f.__doc__ = doc\n        return f\n    return inner\ndef strip_oneof(docstring):\n    lines = docstring.splitlines()\n    lines = [line for line in lines if \".. _oneof:\" not in line]\n    lines = [line for line in lines if \"This field is a member of `oneof`_\" not in line]",
        "detail": "google.generativeai.string_utils",
        "documentation": {}
    },
    {
        "label": "strip_oneof",
        "kind": 2,
        "importPath": "google.generativeai.string_utils",
        "description": "google.generativeai.string_utils",
        "peekOfCode": "def strip_oneof(docstring):\n    lines = docstring.splitlines()\n    lines = [line for line in lines if \".. _oneof:\" not in line]\n    lines = [line for line in lines if \"This field is a member of `oneof`_\" not in line]\n    return \"\\n\".join(lines)\ndef prettyprint(cls):\n    cls.__str__ = _prettyprint\n    cls.__repr__ = _prettyprint\n    return cls\nrepr = reprlib.Repr()",
        "detail": "google.generativeai.string_utils",
        "documentation": {}
    },
    {
        "label": "prettyprint",
        "kind": 2,
        "importPath": "google.generativeai.string_utils",
        "description": "google.generativeai.string_utils",
        "peekOfCode": "def prettyprint(cls):\n    cls.__str__ = _prettyprint\n    cls.__repr__ = _prettyprint\n    return cls\nrepr = reprlib.Repr()\n@reprlib.recursive_repr()\ndef _prettyprint(self):\n    \"\"\"A dataclass prettyprint function you can use in __str__or __repr__.\n    Note: You can't set `__str__ = pprint.pformat` because it causes a recursion error.\n    Mostly identical to pprint but:",
        "detail": "google.generativeai.string_utils",
        "documentation": {}
    },
    {
        "label": "repr",
        "kind": 5,
        "importPath": "google.generativeai.string_utils",
        "description": "google.generativeai.string_utils",
        "peekOfCode": "repr = reprlib.Repr()\n@reprlib.recursive_repr()\ndef _prettyprint(self):\n    \"\"\"A dataclass prettyprint function you can use in __str__or __repr__.\n    Note: You can't set `__str__ = pprint.pformat` because it causes a recursion error.\n    Mostly identical to pprint but:\n    * This will contract long lists and dicts (> 10lines) to [...] and {...}.\n    * This will contract long object reprs to ClassName(...).\n    \"\"\"\n    fields = []",
        "detail": "google.generativeai.string_utils",
        "documentation": {}
    },
    {
        "label": "Completion",
        "kind": 6,
        "importPath": "google.generativeai.text",
        "description": "google.generativeai.text",
        "peekOfCode": "class Completion(text_types.Completion):\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n        self.result = None\n        if self.candidates:\n            self.result = self.candidates[0][\"output\"]\ndef _generate_response(\n    request: protos.GenerateTextRequest,\n    client: glm.TextServiceClient = None,",
        "detail": "google.generativeai.text",
        "documentation": {}
    },
    {
        "label": "generate_text",
        "kind": 2,
        "importPath": "google.generativeai.text",
        "description": "google.generativeai.text",
        "peekOfCode": "def generate_text(\n    *,\n    model: model_types.AnyModelNameOptions = DEFAULT_TEXT_MODEL,\n    prompt: str,\n    temperature: float | None = None,\n    candidate_count: int | None = None,\n    max_output_tokens: int | None = None,\n    top_p: float | None = None,\n    top_k: float | None = None,\n    safety_settings: palm_safety_types.SafetySettingOptions | None = None,",
        "detail": "google.generativeai.text",
        "documentation": {}
    },
    {
        "label": "count_text_tokens",
        "kind": 2,
        "importPath": "google.generativeai.text",
        "description": "google.generativeai.text",
        "peekOfCode": "def count_text_tokens(\n    model: model_types.AnyModelNameOptions,\n    prompt: str,\n    client: glm.TextServiceClient | None = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> text_types.TokenCount:\n    \"\"\"Calls the API to count the number of tokens in the text prompt.\"\"\"\n    base_model = models.get_base_model_name(model)\n    if request_options is None:\n        request_options = {}",
        "detail": "google.generativeai.text",
        "documentation": {}
    },
    {
        "label": "generate_embeddings",
        "kind": 2,
        "importPath": "google.generativeai.text",
        "description": "google.generativeai.text",
        "peekOfCode": "def generate_embeddings(\n    model: model_types.BaseModelNameOptions,\n    text: str,\n    client: glm.TextServiceClient = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> text_types.EmbeddingDict: ...\n@overload\ndef generate_embeddings(\n    model: model_types.BaseModelNameOptions,\n    text: Sequence[str],",
        "detail": "google.generativeai.text",
        "documentation": {}
    },
    {
        "label": "generate_embeddings",
        "kind": 2,
        "importPath": "google.generativeai.text",
        "description": "google.generativeai.text",
        "peekOfCode": "def generate_embeddings(\n    model: model_types.BaseModelNameOptions,\n    text: Sequence[str],\n    client: glm.TextServiceClient = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> text_types.BatchEmbeddingDict: ...\ndef generate_embeddings(\n    model: model_types.BaseModelNameOptions,\n    text: str | Sequence[str],\n    client: glm.TextServiceClient = None,",
        "detail": "google.generativeai.text",
        "documentation": {}
    },
    {
        "label": "generate_embeddings",
        "kind": 2,
        "importPath": "google.generativeai.text",
        "description": "google.generativeai.text",
        "peekOfCode": "def generate_embeddings(\n    model: model_types.BaseModelNameOptions,\n    text: str | Sequence[str],\n    client: glm.TextServiceClient = None,\n    request_options: helper_types.RequestOptionsType | None = None,\n) -> text_types.EmbeddingDict | text_types.BatchEmbeddingDict:\n    \"\"\"Calls the API to create an embedding for the text passed in.\n    Args:\n        model: Which model to call, as a string or a `types.Model`.\n        text: Free-form input text given to the model. Given a string, the model will",
        "detail": "google.generativeai.text",
        "documentation": {}
    },
    {
        "label": "DEFAULT_TEXT_MODEL",
        "kind": 5,
        "importPath": "google.generativeai.text",
        "description": "google.generativeai.text",
        "peekOfCode": "DEFAULT_TEXT_MODEL = \"models/text-bison-001\"\nEMBEDDING_MAX_BATCH_SIZE = 100\ntry:\n    # python 3.12+\n    _batched = itertools.batched  # type: ignore\nexcept AttributeError:\n    T = TypeVar(\"T\")\n    def _batched(iterable: Iterable[T], n: int) -> Iterable[list[T]]:\n        if n < 1:\n            raise ValueError(f\"Batch size `n` must be >1, got: {n}\")",
        "detail": "google.generativeai.text",
        "documentation": {}
    },
    {
        "label": "EMBEDDING_MAX_BATCH_SIZE",
        "kind": 5,
        "importPath": "google.generativeai.text",
        "description": "google.generativeai.text",
        "peekOfCode": "EMBEDDING_MAX_BATCH_SIZE = 100\ntry:\n    # python 3.12+\n    _batched = itertools.batched  # type: ignore\nexcept AttributeError:\n    T = TypeVar(\"T\")\n    def _batched(iterable: Iterable[T], n: int) -> Iterable[list[T]]:\n        if n < 1:\n            raise ValueError(f\"Batch size `n` must be >1, got: {n}\")\n        batch = []",
        "detail": "google.generativeai.text",
        "documentation": {}
    },
    {
        "label": "flatten_update_paths",
        "kind": 2,
        "importPath": "google.generativeai.utils",
        "description": "google.generativeai.utils",
        "peekOfCode": "def flatten_update_paths(updates):\n    \"\"\"Flattens a nested dictionary into a single level dictionary, with keys representing the original path.\"\"\"\n    new_updates = {}\n    for key, value in updates.items():\n        if isinstance(value, dict):\n            for sub_key, sub_value in flatten_update_paths(value).items():\n                new_updates[f\"{key}.{sub_key}\"] = sub_value\n        else:\n            new_updates[key] = value\n    return new_updates",
        "detail": "google.generativeai.utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "google.generativeai.version",
        "description": "google.generativeai.version",
        "peekOfCode": "__version__ = \"0.7.0\"",
        "detail": "google.generativeai.version",
        "documentation": {}
    },
    {
        "label": "_MockModel",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "class _MockModel(model_lib.AbstractModel):\n    \"\"\"Mock model that returns a caller-provided result.\"\"\"\n    def __init__(self, mock_results: Sequence[str]):\n        self._mock_results = mock_results\n    def call_model(\n        self,\n        model_input: str,\n        model_args: model_lib.ModelArguments | None = None,\n    ) -> model_lib.ModelResults:\n        return model_lib.ModelResults(model_input=model_input, text_results=self._mock_results)",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "_MockInputsSource",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "class _MockInputsSource(llmfn_inputs_source.LLMFnInputsSource):\n    def _to_normalized_inputs_impl(\n        self,\n    ) -> tuple[Sequence[Mapping[str, str]], Callable[[], None]]:\n        return [\n            {\"word_one\": \"apple\", \"word_two\": \"banana\"},\n            {\"word_one\": \"australia\", \"word_two\": \"brazil\"},\n        ], lambda: None\nclass LLMFunctionBasicTest(absltest.TestCase):\n    \"\"\"Test basic functionality such as execution and input-handling.\"\"\"",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "LLMFunctionBasicTest",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "class LLMFunctionBasicTest(absltest.TestCase):\n    \"\"\"Test basic functionality such as execution and input-handling.\"\"\"\n    def _test_is_callable(\n        self,\n        llm_fn: Callable[[Sequence[tuple[str, str]] | None], LLMFnOutputs],\n    ) -> LLMFnOutputs:\n        return llm_fn(None)\n    def test_run(self):\n        llm_fn = LLMFunctionImpl(\n            model=model_lib.EchoModel(),",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "LLMFunctionPostProcessTest",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "class LLMFunctionPostProcessTest(absltest.TestCase):\n    \"\"\"Test post-processing features.\"\"\"\n    def test_add_post_process_reorder_fn(self):\n        llm_fn = LLMFunctionImpl(\n            model=_MockModel(\n                mock_results=[\"cold\", \"freezing\", \"chilly\"],\n            ),\n            prompts=[\"The opposite of {word} is\"],\n        )\n        # Reverse the order of rows.",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "LLMCompareFunctionTest",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "class LLMCompareFunctionTest(absltest.TestCase):\n    \"\"\"Test LLMCompareFunction.\"\"\"\n    def test_basic_run(self):\n        \"\"\"Basic comparison test.\"\"\"\n        lhs_fn = LLMFunctionImpl(\n            model=model_lib.EchoModel(),\n            prompts=[\"lhs_{word}\"],\n        )\n        rhs_fn = LLMFunctionImpl(\n            model=model_lib.EchoModel(),",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "LLMCompareFunction",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "LLMCompareFunction = llm_function.LLMCompareFunction\nLLMFunctionImpl = llm_function.LLMFunctionImpl\nLLMFnOutputs = llmfn_outputs.LLMFnOutputs\nLLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\nLLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nclass _MockModel(model_lib.AbstractModel):\n    \"\"\"Mock model that returns a caller-provided result.\"\"\"\n    def __init__(self, mock_results: Sequence[str]):\n        self._mock_results = mock_results\n    def call_model(",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "LLMFunctionImpl",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "LLMFunctionImpl = llm_function.LLMFunctionImpl\nLLMFnOutputs = llmfn_outputs.LLMFnOutputs\nLLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\nLLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nclass _MockModel(model_lib.AbstractModel):\n    \"\"\"Mock model that returns a caller-provided result.\"\"\"\n    def __init__(self, mock_results: Sequence[str]):\n        self._mock_results = mock_results\n    def call_model(\n        self,",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputs",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "LLMFnOutputs = llmfn_outputs.LLMFnOutputs\nLLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\nLLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nclass _MockModel(model_lib.AbstractModel):\n    \"\"\"Mock model that returns a caller-provided result.\"\"\"\n    def __init__(self, mock_results: Sequence[str]):\n        self._mock_results = mock_results\n    def call_model(\n        self,\n        model_input: str,",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRow",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "LLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\nLLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nclass _MockModel(model_lib.AbstractModel):\n    \"\"\"Mock model that returns a caller-provided result.\"\"\"\n    def __init__(self, mock_results: Sequence[str]):\n        self._mock_results = mock_results\n    def call_model(\n        self,\n        model_input: str,\n        model_args: model_lib.ModelArguments | None = None,",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRowView",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llm_function",
        "description": "tests.notebook.lib.test_llm_function",
        "peekOfCode": "LLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nclass _MockModel(model_lib.AbstractModel):\n    \"\"\"Mock model that returns a caller-provided result.\"\"\"\n    def __init__(self, mock_results: Sequence[str]):\n        self._mock_results = mock_results\n    def call_model(\n        self,\n        model_input: str,\n        model_args: model_lib.ModelArguments | None = None,\n    ) -> model_lib.ModelResults:",
        "detail": "tests.notebook.lib.test_llm_function",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRowTest",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_llmfn_output_row",
        "description": "tests.notebook.lib.test_llmfn_output_row",
        "peekOfCode": "class LLMFnOutputRowTest(absltest.TestCase):\n    def _test_is_mapping_impl(self, row: Mapping[str, Any]) -> int:\n        \"\"\"Dummy function that asserts that a LLMFnOutputRow is a Mapping.\"\"\"\n        count = 0\n        for _ in row:\n            count = count + 1\n        return count\n    def test_is_mapping(self):\n        row = LLMFnOutputRow(data={\"result\": \"none\"}, result_type=str)\n        self.assertLen(row, self._test_is_mapping_impl(row))",
        "detail": "tests.notebook.lib.test_llmfn_output_row",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRow",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_output_row",
        "description": "tests.notebook.lib.test_llmfn_output_row",
        "peekOfCode": "LLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\nclass LLMFnOutputRowTest(absltest.TestCase):\n    def _test_is_mapping_impl(self, row: Mapping[str, Any]) -> int:\n        \"\"\"Dummy function that asserts that a LLMFnOutputRow is a Mapping.\"\"\"\n        count = 0\n        for _ in row:\n            count = count + 1\n        return count\n    def test_is_mapping(self):\n        row = LLMFnOutputRow(data={\"result\": \"none\"}, result_type=str)",
        "detail": "tests.notebook.lib.test_llmfn_output_row",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputsTest",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_llmfn_outputs",
        "description": "tests.notebook.lib.test_llmfn_outputs",
        "peekOfCode": "class LLMFnOutputsTest(absltest.TestCase):\n    def _test_is_sequence(self, outputs: Sequence[LLMFnOutputEntry]):\n        # Make sure `outputs` is iterable.\n        count = 0\n        for _ in outputs:\n            count = count + 1\n        # Make sure len(outputs) works.\n        self.assertLen(outputs, count)\n        # Make sure regular integer indices are accepted.\n        self.assertIsInstance(outputs[0], LLMFnOutputEntry)",
        "detail": "tests.notebook.lib.test_llmfn_outputs",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputEntry",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_outputs",
        "description": "tests.notebook.lib.test_llmfn_outputs",
        "peekOfCode": "LLMFnOutputEntry = llmfn_outputs.LLMFnOutputEntry\nLLMFnOutputs = llmfn_outputs.LLMFnOutputs\nLLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\ndef _get_empty_model_results() -> model_lib.ModelResults:\n    return model_lib.ModelResults(model_input=\"\", text_results=[])\nclass LLMFnOutputsTest(absltest.TestCase):\n    def _test_is_sequence(self, outputs: Sequence[LLMFnOutputEntry]):\n        # Make sure `outputs` is iterable.\n        count = 0\n        for _ in outputs:",
        "detail": "tests.notebook.lib.test_llmfn_outputs",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputs",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_outputs",
        "description": "tests.notebook.lib.test_llmfn_outputs",
        "peekOfCode": "LLMFnOutputs = llmfn_outputs.LLMFnOutputs\nLLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\ndef _get_empty_model_results() -> model_lib.ModelResults:\n    return model_lib.ModelResults(model_input=\"\", text_results=[])\nclass LLMFnOutputsTest(absltest.TestCase):\n    def _test_is_sequence(self, outputs: Sequence[LLMFnOutputEntry]):\n        # Make sure `outputs` is iterable.\n        count = 0\n        for _ in outputs:\n            count = count + 1",
        "detail": "tests.notebook.lib.test_llmfn_outputs",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRow",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_outputs",
        "description": "tests.notebook.lib.test_llmfn_outputs",
        "peekOfCode": "LLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\ndef _get_empty_model_results() -> model_lib.ModelResults:\n    return model_lib.ModelResults(model_input=\"\", text_results=[])\nclass LLMFnOutputsTest(absltest.TestCase):\n    def _test_is_sequence(self, outputs: Sequence[LLMFnOutputEntry]):\n        # Make sure `outputs` is iterable.\n        count = 0\n        for _ in outputs:\n            count = count + 1\n        # Make sure len(outputs) works.",
        "detail": "tests.notebook.lib.test_llmfn_outputs",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessCmdTest",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "description": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "peekOfCode": "class LLMFnPostProcessCmdTest(absltest.TestCase):\n    def test_post_process_reorder_cmd_bad_index_duplicate_indices(self):\n        def bad_index_fn(rows: Sequence[LLMFnOutputRowView]) -> Sequence[int]:\n            del rows\n            return [0, 0]\n        cmd = LLMFnPostProcessReorderCommand(name=\"test\", fn=bad_index_fn)\n        expected_msg = 'Error executing \"test\": returned indices should be unique'\n        with self.assertRaisesRegex(PostProcessExecutionError, expected_msg):\n            cmd.run([LLMFnOutputRow(data={\"text_result\": \"hello\"}, result_type=str)])\n    def test_post_process_reorder_cmd_bad_index_less_than_zero(self):",
        "detail": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMCompareFnPostProcessTest",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "description": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "peekOfCode": "class LLMCompareFnPostProcessTest(absltest.TestCase):\n    def test_cmp_post_process_add_cmd(self):\n        def add_fn(rows: Sequence[tuple[LLMFnOutputRowView, LLMFnOutputRowView]]) -> Sequence[int]:\n            return [x.result_value() + y.result_value() for x, y in rows]\n        cmd = LLMCompareFnPostProcessAddCommand(name=\"sum\", fn=add_fn)\n        results = cmd.run(\n            [\n                (\n                    LLMFnOutputRow(data={\"int_result\": 1}, result_type=int),\n                    LLMFnOutputRow(data={\"int_result\": 2}, result_type=int),",
        "detail": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRow",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "description": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "peekOfCode": "LLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\nLLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nPostProcessExecutionError = llmfn_post_process.PostProcessExecutionError\nLLMFnPostProcessReorderCommand = llmfn_post_process_cmds.LLMFnPostProcessReorderCommand\nLLMFnPostProcessAddCommand = llmfn_post_process_cmds.LLMFnPostProcessAddCommand\nLLMFnPostProcessReplaceCommand = llmfn_post_process_cmds.LLMFnPostProcessReplaceCommand\nLLMCompareFnPostProcessAddCommand = llmfn_post_process_cmds.LLMCompareFnPostProcessAddCommand\nclass LLMFnPostProcessCmdTest(absltest.TestCase):\n    def test_post_process_reorder_cmd_bad_index_duplicate_indices(self):\n        def bad_index_fn(rows: Sequence[LLMFnOutputRowView]) -> Sequence[int]:",
        "detail": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRowView",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "description": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "peekOfCode": "LLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nPostProcessExecutionError = llmfn_post_process.PostProcessExecutionError\nLLMFnPostProcessReorderCommand = llmfn_post_process_cmds.LLMFnPostProcessReorderCommand\nLLMFnPostProcessAddCommand = llmfn_post_process_cmds.LLMFnPostProcessAddCommand\nLLMFnPostProcessReplaceCommand = llmfn_post_process_cmds.LLMFnPostProcessReplaceCommand\nLLMCompareFnPostProcessAddCommand = llmfn_post_process_cmds.LLMCompareFnPostProcessAddCommand\nclass LLMFnPostProcessCmdTest(absltest.TestCase):\n    def test_post_process_reorder_cmd_bad_index_duplicate_indices(self):\n        def bad_index_fn(rows: Sequence[LLMFnOutputRowView]) -> Sequence[int]:\n            del rows",
        "detail": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "PostProcessExecutionError",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "description": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "peekOfCode": "PostProcessExecutionError = llmfn_post_process.PostProcessExecutionError\nLLMFnPostProcessReorderCommand = llmfn_post_process_cmds.LLMFnPostProcessReorderCommand\nLLMFnPostProcessAddCommand = llmfn_post_process_cmds.LLMFnPostProcessAddCommand\nLLMFnPostProcessReplaceCommand = llmfn_post_process_cmds.LLMFnPostProcessReplaceCommand\nLLMCompareFnPostProcessAddCommand = llmfn_post_process_cmds.LLMCompareFnPostProcessAddCommand\nclass LLMFnPostProcessCmdTest(absltest.TestCase):\n    def test_post_process_reorder_cmd_bad_index_duplicate_indices(self):\n        def bad_index_fn(rows: Sequence[LLMFnOutputRowView]) -> Sequence[int]:\n            del rows\n            return [0, 0]",
        "detail": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessReorderCommand",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "description": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "peekOfCode": "LLMFnPostProcessReorderCommand = llmfn_post_process_cmds.LLMFnPostProcessReorderCommand\nLLMFnPostProcessAddCommand = llmfn_post_process_cmds.LLMFnPostProcessAddCommand\nLLMFnPostProcessReplaceCommand = llmfn_post_process_cmds.LLMFnPostProcessReplaceCommand\nLLMCompareFnPostProcessAddCommand = llmfn_post_process_cmds.LLMCompareFnPostProcessAddCommand\nclass LLMFnPostProcessCmdTest(absltest.TestCase):\n    def test_post_process_reorder_cmd_bad_index_duplicate_indices(self):\n        def bad_index_fn(rows: Sequence[LLMFnOutputRowView]) -> Sequence[int]:\n            del rows\n            return [0, 0]\n        cmd = LLMFnPostProcessReorderCommand(name=\"test\", fn=bad_index_fn)",
        "detail": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessAddCommand",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "description": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "peekOfCode": "LLMFnPostProcessAddCommand = llmfn_post_process_cmds.LLMFnPostProcessAddCommand\nLLMFnPostProcessReplaceCommand = llmfn_post_process_cmds.LLMFnPostProcessReplaceCommand\nLLMCompareFnPostProcessAddCommand = llmfn_post_process_cmds.LLMCompareFnPostProcessAddCommand\nclass LLMFnPostProcessCmdTest(absltest.TestCase):\n    def test_post_process_reorder_cmd_bad_index_duplicate_indices(self):\n        def bad_index_fn(rows: Sequence[LLMFnOutputRowView]) -> Sequence[int]:\n            del rows\n            return [0, 0]\n        cmd = LLMFnPostProcessReorderCommand(name=\"test\", fn=bad_index_fn)\n        expected_msg = 'Error executing \"test\": returned indices should be unique'",
        "detail": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMFnPostProcessReplaceCommand",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "description": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "peekOfCode": "LLMFnPostProcessReplaceCommand = llmfn_post_process_cmds.LLMFnPostProcessReplaceCommand\nLLMCompareFnPostProcessAddCommand = llmfn_post_process_cmds.LLMCompareFnPostProcessAddCommand\nclass LLMFnPostProcessCmdTest(absltest.TestCase):\n    def test_post_process_reorder_cmd_bad_index_duplicate_indices(self):\n        def bad_index_fn(rows: Sequence[LLMFnOutputRowView]) -> Sequence[int]:\n            del rows\n            return [0, 0]\n        cmd = LLMFnPostProcessReorderCommand(name=\"test\", fn=bad_index_fn)\n        expected_msg = 'Error executing \"test\": returned indices should be unique'\n        with self.assertRaisesRegex(PostProcessExecutionError, expected_msg):",
        "detail": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "LLMCompareFnPostProcessAddCommand",
        "kind": 5,
        "importPath": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "description": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "peekOfCode": "LLMCompareFnPostProcessAddCommand = llmfn_post_process_cmds.LLMCompareFnPostProcessAddCommand\nclass LLMFnPostProcessCmdTest(absltest.TestCase):\n    def test_post_process_reorder_cmd_bad_index_duplicate_indices(self):\n        def bad_index_fn(rows: Sequence[LLMFnOutputRowView]) -> Sequence[int]:\n            del rows\n            return [0, 0]\n        cmd = LLMFnPostProcessReorderCommand(name=\"test\", fn=bad_index_fn)\n        expected_msg = 'Error executing \"test\": returned indices should be unique'\n        with self.assertRaisesRegex(PostProcessExecutionError, expected_msg):\n            cmd.run([LLMFnOutputRow(data={\"text_result\": \"hello\"}, result_type=str)])",
        "detail": "tests.notebook.lib.test_llmfn_post_process_cmds",
        "documentation": {}
    },
    {
        "label": "PromptUtilsTest",
        "kind": 6,
        "importPath": "tests.notebook.lib.test_prompt_utils",
        "description": "tests.notebook.lib.test_prompt_utils",
        "peekOfCode": "class PromptUtilsTest(absltest.TestCase):\n    def test_get_placeholders_empty(self):\n        placeholders = prompt_utils.get_placeholders(\"\")\n        self.assertEmpty(placeholders)\n        placeholders = prompt_utils.get_placeholders(\"There are no placeholders here\")\n        self.assertEmpty(placeholders)\n    def test_get_placeholders(self):\n        placeholders = prompt_utils.get_placeholders(\"today {hello} world\")\n        self.assertEqual(frozenset({\"hello\"}), placeholders)\n        placeholders = prompt_utils.get_placeholders(\"{hello} {world}\")",
        "detail": "tests.notebook.lib.test_prompt_utils",
        "documentation": {}
    },
    {
        "label": "UniqueFntest",
        "kind": 6,
        "importPath": "tests.notebook.lib.unique_fn_test",
        "description": "tests.notebook.lib.unique_fn_test",
        "peekOfCode": "class UniqueFntest(absltest.TestCase):\n    def test_all_unique(self):\n        rows = [\n            LLMFnOutputRow(data={\"text_result\": \"red\"}, result_type=str),\n            LLMFnOutputRow(data={\"text_result\": \"green\"}, result_type=str),\n            LLMFnOutputRow(data={\"text_result\": \"blue\"}, result_type=str),\n        ]\n        self.assertEqual([0, 1, 2], unique_fn.unique_fn(rows))\n    def test_some_dupes(self):\n        rows = [",
        "detail": "tests.notebook.lib.unique_fn_test",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRow",
        "kind": 5,
        "importPath": "tests.notebook.lib.unique_fn_test",
        "description": "tests.notebook.lib.unique_fn_test",
        "peekOfCode": "LLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\nclass UniqueFntest(absltest.TestCase):\n    def test_all_unique(self):\n        rows = [\n            LLMFnOutputRow(data={\"text_result\": \"red\"}, result_type=str),\n            LLMFnOutputRow(data={\"text_result\": \"green\"}, result_type=str),\n            LLMFnOutputRow(data={\"text_result\": \"blue\"}, result_type=str),\n        ]\n        self.assertEqual([0, 1, 2], unique_fn.unique_fn(rows))\n    def test_some_dupes(self):",
        "detail": "tests.notebook.lib.unique_fn_test",
        "documentation": {}
    },
    {
        "label": "ArgumentParserTest",
        "kind": 6,
        "importPath": "tests.notebook.test_argument_parser",
        "description": "tests.notebook.test_argument_parser",
        "peekOfCode": "class ArgumentParserTest(absltest.TestCase):\n    def test_help(self):\n        \"\"\"Verify that help messages raise ParserNormalExit.\"\"\"\n        parser = parser_lib.ArgumentParser()\n        with self.assertRaisesRegex(parser_lib.ParserNormalExit, \"show this help message and exit\"):\n            parser.parse_args([\"-h\"])\n    def test_parse_arg_errors(self):\n        def new_parser() -> argparse.ArgumentParser:\n            parser = parser_lib.ArgumentParser()\n            parser.add_argument(\"--value\", type=int, required=True)",
        "detail": "tests.notebook.test_argument_parser",
        "documentation": {}
    },
    {
        "label": "CmdLineParserTestBase",
        "kind": 6,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "class CmdLineParserTestBase(absltest.TestCase):\n    def setUp(self):\n        super().setUp()\n        # Reset variables.\n        global _OUTPUT_VAR_ONE\n        global _OUTPUT_VAR_TWO\n        _OUTPUT_VAR_ONE = None\n        _OUTPUT_VAR_TWO = None\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "CmdLineParserCommonTest",
        "kind": 6,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "class CmdLineParserCommonTest(CmdLineParserTestBase):\n    \"\"\"For tests that are not specific to any command.\"\"\"\n    def test_parse_args_help(self):\n        parser = cmd_line_parser.CmdLineParser()\n        with self.assertRaises(argument_parser.ParserNormalExit):\n            parser.parse_line(\"-h\")\n        with self.assertRaises(argument_parser.ParserNormalExit):\n            parser.parse_line(\"--help\")\n        with self.assertRaises(argument_parser.ParserNormalExit):\n            parser.parse_line(\"run -h\")",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "CmdLineParserModelFlagsTest",
        "kind": 6,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "class CmdLineParserModelFlagsTest(CmdLineParserTestBase):\n    def test_parse_args_sets_model_type(self):\n        parser = cmd_line_parser.CmdLineParser()\n        results, _ = parser.parse_line(\"--model_type=echo\")\n        self.assertEqual(model_registry.ModelName.ECHO_MODEL, results.model_type)\n        results, _ = parser.parse_line(\"--model_type=text\")\n        self.assertEqual(model_registry.ModelName.TEXT_MODEL, results.model_type)\n    def test_parse_args_sets_model(self):\n        parser = cmd_line_parser.CmdLineParser()\n        results, _ = parser.parse_line(\"--model=/ml/test\")",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "CmdLineParserRunTest",
        "kind": 6,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "class CmdLineParserRunTest(CmdLineParserTestBase):\n    \"\"\"For the \"run\" command.\"\"\"\n    def test_parse_args_run_is_default(self):\n        parser = cmd_line_parser.CmdLineParser()\n        results, _ = parser.parse_line(\"--model_type=echo\")\n        self.assertEqual(parsed_args_lib.CommandName.RUN_CMD, results.cmd)\n        self.assertEqual(model_registry.ModelName.ECHO_MODEL, results.model_type)\n    def test_parse_input_and_output_args(self):\n        parser = cmd_line_parser.CmdLineParser()\n        results, _ = parser.parse_line(",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "CmdLineParserCompileTest",
        "kind": 6,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "class CmdLineParserCompileTest(CmdLineParserTestBase):\n    \"\"\"For the \"compile\" command.\"\"\"\n    def test_parse_args_needs_save_name(self):\n        parser = cmd_line_parser.CmdLineParser()\n        with self.assertRaisesRegex(\n            argument_parser.ParserError,\n            \"the following arguments are required: compile_save_name\",\n        ):\n            parser.parse_line(\"compile\")\n    def test_parse_args_bad_save_name(self):",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "CmdLineParserCompareTest",
        "kind": 6,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "class CmdLineParserCompareTest(CmdLineParserTestBase):\n    \"\"\"For the \"compare\" command.\"\"\"\n    def test_compare(self):\n        parser = cmd_line_parser.CmdLineParser()\n        results, _ = parser.parse_line(\"compare _test_lhs_fn _test_rhs_fn --inputs _INPUT_VAR_ONE\")\n        self.assertEqual((\"_test_lhs_fn\", _test_lhs_fn), results.lhs_name_and_fn)\n        self.assertEqual((\"_test_rhs_fn\", _test_rhs_fn), results.rhs_name_and_fn)\n        self.assertEmpty(results.compare_fn)\n    def test_compare_with_custom_compare_fn(self):\n        parser = cmd_line_parser.CmdLineParser()",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "CmdLineParserEvalTest",
        "kind": 6,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "class CmdLineParserEvalTest(CmdLineParserTestBase):\n    \"\"\"For the \"eval\" command.\"\"\"\n    def test_eval(self):\n        parser = cmd_line_parser.CmdLineParser()\n        results, _ = parser.parse_line(\n            \"eval --ground_truth _GROUND_TRUTH_VAR --inputs _INPUT_VAR_ONE\"\n        )\n        self.assertEqual([\"apple\", \"banana\", \"cantaloupe\"], results.ground_truth)\n    def test_placeholder_error(self):\n        parser = cmd_line_parser.CmdLineParser()",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "CmdLineParserPostProcessingTest",
        "kind": 6,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "class CmdLineParserPostProcessingTest(CmdLineParserTestBase):\n    \"\"\"For the \"run\" command.\"\"\"\n    def test_parse_tokens(self):\n        parser = cmd_line_parser.CmdLineParser()\n        _, post_process_exprs = parser.parse_line(\"| add_length | to_upper\")\n        self.assertLen(post_process_exprs, 2)\n        self.assertEqual([\"add_length\"], post_process_exprs[0])\n        self.assertEqual([\"to_upper\"], post_process_exprs[1])\n    def test_illformed_expression(self):\n        parser = cmd_line_parser.CmdLineParser()",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "_INPUT_VAR_ONE",
        "kind": 5,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "_INPUT_VAR_ONE = {\"word\": [\"one\"]}\n_INPUT_VAR_TWO = {\"word\": [\"two\"]}\n_INPUT_VAR_THREE = {\"word\": [\"three\"]}\n_NOT_WORD_INPUT_VAR = {\"not_word\": [\"hello\", \"world\"]}\n_OUTPUT_VAR_ONE: llmfn_outputs.LLMFnOutputs | None = None\n_OUTPUT_VAR_TWO: llmfn_outputs.LLMFnOutputs | None = None\n_GROUND_TRUTH_VAR = [\"apple\", \"banana\", \"cantaloupe\"]\ndef _set_output_sink(text_result: str, sink: llmfn_outputs.LLMFnOutputsSink) -> None:\n    sink.write_outputs(\n        llmfn_outputs.LLMFnOutputs(",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "_INPUT_VAR_TWO",
        "kind": 5,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "_INPUT_VAR_TWO = {\"word\": [\"two\"]}\n_INPUT_VAR_THREE = {\"word\": [\"three\"]}\n_NOT_WORD_INPUT_VAR = {\"not_word\": [\"hello\", \"world\"]}\n_OUTPUT_VAR_ONE: llmfn_outputs.LLMFnOutputs | None = None\n_OUTPUT_VAR_TWO: llmfn_outputs.LLMFnOutputs | None = None\n_GROUND_TRUTH_VAR = [\"apple\", \"banana\", \"cantaloupe\"]\ndef _set_output_sink(text_result: str, sink: llmfn_outputs.LLMFnOutputsSink) -> None:\n    sink.write_outputs(\n        llmfn_outputs.LLMFnOutputs(\n            outputs=[",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "_INPUT_VAR_THREE",
        "kind": 5,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "_INPUT_VAR_THREE = {\"word\": [\"three\"]}\n_NOT_WORD_INPUT_VAR = {\"not_word\": [\"hello\", \"world\"]}\n_OUTPUT_VAR_ONE: llmfn_outputs.LLMFnOutputs | None = None\n_OUTPUT_VAR_TWO: llmfn_outputs.LLMFnOutputs | None = None\n_GROUND_TRUTH_VAR = [\"apple\", \"banana\", \"cantaloupe\"]\ndef _set_output_sink(text_result: str, sink: llmfn_outputs.LLMFnOutputsSink) -> None:\n    sink.write_outputs(\n        llmfn_outputs.LLMFnOutputs(\n            outputs=[\n                llmfn_outputs.LLMFnOutputEntry(",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "_NOT_WORD_INPUT_VAR",
        "kind": 5,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "_NOT_WORD_INPUT_VAR = {\"not_word\": [\"hello\", \"world\"]}\n_OUTPUT_VAR_ONE: llmfn_outputs.LLMFnOutputs | None = None\n_OUTPUT_VAR_TWO: llmfn_outputs.LLMFnOutputs | None = None\n_GROUND_TRUTH_VAR = [\"apple\", \"banana\", \"cantaloupe\"]\ndef _set_output_sink(text_result: str, sink: llmfn_outputs.LLMFnOutputsSink) -> None:\n    sink.write_outputs(\n        llmfn_outputs.LLMFnOutputs(\n            outputs=[\n                llmfn_outputs.LLMFnOutputEntry(\n                    prompt_num=0,",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "_GROUND_TRUTH_VAR",
        "kind": 5,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "_GROUND_TRUTH_VAR = [\"apple\", \"banana\", \"cantaloupe\"]\ndef _set_output_sink(text_result: str, sink: llmfn_outputs.LLMFnOutputsSink) -> None:\n    sink.write_outputs(\n        llmfn_outputs.LLMFnOutputs(\n            outputs=[\n                llmfn_outputs.LLMFnOutputEntry(\n                    prompt_num=0,\n                    input_num=0,\n                    prompt_vars={},\n                    output_rows=[",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "_test_lhs_fn",
        "kind": 5,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "_test_lhs_fn = llm_function.LLMFunctionImpl(\n    model=model_lib.EchoModel(), prompts=[\"dummy lhs prompt {word}\"]\n)\n_test_rhs_fn = llm_function.LLMFunctionImpl(\n    model=model_lib.EchoModel(), prompts=[\"dummy rhs prompt {word}\"]\n)\ndef _test_compare_fn(lhs: str, rhs: str) -> bool:\n    return lhs == rhs\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "_test_rhs_fn",
        "kind": 5,
        "importPath": "tests.notebook.test_cmd_line_parser",
        "description": "tests.notebook.test_cmd_line_parser",
        "peekOfCode": "_test_rhs_fn = llm_function.LLMFunctionImpl(\n    model=model_lib.EchoModel(), prompts=[\"dummy rhs prompt {word}\"]\n)\ndef _test_compare_fn(lhs: str, rhs: str) -> bool:\n    return lhs == rhs\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass CmdLineParserCompareTest(CmdLineParserTestBase):\n    \"\"\"For the \"compare\" command.\"\"\"\n    def test_compare(self):",
        "detail": "tests.notebook.test_cmd_line_parser",
        "documentation": {}
    },
    {
        "label": "SingleValueFlagDefTest",
        "kind": 6,
        "importPath": "tests.notebook.test_flag_def",
        "description": "tests.notebook.test_flag_def",
        "peekOfCode": "class SingleValueFlagDefTest(absltest.TestCase):\n    def test_short_name(self):\n        flag = flag_def.SingleValueFlagDef(\n            name=\"value\", short_name=\"v\", parse_type=str, required=True\n        )\n        results = _new_parser(flag).parse_args([\"--value=forty-one\"])\n        self.assertEqual(\"forty-one\", results.value)\n        results = _new_parser(flag).parse_args([\"-v\", \"forty-two\"])\n        self.assertEqual(\"forty-two\", results.value)\n    def test_cardinality(self):",
        "detail": "tests.notebook.test_flag_def",
        "documentation": {}
    },
    {
        "label": "ColorsEnum",
        "kind": 6,
        "importPath": "tests.notebook.test_flag_def",
        "description": "tests.notebook.test_flag_def",
        "peekOfCode": "class ColorsEnum(enum.Enum):\n    RED = \"red\"\n    GREEN = \"green\"\n    BLUE = \"blue\"\nclass EnumFlagDefTest(absltest.TestCase):\n    def test_construction(self):\n        # \"enum_type\" must be provided.\n        with self.assertRaisesRegex(TypeError, \"missing 1 required keyword-only argument\"):\n            # pylint: disable-next=missing-kwoa\n            flag_def.EnumFlagDef(name=\"color\", required=True)  # type: ignore",
        "detail": "tests.notebook.test_flag_def",
        "documentation": {}
    },
    {
        "label": "EnumFlagDefTest",
        "kind": 6,
        "importPath": "tests.notebook.test_flag_def",
        "description": "tests.notebook.test_flag_def",
        "peekOfCode": "class EnumFlagDefTest(absltest.TestCase):\n    def test_construction(self):\n        # \"enum_type\" must be provided.\n        with self.assertRaisesRegex(TypeError, \"missing 1 required keyword-only argument\"):\n            # pylint: disable-next=missing-kwoa\n            flag_def.EnumFlagDef(name=\"color\", required=True)  # type: ignore\n        # \"parse_type\" cannot be provided.\n        with self.assertRaisesRegex(ValueError, 'Cannot set \"parse_type\" for EnumFlagDef'):\n            flag_def.EnumFlagDef(\n                name=\"color\",",
        "detail": "tests.notebook.test_flag_def",
        "documentation": {}
    },
    {
        "label": "MultiValuesFlagDefTest",
        "kind": 6,
        "importPath": "tests.notebook.test_flag_def",
        "description": "tests.notebook.test_flag_def",
        "peekOfCode": "class MultiValuesFlagDefTest(absltest.TestCase):\n    def test_basic(self):\n        # Default value is not needed even if optional; the value would just be the\n        # empty list.\n        flag = flag_def.MultiValuesFlagDef(name=\"colors\", parse_type=str, required=False)\n        # Default value is the empty list.\n        results = _new_parser(flag).parse_args([])\n        self.assertEmpty(results.colors)\n        results = _new_parser(flag).parse_args([\"--colors\", \"red\"])\n        self.assertEqual([\"red\"], results.colors)",
        "detail": "tests.notebook.test_flag_def",
        "documentation": {}
    },
    {
        "label": "BooleanFlagDefTest",
        "kind": 6,
        "importPath": "tests.notebook.test_flag_def",
        "description": "tests.notebook.test_flag_def",
        "peekOfCode": "class BooleanFlagDefTest(absltest.TestCase):\n    def test_basic(self):\n        flag = flag_def.BooleanFlagDef(name=\"unique\")\n        results = _new_parser(flag).parse_args([])\n        self.assertFalse(results.unique)\n        results = _new_parser(flag).parse_args([\"--unique\"])\n        self.assertTrue(results.unique)\n    def test_constructor(self):\n        \"\"\"Check that invalid constructor arguments are rejected.\"\"\"\n        with self.assertRaisesRegex(ValueError, \"dest_type cannot be set for BooleanFlagDef\"):",
        "detail": "tests.notebook.test_flag_def",
        "documentation": {}
    },
    {
        "label": "HtmlUtilsTest",
        "kind": 6,
        "importPath": "tests.notebook.test_html_utils",
        "description": "tests.notebook.test_html_utils",
        "peekOfCode": "class HtmlUtilsTest(absltest.TestCase):\n    def test_get_anchor_tag_text_is_escaped(self):\n        html = html_utils.get_anchor_tag(\n            url=sheets_id.SheetsURL(\"https://docs.google.com/?a=b#hello\"),\n            text=\"hello<evil_tag/>world\",\n        )\n        self.assertEqual(\n            (\n                '<a target=\"_blank\" rel=\"noopener\"'\n                ' href=\"https://docs.google.com/?a=b#hello\">hello&lt;evil_tag/&gt;world</a>'",
        "detail": "tests.notebook.test_html_utils",
        "documentation": {}
    },
    {
        "label": "EchoModelRegistry",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class EchoModelRegistry(model_registry.ModelRegistry):\n    \"\"\"Fake model registry for testing.\"\"\"\n    def __init__(self, alt_model=None):\n        self.model = alt_model or model.EchoModel()\n        self.get_model_name: model_registry.ModelName | None = None\n    def get_model(self, model_name: model_registry.ModelName) -> model.AbstractModel:\n        self.get_model_name = model_name\n        return self.model\nclass FakeIPythonEnv(ipython_env.IPythonEnv):\n    \"\"\"Fake IPythonEnv for testing.\"\"\"",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "FakeIPythonEnv",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class FakeIPythonEnv(ipython_env.IPythonEnv):\n    \"\"\"Fake IPythonEnv for testing.\"\"\"\n    def __init__(self):\n        self.display_args: Any = None\n    def clear(self) -> None:\n        self.display_args = None\n    def display(self, x: Any) -> None:\n        self.display_args = x\n        logging.info(\"IPythonEnv.display called with:\\n%r\", x)\n    def display_html(self, x: Any) -> None:",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "FakeInputsSource",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class FakeInputsSource(llmfn_inputs_source.LLMFnInputsSource):\n    def _to_normalized_inputs_impl(\n        self,\n    ) -> tuple[Sequence[Mapping[str, str]], Callable[[], None]]:\n        return [{\"word\": \"quack3\"}, {\"word\": \"quack4\"}], lambda: None\nclass FakeOutputsSink(llmfn_outputs.LLMFnOutputsSink):\n    def __init__(self):\n        self.outputs: llmfn_outputs.LLMFnOutputsBase | None = None\n    def write_outputs(self, outputs: llmfn_outputs.LLMFnOutputsBase) -> None:\n        self.outputs = outputs",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "FakeOutputsSink",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class FakeOutputsSink(llmfn_outputs.LLMFnOutputsSink):\n    def __init__(self):\n        self.outputs: llmfn_outputs.LLMFnOutputsBase | None = None\n    def write_outputs(self, outputs: llmfn_outputs.LLMFnOutputsBase) -> None:\n        self.outputs = outputs\nclass MockGSpreadClient(gspread_client.GSpreadClient):\n    def __init__(self):\n        self.get_all_records_name: str | None = None\n        self.get_all_records_worksheet_id: int | None = None\n        self.write_records_name: str | None = None",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "MockGSpreadClient",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class MockGSpreadClient(gspread_client.GSpreadClient):\n    def __init__(self):\n        self.get_all_records_name: str | None = None\n        self.get_all_records_worksheet_id: int | None = None\n        self.write_records_name: str | None = None\n        self.write_records_rows: Sequence[Sequence[Any]] | None = None\n    def validate(self, sid: sheets_id.SheetsIdentifier):\n        if sid.name() is None:\n            raise gspread_client.SpreadsheetNotFoundError(\"Sheets not found: {}\".format(sid))\n        pass",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "EndToEndTests",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class EndToEndTests(absltest.TestCase):\n    def setUp(self):\n        super().setUp()\n        self._mock_client = MockGSpreadClient()\n        gspread_client.testonly_set_client(self._mock_client)\n        _reset_globals()\n    def _assert_is_expected_pandas_dataframe(\n        self, results: pandas.DataFrame, expected_results: Mapping[str, Any]\n    ) -> None:\n        self.assertIsInstance(results, pandas.DataFrame)",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "HelpEndToEndTests",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class HelpEndToEndTests(EndToEndTests):\n    def test_help(self):\n        mock_registry = EchoModelRegistry()\n        magic_line = \"--help\"\n        engine = magics_engine.MagicsEngine(registry=mock_registry)\n        # Should not raise an exception.\n        results = engine.execute_cell(magic_line, \"ignored\")\n        self.assertRegex(str(results), \"A system for interacting with LLMs\")\n    def test_run_help(self):\n        mock_registry = EchoModelRegistry()",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "RunCmdEndToEndTests",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class RunCmdEndToEndTests(EndToEndTests):\n    def test_run_cmd(self):\n        \"\"\"Smoke test for executing the run command.\"\"\"\n        mock_registry = EchoModelRegistry()\n        magic_line = \"run --model_type=echo\"\n        engine = magics_engine.MagicsEngine(registry=mock_registry)\n        results = engine.execute_cell(magic_line, \"quack quack\")\n        expected_results = {\n            \"Prompt Num\": [0],\n            \"Input Num\": [0],",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "CompileCmdEndToEndTests",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class CompileCmdEndToEndTests(EndToEndTests):\n    def test_compile_cmd(self):\n        fake_env = FakeIPythonEnv()\n        engine = magics_engine.MagicsEngine(registry=EchoModelRegistry(), env=fake_env)\n        _ = engine.execute_cell(\"compile _compiled_function --model_type=echo\", \"quack {word}\")\n        # The \"compile\" command produces a saved function.\n        # Execute the saved function and check that it produces the expected output.\n        self.assertIsInstance(_compiled_function, llm_function.LLMFunction)\n        outputs = _compiled_function({\"word\": [\"LOUD QUACK\"]})\n        expected_outputs = {",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "CompareCmdEndToEndTests",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class CompareCmdEndToEndTests(EndToEndTests):\n    def test_compare_cmd_with_default_compare_fn(self):\n        fake_env = FakeIPythonEnv()\n        engine = magics_engine.MagicsEngine(registry=EchoModelRegistry(), env=fake_env)\n        # Create a pair of LLMFunctions to compare.\n        _ = engine.execute_cell(\n            \"compile _compiled_lhs_function --model_type=echo\",\n            \"left quack {word}\",\n        )\n        _ = engine.execute_cell(",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "EvalCmdEndToEndTests",
        "kind": 6,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "class EvalCmdEndToEndTests(EndToEndTests):\n    def test_eval_cmd(self):\n        fake_env = FakeIPythonEnv()\n        engine = magics_engine.MagicsEngine(registry=EchoModelRegistry(), env=fake_env)\n        # Run evaluation.\n        #\n        # Some of the features tested are:\n        # 1. We evoke a model flag (to make sure model flags are parsed.)\n        # 2. We add a post-processing function to the prompt results\n        # 3. We add a few custom comparison functions.",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "add_length",
        "kind": 2,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "def add_length(result: str) -> int:\n    return len(result)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(result: str) -> int:\n    return len(result)\n@post_process_utils.post_process_replace_fn\ndef repeat(result: str) -> str:\n    return result + result\n@post_process_utils.post_process_replace_fn\ndef to_upper(result: str) -> str:",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "add_length_decorated",
        "kind": 2,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "def add_length_decorated(result: str) -> int:\n    return len(result)\n@post_process_utils.post_process_replace_fn\ndef repeat(result: str) -> str:\n    return result + result\n@post_process_utils.post_process_replace_fn\ndef to_upper(result: str) -> str:\n    return result.upper()\n# Comparison functions for \"compare\" command.\ndef get_sum_of_lengths(lhs: str, rhs: str) -> int:",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "repeat",
        "kind": 2,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "def repeat(result: str) -> str:\n    return result + result\n@post_process_utils.post_process_replace_fn\ndef to_upper(result: str) -> str:\n    return result.upper()\n# Comparison functions for \"compare\" command.\ndef get_sum_of_lengths(lhs: str, rhs: str) -> int:\n    return len(lhs) + len(rhs)\ndef concat(lhs: str, rhs: str) -> str:\n    return lhs + \" \" + rhs",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "to_upper",
        "kind": 2,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "def to_upper(result: str) -> str:\n    return result.upper()\n# Comparison functions for \"compare\" command.\ndef get_sum_of_lengths(lhs: str, rhs: str) -> int:\n    return len(lhs) + len(rhs)\ndef concat(lhs: str, rhs: str) -> str:\n    return lhs + \" \" + rhs\ndef my_is_equal_fn(lhs: str, rhs: str) -> bool:\n    return lhs == rhs\nclass EchoModelRegistry(model_registry.ModelRegistry):",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "get_sum_of_lengths",
        "kind": 2,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "def get_sum_of_lengths(lhs: str, rhs: str) -> int:\n    return len(lhs) + len(rhs)\ndef concat(lhs: str, rhs: str) -> str:\n    return lhs + \" \" + rhs\ndef my_is_equal_fn(lhs: str, rhs: str) -> bool:\n    return lhs == rhs\nclass EchoModelRegistry(model_registry.ModelRegistry):\n    \"\"\"Fake model registry for testing.\"\"\"\n    def __init__(self, alt_model=None):\n        self.model = alt_model or model.EchoModel()",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "concat",
        "kind": 2,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "def concat(lhs: str, rhs: str) -> str:\n    return lhs + \" \" + rhs\ndef my_is_equal_fn(lhs: str, rhs: str) -> bool:\n    return lhs == rhs\nclass EchoModelRegistry(model_registry.ModelRegistry):\n    \"\"\"Fake model registry for testing.\"\"\"\n    def __init__(self, alt_model=None):\n        self.model = alt_model or model.EchoModel()\n        self.get_model_name: model_registry.ModelName | None = None\n    def get_model(self, model_name: model_registry.ModelName) -> model.AbstractModel:",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "my_is_equal_fn",
        "kind": 2,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "def my_is_equal_fn(lhs: str, rhs: str) -> bool:\n    return lhs == rhs\nclass EchoModelRegistry(model_registry.ModelRegistry):\n    \"\"\"Fake model registry for testing.\"\"\"\n    def __init__(self, alt_model=None):\n        self.model = alt_model or model.EchoModel()\n        self.get_model_name: model_registry.ModelName | None = None\n    def get_model(self, model_name: model_registry.ModelName) -> model.AbstractModel:\n        self.get_model_name = model_name\n        return self.model",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "_compiled_function",
        "kind": 5,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "_compiled_function = _fake_llm_function\n_compiled_lhs_function = _fake_llm_function\n_compiled_rhs_function = _fake_llm_function\n# Decorators for testing post-processing operations.\ndef add_length(result: str) -> int:\n    return len(result)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(result: str) -> int:\n    return len(result)\n@post_process_utils.post_process_replace_fn",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "_compiled_lhs_function",
        "kind": 5,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "_compiled_lhs_function = _fake_llm_function\n_compiled_rhs_function = _fake_llm_function\n# Decorators for testing post-processing operations.\ndef add_length(result: str) -> int:\n    return len(result)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(result: str) -> int:\n    return len(result)\n@post_process_utils.post_process_replace_fn\ndef repeat(result: str) -> str:",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "_compiled_rhs_function",
        "kind": 5,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "_compiled_rhs_function = _fake_llm_function\n# Decorators for testing post-processing operations.\ndef add_length(result: str) -> int:\n    return len(result)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(result: str) -> int:\n    return len(result)\n@post_process_utils.post_process_replace_fn\ndef repeat(result: str) -> str:\n    return result + result",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "_INPUT_VAR_ONE",
        "kind": 5,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "_INPUT_VAR_ONE = {\"word\": [\"quack1\", \"quack2\"]}\n_INPUT_VAR_TWO = FakeInputsSource()\n_SHEETS_INPUT_VAR = None\n# Variable to test the --ground_truth flag.\n_GROUND_TRUTH_VAR = [\"QUACK QUACK1\", \"NOT QUACK QUACK2\"]\n# Variables to test the --outputs flag.\n_output_var: llmfn_outputs.LLMFnOutputs | None = None\n_output_sink_var = FakeOutputsSink()\ndef _reset_globals() -> None:\n    # Reset all our gloabls.",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "_INPUT_VAR_TWO",
        "kind": 5,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "_INPUT_VAR_TWO = FakeInputsSource()\n_SHEETS_INPUT_VAR = None\n# Variable to test the --ground_truth flag.\n_GROUND_TRUTH_VAR = [\"QUACK QUACK1\", \"NOT QUACK QUACK2\"]\n# Variables to test the --outputs flag.\n_output_var: llmfn_outputs.LLMFnOutputs | None = None\n_output_sink_var = FakeOutputsSink()\ndef _reset_globals() -> None:\n    # Reset all our gloabls.\n    global _compiled_function",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "_SHEETS_INPUT_VAR",
        "kind": 5,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "_SHEETS_INPUT_VAR = None\n# Variable to test the --ground_truth flag.\n_GROUND_TRUTH_VAR = [\"QUACK QUACK1\", \"NOT QUACK QUACK2\"]\n# Variables to test the --outputs flag.\n_output_var: llmfn_outputs.LLMFnOutputs | None = None\n_output_sink_var = FakeOutputsSink()\ndef _reset_globals() -> None:\n    # Reset all our gloabls.\n    global _compiled_function\n    global _compiled_lhs_function",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "_GROUND_TRUTH_VAR",
        "kind": 5,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "_GROUND_TRUTH_VAR = [\"QUACK QUACK1\", \"NOT QUACK QUACK2\"]\n# Variables to test the --outputs flag.\n_output_var: llmfn_outputs.LLMFnOutputs | None = None\n_output_sink_var = FakeOutputsSink()\ndef _reset_globals() -> None:\n    # Reset all our gloabls.\n    global _compiled_function\n    global _compiled_lhs_function\n    global _compiled_rhs_function\n    global _output_var",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "_output_sink_var",
        "kind": 5,
        "importPath": "tests.notebook.test_magics_engine",
        "description": "tests.notebook.test_magics_engine",
        "peekOfCode": "_output_sink_var = FakeOutputsSink()\ndef _reset_globals() -> None:\n    # Reset all our gloabls.\n    global _compiled_function\n    global _compiled_lhs_function\n    global _compiled_rhs_function\n    global _output_var\n    global _output_sink_var\n    global _SHEETS_INPUT_VAR\n    _compiled_function = None",
        "detail": "tests.notebook.test_magics_engine",
        "documentation": {}
    },
    {
        "label": "ModelRegistryTest",
        "kind": 6,
        "importPath": "tests.notebook.test_model_registry",
        "description": "tests.notebook.test_model_registry",
        "peekOfCode": "class ModelRegistryTest(absltest.TestCase):\n    def test_get_model_echo_model(self):\n        registry = model_registry.ModelRegistry()\n        model = registry.get_model(model_registry.ModelName.ECHO_MODEL)\n        results = model.call_model(model_input=\"this_is_a_test\")\n        self.assertEqual(\"this_is_a_test\", results.model_input)\n        # Echo model returns the model_input as text results.\n        self.assertEqual([\"this_is_a_test\"], results.text_results)\nif __name__ == \"__main__\":\n    absltest.main()",
        "detail": "tests.notebook.test_model_registry",
        "documentation": {}
    },
    {
        "label": "PostProcessUtilsResolveTest",
        "kind": 6,
        "importPath": "tests.notebook.test_post_process_utils",
        "description": "tests.notebook.test_post_process_utils",
        "peekOfCode": "class PostProcessUtilsResolveTest(absltest.TestCase):\n    def test_cannot_resolve_empty_expression(self):\n        with self.assertRaisesRegex(PostProcessParseError, \"Cannot have empty\"):\n            post_process_utils._resolve_one_post_processing_expression([])\n    def test_cannot_resolve_multiword_expression(self):\n        with self.assertRaisesRegex(PostProcessParseError, \"should be a single token\"):\n            post_process_utils._resolve_one_post_processing_expression([\"hello\", \"world\"])\n    def test_cannot_resolve_invalid_module(self):\n        with self.assertRaisesRegex(PostProcessParseError, 'Unable to resolve \"invalid_module\"'):\n            post_process_utils._resolve_one_post_processing_expression(",
        "detail": "tests.notebook.test_post_process_utils",
        "documentation": {}
    },
    {
        "label": "PostProcessUtilsTest",
        "kind": 6,
        "importPath": "tests.notebook.test_post_process_utils",
        "description": "tests.notebook.test_post_process_utils",
        "peekOfCode": "class PostProcessUtilsTest(absltest.TestCase):\n    def test_must_be_callable(self):\n        with self.assertRaisesRegex(PostProcessParseError, \"NOT_A_FUNCTION is not callable\"):\n            post_process_utils.resolve_post_processing_tokens([[\"NOT_A_FUNCTION\"]])\n    def test_parsed_post_process_add_fn(self):\n        \"\"\"Test that from a post-processing token to an updated LLMFunction.\"\"\"\n        parsed_exprs = post_process_utils.resolve_post_processing_tokens(\n            [\n                [\"add_length\"],\n            ]",
        "detail": "tests.notebook.test_post_process_utils",
        "documentation": {}
    },
    {
        "label": "add_length",
        "kind": 2,
        "importPath": "tests.notebook.test_post_process_utils",
        "description": "tests.notebook.test_post_process_utils",
        "peekOfCode": "def add_length(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_replace_fn\ndef to_upper(x: str) -> str:\n    return x.upper()\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})",
        "detail": "tests.notebook.test_post_process_utils",
        "documentation": {}
    },
    {
        "label": "add_length_decorated",
        "kind": 2,
        "importPath": "tests.notebook.test_post_process_utils",
        "description": "tests.notebook.test_post_process_utils",
        "peekOfCode": "def add_length_decorated(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_replace_fn\ndef to_upper(x: str) -> str:\n    return x.upper()\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass PostProcessUtilsResolveTest(absltest.TestCase):\n    def test_cannot_resolve_empty_expression(self):\n        with self.assertRaisesRegex(PostProcessParseError, \"Cannot have empty\"):",
        "detail": "tests.notebook.test_post_process_utils",
        "documentation": {}
    },
    {
        "label": "to_upper",
        "kind": 2,
        "importPath": "tests.notebook.test_post_process_utils",
        "description": "tests.notebook.test_post_process_utils",
        "peekOfCode": "def to_upper(x: str) -> str:\n    return x.upper()\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass PostProcessUtilsResolveTest(absltest.TestCase):\n    def test_cannot_resolve_empty_expression(self):\n        with self.assertRaisesRegex(PostProcessParseError, \"Cannot have empty\"):\n            post_process_utils._resolve_one_post_processing_expression([])\n    def test_cannot_resolve_multiword_expression(self):\n        with self.assertRaisesRegex(PostProcessParseError, \"should be a single token\"):",
        "detail": "tests.notebook.test_post_process_utils",
        "documentation": {}
    },
    {
        "label": "NOT_A_FUNCTION",
        "kind": 5,
        "importPath": "tests.notebook.test_post_process_utils",
        "description": "tests.notebook.test_post_process_utils",
        "peekOfCode": "NOT_A_FUNCTION = \"this is a string not a function\"\nLLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\nLLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nPostProcessParseError = post_process_utils.PostProcessParseError\ndef add_length(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_replace_fn",
        "detail": "tests.notebook.test_post_process_utils",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRow",
        "kind": 5,
        "importPath": "tests.notebook.test_post_process_utils",
        "description": "tests.notebook.test_post_process_utils",
        "peekOfCode": "LLMFnOutputRow = llmfn_output_row.LLMFnOutputRow\nLLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nPostProcessParseError = post_process_utils.PostProcessParseError\ndef add_length(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_replace_fn\ndef to_upper(x: str) -> str:",
        "detail": "tests.notebook.test_post_process_utils",
        "documentation": {}
    },
    {
        "label": "LLMFnOutputRowView",
        "kind": 5,
        "importPath": "tests.notebook.test_post_process_utils",
        "description": "tests.notebook.test_post_process_utils",
        "peekOfCode": "LLMFnOutputRowView = llmfn_output_row.LLMFnOutputRowView\nPostProcessParseError = post_process_utils.PostProcessParseError\ndef add_length(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_replace_fn\ndef to_upper(x: str) -> str:\n    return x.upper()",
        "detail": "tests.notebook.test_post_process_utils",
        "documentation": {}
    },
    {
        "label": "PostProcessParseError",
        "kind": 5,
        "importPath": "tests.notebook.test_post_process_utils",
        "description": "tests.notebook.test_post_process_utils",
        "peekOfCode": "PostProcessParseError = post_process_utils.PostProcessParseError\ndef add_length(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_add_fn\ndef add_length_decorated(x: str) -> int:\n    return len(x)\n@post_process_utils.post_process_replace_fn\ndef to_upper(x: str) -> str:\n    return x.upper()\n# `unittest discover` does not run via __main__, so patch this context in.",
        "detail": "tests.notebook.test_post_process_utils",
        "documentation": {}
    },
    {
        "label": "PyUtilsTest",
        "kind": 6,
        "importPath": "tests.notebook.test_py_utils",
        "description": "tests.notebook.test_py_utils",
        "peekOfCode": "class PyUtilsTest(absltest.TestCase):\n    def test_get_py_var(self):\n        # get_py_var() with an invalid var should raise an error.\n        with self.assertRaisesRegex(NameError, \"IncorrectVar\"):\n            py_utils.get_py_var(\"IncorrectVar\")\n        results = py_utils.get_py_var(\"_INPUT_VAR\")\n        self.assertEqual(\"hello world\", results)\n    def test_set_py_var(self):\n        py_utils.set_py_var(\"_OUTPUT_VAR\", \"world hello\")\n        self.assertEqual(\"world hello\", _OUTPUT_VAR)",
        "detail": "tests.notebook.test_py_utils",
        "documentation": {}
    },
    {
        "label": "_INPUT_VAR",
        "kind": 5,
        "importPath": "tests.notebook.test_py_utils",
        "description": "tests.notebook.test_py_utils",
        "peekOfCode": "_INPUT_VAR = \"hello world\"\n_OUTPUT_VAR = None\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass PyUtilsTest(absltest.TestCase):\n    def test_get_py_var(self):\n        # get_py_var() with an invalid var should raise an error.\n        with self.assertRaisesRegex(NameError, \"IncorrectVar\"):\n            py_utils.get_py_var(\"IncorrectVar\")\n        results = py_utils.get_py_var(\"_INPUT_VAR\")",
        "detail": "tests.notebook.test_py_utils",
        "documentation": {}
    },
    {
        "label": "_OUTPUT_VAR",
        "kind": 5,
        "importPath": "tests.notebook.test_py_utils",
        "description": "tests.notebook.test_py_utils",
        "peekOfCode": "_OUTPUT_VAR = None\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass PyUtilsTest(absltest.TestCase):\n    def test_get_py_var(self):\n        # get_py_var() with an invalid var should raise an error.\n        with self.assertRaisesRegex(NameError, \"IncorrectVar\"):\n            py_utils.get_py_var(\"IncorrectVar\")\n        results = py_utils.get_py_var(\"_INPUT_VAR\")\n        self.assertEqual(\"hello world\", results)",
        "detail": "tests.notebook.test_py_utils",
        "documentation": {}
    },
    {
        "label": "SheetsIdentifierTest",
        "kind": 6,
        "importPath": "tests.notebook.test_sheets_id",
        "description": "tests.notebook.test_sheets_id",
        "peekOfCode": "class SheetsIdentifierTest(absltest.TestCase):\n    def test_constructor(self):\n        sid = sheets_id.SheetsIdentifier(name=\"hello\")\n        self.assertEqual(\"name=hello\", str(sid))\n        sid = sheets_id.SheetsIdentifier(key=sheets_id.SheetsKey(\"hello\"))\n        self.assertEqual(\"key=hello\", str(sid))\n        sid = sheets_id.SheetsIdentifier(url=sheets_id.SheetsURL(\"https://docs.google.com/\"))\n        self.assertEqual(\"url=https://docs.google.com/\", str(sid))\n    def test_constructor_error(self):\n        with self.assertRaisesRegex(ValueError, \"Must set exactly one of name, key or url\"):",
        "detail": "tests.notebook.test_sheets_id",
        "documentation": {}
    },
    {
        "label": "SheetsSanitizeURLTest",
        "kind": 6,
        "importPath": "tests.notebook.test_sheets_sanitize_url",
        "description": "tests.notebook.test_sheets_sanitize_url",
        "peekOfCode": "class SheetsSanitizeURLTest(absltest.TestCase):\n    def test_scheme_must_be_https(self):\n        \"\"\"The URL must be https://.\"\"\"\n        with self.assertRaisesRegex(\n            ValueError, 'Scheme for Sheets url must be \"https\", got \"http\"'\n        ):\n            sanitize_sheets_url(\"http://docs.google.com\")\n        # HTTPS goes through.\n        url = sanitize_sheets_url(\"https://docs.google.com\")\n        self.assertEqual(\"https://docs.google.com\", str(url))",
        "detail": "tests.notebook.test_sheets_sanitize_url",
        "documentation": {}
    },
    {
        "label": "sanitize_sheets_url",
        "kind": 5,
        "importPath": "tests.notebook.test_sheets_sanitize_url",
        "description": "tests.notebook.test_sheets_sanitize_url",
        "peekOfCode": "sanitize_sheets_url = sheets_sanitize_url.sanitize_sheets_url\nclass SheetsSanitizeURLTest(absltest.TestCase):\n    def test_scheme_must_be_https(self):\n        \"\"\"The URL must be https://.\"\"\"\n        with self.assertRaisesRegex(\n            ValueError, 'Scheme for Sheets url must be \"https\", got \"http\"'\n        ):\n            sanitize_sheets_url(\"http://docs.google.com\")\n        # HTTPS goes through.\n        url = sanitize_sheets_url(\"https://docs.google.com\")",
        "detail": "tests.notebook.test_sheets_sanitize_url",
        "documentation": {}
    },
    {
        "label": "InputUtilsTest",
        "kind": 6,
        "importPath": "tests.notebook.tet_input_utils",
        "description": "tests.notebook.tet_input_utils",
        "peekOfCode": "class InputUtilsTest(absltest.TestCase):\n    def test_get_inputs_source_from_py_var_invalid_name(self):\n        with self.assertRaisesRegex(NameError, \"UnknownVar\"):\n            input_utils.get_inputs_source_from_py_var(\"UnknownVar\")\n    def test_get_inputs_source_from_py_var_empty_one(self):\n        source = input_utils.get_inputs_source_from_py_var(\"_EMPTY_INPUT_VAR_ONE\")\n        results = source.to_normalized_inputs()\n        self.assertEmpty(results)\n    def test_get_inputs_source_from_py_var_empty_two(self):\n        source = input_utils.get_inputs_source_from_py_var(\"_EMPTY_INPUT_VAR_TWO\")",
        "detail": "tests.notebook.tet_input_utils",
        "documentation": {}
    },
    {
        "label": "_EMPTY_INPUT_VAR_ONE",
        "kind": 5,
        "importPath": "tests.notebook.tet_input_utils",
        "description": "tests.notebook.tet_input_utils",
        "peekOfCode": "_EMPTY_INPUT_VAR_ONE = {}\n_EMPTY_INPUT_VAR_TWO = {\"word\": []}\n_INPUT_VAR_ONE = {\"word\": [\"lukewarm\"]}\n_INPUT_VAR_TWO = {\"word\": [\"hot\", \"cold\"]}\n_MULTI_INPUTS_VAR_ONE = {\"a\": [\"apple\"], \"b\": [\"banana\"]}\n_MULTI_INPUTS_VAR_TWO = {\"a\": [\"australia\", \"alpha\"], \"b\": [\"brazil\", \"beta\"]}\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass InputUtilsTest(absltest.TestCase):\n    def test_get_inputs_source_from_py_var_invalid_name(self):",
        "detail": "tests.notebook.tet_input_utils",
        "documentation": {}
    },
    {
        "label": "_EMPTY_INPUT_VAR_TWO",
        "kind": 5,
        "importPath": "tests.notebook.tet_input_utils",
        "description": "tests.notebook.tet_input_utils",
        "peekOfCode": "_EMPTY_INPUT_VAR_TWO = {\"word\": []}\n_INPUT_VAR_ONE = {\"word\": [\"lukewarm\"]}\n_INPUT_VAR_TWO = {\"word\": [\"hot\", \"cold\"]}\n_MULTI_INPUTS_VAR_ONE = {\"a\": [\"apple\"], \"b\": [\"banana\"]}\n_MULTI_INPUTS_VAR_TWO = {\"a\": [\"australia\", \"alpha\"], \"b\": [\"brazil\", \"beta\"]}\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass InputUtilsTest(absltest.TestCase):\n    def test_get_inputs_source_from_py_var_invalid_name(self):\n        with self.assertRaisesRegex(NameError, \"UnknownVar\"):",
        "detail": "tests.notebook.tet_input_utils",
        "documentation": {}
    },
    {
        "label": "_INPUT_VAR_ONE",
        "kind": 5,
        "importPath": "tests.notebook.tet_input_utils",
        "description": "tests.notebook.tet_input_utils",
        "peekOfCode": "_INPUT_VAR_ONE = {\"word\": [\"lukewarm\"]}\n_INPUT_VAR_TWO = {\"word\": [\"hot\", \"cold\"]}\n_MULTI_INPUTS_VAR_ONE = {\"a\": [\"apple\"], \"b\": [\"banana\"]}\n_MULTI_INPUTS_VAR_TWO = {\"a\": [\"australia\", \"alpha\"], \"b\": [\"brazil\", \"beta\"]}\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass InputUtilsTest(absltest.TestCase):\n    def test_get_inputs_source_from_py_var_invalid_name(self):\n        with self.assertRaisesRegex(NameError, \"UnknownVar\"):\n            input_utils.get_inputs_source_from_py_var(\"UnknownVar\")",
        "detail": "tests.notebook.tet_input_utils",
        "documentation": {}
    },
    {
        "label": "_INPUT_VAR_TWO",
        "kind": 5,
        "importPath": "tests.notebook.tet_input_utils",
        "description": "tests.notebook.tet_input_utils",
        "peekOfCode": "_INPUT_VAR_TWO = {\"word\": [\"hot\", \"cold\"]}\n_MULTI_INPUTS_VAR_ONE = {\"a\": [\"apple\"], \"b\": [\"banana\"]}\n_MULTI_INPUTS_VAR_TWO = {\"a\": [\"australia\", \"alpha\"], \"b\": [\"brazil\", \"beta\"]}\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass InputUtilsTest(absltest.TestCase):\n    def test_get_inputs_source_from_py_var_invalid_name(self):\n        with self.assertRaisesRegex(NameError, \"UnknownVar\"):\n            input_utils.get_inputs_source_from_py_var(\"UnknownVar\")\n    def test_get_inputs_source_from_py_var_empty_one(self):",
        "detail": "tests.notebook.tet_input_utils",
        "documentation": {}
    },
    {
        "label": "_MULTI_INPUTS_VAR_ONE",
        "kind": 5,
        "importPath": "tests.notebook.tet_input_utils",
        "description": "tests.notebook.tet_input_utils",
        "peekOfCode": "_MULTI_INPUTS_VAR_ONE = {\"a\": [\"apple\"], \"b\": [\"banana\"]}\n_MULTI_INPUTS_VAR_TWO = {\"a\": [\"australia\", \"alpha\"], \"b\": [\"brazil\", \"beta\"]}\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass InputUtilsTest(absltest.TestCase):\n    def test_get_inputs_source_from_py_var_invalid_name(self):\n        with self.assertRaisesRegex(NameError, \"UnknownVar\"):\n            input_utils.get_inputs_source_from_py_var(\"UnknownVar\")\n    def test_get_inputs_source_from_py_var_empty_one(self):\n        source = input_utils.get_inputs_source_from_py_var(\"_EMPTY_INPUT_VAR_ONE\")",
        "detail": "tests.notebook.tet_input_utils",
        "documentation": {}
    },
    {
        "label": "_MULTI_INPUTS_VAR_TWO",
        "kind": 5,
        "importPath": "tests.notebook.tet_input_utils",
        "description": "tests.notebook.tet_input_utils",
        "peekOfCode": "_MULTI_INPUTS_VAR_TWO = {\"a\": [\"australia\", \"alpha\"], \"b\": [\"brazil\", \"beta\"]}\n# `unittest discover` does not run via __main__, so patch this context in.\n@mock.patch.dict(sys.modules, {\"__main__\": sys.modules[__name__]})\nclass InputUtilsTest(absltest.TestCase):\n    def test_get_inputs_source_from_py_var_invalid_name(self):\n        with self.assertRaisesRegex(NameError, \"UnknownVar\"):\n            input_utils.get_inputs_source_from_py_var(\"UnknownVar\")\n    def test_get_inputs_source_from_py_var_empty_one(self):\n        source = input_utils.get_inputs_source_from_py_var(\"_EMPTY_INPUT_VAR_ONE\")\n        results = source.to_normalized_inputs()",
        "detail": "tests.notebook.tet_input_utils",
        "documentation": {}
    },
    {
        "label": "TestModel",
        "kind": 6,
        "importPath": "tests.notebook.text_model_test",
        "description": "tests.notebook.text_model_test",
        "peekOfCode": "class TestModel(text_model.TextModel):\n    \"\"\"A TextModel, but with _generate_text stubbed out.\"\"\"\n    def _generate_text(\n        self,\n        prompt: str,\n        model: str | None = None,\n        temperature: float | None = None,\n        candidate_count: int | None = None,\n        **kwargs,\n    ) -> generation_types.GenerateContentResponse:",
        "detail": "tests.notebook.text_model_test",
        "documentation": {}
    },
    {
        "label": "TextModelTestCase",
        "kind": 6,
        "importPath": "tests.notebook.text_model_test",
        "description": "tests.notebook.text_model_test",
        "peekOfCode": "class TextModelTestCase(absltest.TestCase):\n    def test_generate_text_without_args(self):\n        model = TestModel()\n        result = model.call_model(\"prompt goes in\")\n        self.assertEqual(result.text_results[0], \"prompt goes in_1\")\n    def test_generate_text_without_args_none_results(self):\n        model = TestModel()\n        result = model.call_model(\"prompt goes in\")\n        self.assertEqual(result.text_results[1], \"None\")\n        self.assertEqual(result.text_results[2], \"None\")",
        "detail": "tests.notebook.text_model_test",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_answer",
        "description": "tests.test_answer",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"generative\"] = self.client\n        client._client_manager.clients[\"model\"] = self.client\n        self.observed_requests = []\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)\n            return f",
        "detail": "tests.test_answer",
        "documentation": {}
    },
    {
        "label": "DEFAULT_ANSWER_MODEL",
        "kind": 5,
        "importPath": "tests.test_answer",
        "description": "tests.test_answer",
        "peekOfCode": "DEFAULT_ANSWER_MODEL = \"models/aqa\"\nclass UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"generative\"] = self.client\n        client._client_manager.clients[\"model\"] = self.client\n        self.observed_requests = []\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)",
        "detail": "tests.test_answer",
        "documentation": {}
    },
    {
        "label": "CodeMatch",
        "kind": 6,
        "importPath": "tests.test_async_code_match",
        "description": "tests.test_async_code_match",
        "peekOfCode": "class CodeMatch(absltest.TestCase):\n    def _maybe_trim_docstring(self, node):\n        if (\n            node.body\n            and isinstance(node.body[0], ast.Expr)\n            and isinstance(node.body[0].value, ast.Constant)\n        ):\n            node.body = node.body[1:]\n        return ast.unparse(node)\n    def _inspect_decorator_exemption(self, node, fpath) -> bool:",
        "detail": "tests.test_async_code_match",
        "documentation": {}
    },
    {
        "label": "EXEMPT_DIRS",
        "kind": 5,
        "importPath": "tests.test_async_code_match",
        "description": "tests.test_async_code_match",
        "peekOfCode": "EXEMPT_DIRS = [\"notebook\"]\nEXEMPT_DECORATORS = [\"overload\", \"property\", \"setter\", \"abstractmethod\", \"staticmethod\"]\nEXEMPT_FILES = [\"client.py\", \"version.py\", \"discuss.py\", \"files.py\"]\nEXEMPT_FUNCTIONS = [\"to_dict\", \"_to_proto\", \"to_proto\", \"from_proto\", \"from_dict\", \"_from_dict\"]\nclass CodeMatch(absltest.TestCase):\n    def _maybe_trim_docstring(self, node):\n        if (\n            node.body\n            and isinstance(node.body[0], ast.Expr)\n            and isinstance(node.body[0].value, ast.Constant)",
        "detail": "tests.test_async_code_match",
        "documentation": {}
    },
    {
        "label": "EXEMPT_DECORATORS",
        "kind": 5,
        "importPath": "tests.test_async_code_match",
        "description": "tests.test_async_code_match",
        "peekOfCode": "EXEMPT_DECORATORS = [\"overload\", \"property\", \"setter\", \"abstractmethod\", \"staticmethod\"]\nEXEMPT_FILES = [\"client.py\", \"version.py\", \"discuss.py\", \"files.py\"]\nEXEMPT_FUNCTIONS = [\"to_dict\", \"_to_proto\", \"to_proto\", \"from_proto\", \"from_dict\", \"_from_dict\"]\nclass CodeMatch(absltest.TestCase):\n    def _maybe_trim_docstring(self, node):\n        if (\n            node.body\n            and isinstance(node.body[0], ast.Expr)\n            and isinstance(node.body[0].value, ast.Constant)\n        ):",
        "detail": "tests.test_async_code_match",
        "documentation": {}
    },
    {
        "label": "EXEMPT_FILES",
        "kind": 5,
        "importPath": "tests.test_async_code_match",
        "description": "tests.test_async_code_match",
        "peekOfCode": "EXEMPT_FILES = [\"client.py\", \"version.py\", \"discuss.py\", \"files.py\"]\nEXEMPT_FUNCTIONS = [\"to_dict\", \"_to_proto\", \"to_proto\", \"from_proto\", \"from_dict\", \"_from_dict\"]\nclass CodeMatch(absltest.TestCase):\n    def _maybe_trim_docstring(self, node):\n        if (\n            node.body\n            and isinstance(node.body[0], ast.Expr)\n            and isinstance(node.body[0].value, ast.Constant)\n        ):\n            node.body = node.body[1:]",
        "detail": "tests.test_async_code_match",
        "documentation": {}
    },
    {
        "label": "EXEMPT_FUNCTIONS",
        "kind": 5,
        "importPath": "tests.test_async_code_match",
        "description": "tests.test_async_code_match",
        "peekOfCode": "EXEMPT_FUNCTIONS = [\"to_dict\", \"_to_proto\", \"to_proto\", \"from_proto\", \"from_dict\", \"_from_dict\"]\nclass CodeMatch(absltest.TestCase):\n    def _maybe_trim_docstring(self, node):\n        if (\n            node.body\n            and isinstance(node.body[0], ast.Expr)\n            and isinstance(node.body[0].value, ast.Constant)\n        ):\n            node.body = node.body[1:]\n        return ast.unparse(node)",
        "detail": "tests.test_async_code_match",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_caching",
        "description": "tests.test_caching",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"cache\"] = self.client\n        self.observed_requests = []\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)\n            return f\n        @add_client_method",
        "detail": "tests.test_caching",
        "documentation": {}
    },
    {
        "label": "ClientTests",
        "kind": 6,
        "importPath": "tests.test_client",
        "description": "tests.test_client",
        "peekOfCode": "class ClientTests(parameterized.TestCase):\n    def setUp(self):\n        super().setUp()\n        client._client_manager = client._ClientManager()\n    def test_api_key_passed_directly(self):\n        client.configure(api_key=\"AIzA_direct\")\n        client_opts = client._client_manager.client_config[\"client_options\"]\n        self.assertEqual(client_opts.api_key, \"AIzA_direct\")\n    def test_api_key_passed_via_client_options(self):\n        client_opts = client_options.ClientOptions(api_key=\"AIzA_client_opts\")",
        "detail": "tests.test_client",
        "documentation": {}
    },
    {
        "label": "ATypedDict",
        "kind": 6,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "class ATypedDict(typing_extensions.TypedDict):\n    a: int\n@dataclasses.dataclass\nclass ADataClass:\n    a: int\n@dataclasses.dataclass\nclass Nested:\n    x: ADataClass\n@dataclasses.dataclass\nclass ADataClassWithNullable:",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "ADataClass",
        "kind": 6,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "class ADataClass:\n    a: int\n@dataclasses.dataclass\nclass Nested:\n    x: ADataClass\n@dataclasses.dataclass\nclass ADataClassWithNullable:\n    a: Union[int, None]\n@dataclasses.dataclass\nclass ADataClassWithList:",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "Nested",
        "kind": 6,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "class Nested:\n    x: ADataClass\n@dataclasses.dataclass\nclass ADataClassWithNullable:\n    a: Union[int, None]\n@dataclasses.dataclass\nclass ADataClassWithList:\n    a: list[int]\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "ADataClassWithNullable",
        "kind": 6,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "class ADataClassWithNullable:\n    a: Union[int, None]\n@dataclasses.dataclass\nclass ADataClassWithList:\n    a: list[int]\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\"PIL\", PIL.Image.open(TEST_PNG_PATH)],\n        [\"RGBA\", PIL.Image.fromarray(np.zeros([6, 6, 4], dtype=np.uint8))],\n        [\"IPython\", IPython.display.Image(filename=TEST_PNG_PATH)],",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "ADataClassWithList",
        "kind": 6,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "class ADataClassWithList:\n    a: list[int]\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\"PIL\", PIL.Image.open(TEST_PNG_PATH)],\n        [\"RGBA\", PIL.Image.fromarray(np.zeros([6, 6, 4], dtype=np.uint8))],\n        [\"IPython\", IPython.display.Image(filename=TEST_PNG_PATH)],\n    )\n    def test_png_to_blob(self, image):\n        blob = content_types.image_to_blob(image)",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\"PIL\", PIL.Image.open(TEST_PNG_PATH)],\n        [\"RGBA\", PIL.Image.fromarray(np.zeros([6, 6, 4], dtype=np.uint8))],\n        [\"IPython\", IPython.display.Image(filename=TEST_PNG_PATH)],\n    )\n    def test_png_to_blob(self, image):\n        blob = content_types.image_to_blob(image)\n        self.assertIsInstance(blob, protos.Blob)\n        self.assertEqual(blob.mime_type, \"image/png\")",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 2,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "def datetime():\n    \"Returns the current UTC date and time.\"\nclass ATypedDict(typing_extensions.TypedDict):\n    a: int\n@dataclasses.dataclass\nclass ADataClass:\n    a: int\n@dataclasses.dataclass\nclass Nested:\n    x: ADataClass",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "HERE",
        "kind": 5,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "HERE = pathlib.Path(__file__).parent\nTEST_PNG_PATH = HERE / \"test_img.png\"\nTEST_PNG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.png\"\nTEST_PNG_DATA = TEST_PNG_PATH.read_bytes()\nTEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "TEST_PNG_PATH",
        "kind": 5,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "TEST_PNG_PATH = HERE / \"test_img.png\"\nTEST_PNG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.png\"\nTEST_PNG_DATA = TEST_PNG_PATH.read_bytes()\nTEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass ATypedDict(typing_extensions.TypedDict):",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "TEST_PNG_URL",
        "kind": 5,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "TEST_PNG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.png\"\nTEST_PNG_DATA = TEST_PNG_PATH.read_bytes()\nTEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass ATypedDict(typing_extensions.TypedDict):\n    a: int",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "TEST_PNG_DATA",
        "kind": 5,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "TEST_PNG_DATA = TEST_PNG_PATH.read_bytes()\nTEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass ATypedDict(typing_extensions.TypedDict):\n    a: int\n@dataclasses.dataclass",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "TEST_JPG_PATH",
        "kind": 5,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "TEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass ATypedDict(typing_extensions.TypedDict):\n    a: int\n@dataclasses.dataclass\nclass ADataClass:",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "TEST_JPG_URL",
        "kind": 5,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "TEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass ATypedDict(typing_extensions.TypedDict):\n    a: int\n@dataclasses.dataclass\nclass ADataClass:\n    a: int",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "TEST_JPG_DATA",
        "kind": 5,
        "importPath": "tests.test_content",
        "description": "tests.test_content",
        "peekOfCode": "TEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass ATypedDict(typing_extensions.TypedDict):\n    a: int\n@dataclasses.dataclass\nclass ADataClass:\n    a: int\n@dataclasses.dataclass",
        "detail": "tests.test_content",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_discuss",
        "description": "tests.test_discuss",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"discuss\"] = self.client\n        self.observed_request = None\n        self.mock_response = protos.GenerateMessageResponse(\n            candidates=[\n                protos.Message(content=\"a\", author=\"1\"),\n                protos.Message(content=\"b\", author=\"1\"),\n                protos.Message(content=\"c\", author=\"1\"),",
        "detail": "tests.test_discuss",
        "documentation": {}
    },
    {
        "label": "AsyncTests",
        "kind": 6,
        "importPath": "tests.test_discuss_async",
        "description": "tests.test_discuss_async",
        "peekOfCode": "class AsyncTests(parameterized.TestCase, unittest.IsolatedAsyncioTestCase):\n    async def test_chat_async(self):\n        client = unittest.mock.AsyncMock()\n        observed_request = None\n        async def fake_generate_message(\n            request: protos.GenerateMessageRequest,\n            **kwargs,\n        ) -> protos.GenerateMessageResponse:\n            nonlocal observed_request\n            observed_request = request",
        "detail": "tests.test_discuss_async",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_embedding",
        "description": "tests.test_embedding",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"generative\"] = self.client\n        client._client_manager.clients[\"model\"] = self.client\n        self.observed_requests = []\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)\n            return f",
        "detail": "tests.test_embedding",
        "documentation": {}
    },
    {
        "label": "DEFAULT_EMB_MODEL",
        "kind": 5,
        "importPath": "tests.test_embedding",
        "description": "tests.test_embedding",
        "peekOfCode": "DEFAULT_EMB_MODEL = \"models/embedding-001\"\nclass UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"generative\"] = self.client\n        client._client_manager.clients[\"model\"] = self.client\n        self.observed_requests = []\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)",
        "detail": "tests.test_embedding",
        "documentation": {}
    },
    {
        "label": "AsyncTests",
        "kind": 6,
        "importPath": "tests.test_embedding_async",
        "description": "tests.test_embedding_async",
        "peekOfCode": "class AsyncTests(parameterized.TestCase, unittest.IsolatedAsyncioTestCase):\n    def setUp(self):\n        self.client = unittest.mock.AsyncMock()\n        client_lib._client_manager.clients[\"generative_async\"] = self.client\n        self.observed_requests = []\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)\n            return f\n        @add_client_method",
        "detail": "tests.test_embedding_async",
        "documentation": {}
    },
    {
        "label": "DEFAULT_EMB_MODEL",
        "kind": 5,
        "importPath": "tests.test_embedding_async",
        "description": "tests.test_embedding_async",
        "peekOfCode": "DEFAULT_EMB_MODEL = \"models/embedding-001\"\nclass AsyncTests(parameterized.TestCase, unittest.IsolatedAsyncioTestCase):\n    def setUp(self):\n        self.client = unittest.mock.AsyncMock()\n        client_lib._client_manager.clients[\"generative_async\"] = self.client\n        self.observed_requests = []\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)\n            return f",
        "detail": "tests.test_embedding_async",
        "documentation": {}
    },
    {
        "label": "FileServiceClient",
        "kind": 6,
        "importPath": "tests.test_files",
        "description": "tests.test_files",
        "peekOfCode": "class FileServiceClient(client_lib.FileServiceClient):\n    def __init__(self, test):\n        self.test = test\n        self.observed_requests = []\n        self.responses = collections.defaultdict(list)\n    def create_file(\n        self,\n        path: Union[str, pathlib.Path, os.PathLike],\n        *,\n        mime_type: Union[str, None] = None,",
        "detail": "tests.test_files",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_files",
        "description": "tests.test_files",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = FileServiceClient(self)\n        client_lib._client_manager.clients[\"file\"] = self.client\n    @property\n    def observed_requests(self):\n        return self.client.observed_requests\n    @property\n    def responses(self):\n        return self.client.responses",
        "detail": "tests.test_files",
        "documentation": {}
    },
    {
        "label": "Date",
        "kind": 6,
        "importPath": "tests.test_generation",
        "description": "tests.test_generation",
        "peekOfCode": "class Date(TypedDict):\n    day: int\n    month: int\n    year: int\nclass Person(TypedDict):\n    name: str\n    favorite_color: str\n    birthday: Date\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(",
        "detail": "tests.test_generation",
        "documentation": {}
    },
    {
        "label": "Person",
        "kind": 6,
        "importPath": "tests.test_generation",
        "description": "tests.test_generation",
        "peekOfCode": "class Person(TypedDict):\n    name: str\n    favorite_color: str\n    birthday: Date\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\n            \"protos.GenerationConfig\",\n            protos.GenerationConfig(\n                temperature=0.1,",
        "detail": "tests.test_generation",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_generation",
        "description": "tests.test_generation",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\n            \"protos.GenerationConfig\",\n            protos.GenerationConfig(\n                temperature=0.1,\n                stop_sequences=[\"end\"],\n                response_schema=protos.Schema(type=\"STRING\"),\n            ),\n        ],",
        "detail": "tests.test_generation",
        "documentation": {}
    },
    {
        "label": "MockGenerativeServiceClient",
        "kind": 6,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "class MockGenerativeServiceClient:\n    def __init__(self, test):\n        self.test = test\n        self.observed_requests = []\n        self.observed_kwargs = []\n        self.responses = collections.defaultdict(list)\n    def generate_content(\n        self,\n        request: protos.GenerateContentRequest,\n        **kwargs,",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "CUJTests",
        "kind": 6,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "class CUJTests(parameterized.TestCase):\n    \"\"\"Tests are in order with the design doc.\"\"\"\n    @property\n    def observed_requests(self):\n        return self.client.observed_requests\n    @property\n    def observed_kwargs(self):\n        return self.client.observed_kwargs\n    @property\n    def responses(self):",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "simple_part",
        "kind": 2,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "def simple_part(text: str) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": text}]})\ndef noop(x: int):\n    return x\ndef iter_part(texts: Iterable[str]) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": t} for t in texts]})\ndef simple_response(text: str) -> protos.GenerateContentResponse:\n    return protos.GenerateContentResponse({\"candidates\": [{\"content\": simple_part(text)}]})\nclass MockGenerativeServiceClient:\n    def __init__(self, test):",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "noop",
        "kind": 2,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "def noop(x: int):\n    return x\ndef iter_part(texts: Iterable[str]) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": t} for t in texts]})\ndef simple_response(text: str) -> protos.GenerateContentResponse:\n    return protos.GenerateContentResponse({\"candidates\": [{\"content\": simple_part(text)}]})\nclass MockGenerativeServiceClient:\n    def __init__(self, test):\n        self.test = test\n        self.observed_requests = []",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "iter_part",
        "kind": 2,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "def iter_part(texts: Iterable[str]) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": t} for t in texts]})\ndef simple_response(text: str) -> protos.GenerateContentResponse:\n    return protos.GenerateContentResponse({\"candidates\": [{\"content\": simple_part(text)}]})\nclass MockGenerativeServiceClient:\n    def __init__(self, test):\n        self.test = test\n        self.observed_requests = []\n        self.observed_kwargs = []\n        self.responses = collections.defaultdict(list)",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "simple_response",
        "kind": 2,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "def simple_response(text: str) -> protos.GenerateContentResponse:\n    return protos.GenerateContentResponse({\"candidates\": [{\"content\": simple_part(text)}]})\nclass MockGenerativeServiceClient:\n    def __init__(self, test):\n        self.test = test\n        self.observed_requests = []\n        self.observed_kwargs = []\n        self.responses = collections.defaultdict(list)\n    def generate_content(\n        self,",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "HERE",
        "kind": 5,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "HERE = pathlib.Path(__file__).parent\nTEST_IMAGE_PATH = HERE / \"test_img.png\"\nTEST_IMAGE_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.png\"\nTEST_IMAGE_DATA = TEST_IMAGE_PATH.read_bytes()\ndef simple_part(text: str) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": text}]})\ndef noop(x: int):\n    return x\ndef iter_part(texts: Iterable[str]) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": t} for t in texts]})",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "TEST_IMAGE_PATH",
        "kind": 5,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "TEST_IMAGE_PATH = HERE / \"test_img.png\"\nTEST_IMAGE_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.png\"\nTEST_IMAGE_DATA = TEST_IMAGE_PATH.read_bytes()\ndef simple_part(text: str) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": text}]})\ndef noop(x: int):\n    return x\ndef iter_part(texts: Iterable[str]) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": t} for t in texts]})\ndef simple_response(text: str) -> protos.GenerateContentResponse:",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "TEST_IMAGE_URL",
        "kind": 5,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "TEST_IMAGE_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.png\"\nTEST_IMAGE_DATA = TEST_IMAGE_PATH.read_bytes()\ndef simple_part(text: str) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": text}]})\ndef noop(x: int):\n    return x\ndef iter_part(texts: Iterable[str]) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": t} for t in texts]})\ndef simple_response(text: str) -> protos.GenerateContentResponse:\n    return protos.GenerateContentResponse({\"candidates\": [{\"content\": simple_part(text)}]})",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "TEST_IMAGE_DATA",
        "kind": 5,
        "importPath": "tests.test_generative_models",
        "description": "tests.test_generative_models",
        "peekOfCode": "TEST_IMAGE_DATA = TEST_IMAGE_PATH.read_bytes()\ndef simple_part(text: str) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": text}]})\ndef noop(x: int):\n    return x\ndef iter_part(texts: Iterable[str]) -> protos.Content:\n    return protos.Content({\"parts\": [{\"text\": t} for t in texts]})\ndef simple_response(text: str) -> protos.GenerateContentResponse:\n    return protos.GenerateContentResponse({\"candidates\": [{\"content\": simple_part(text)}]})\nclass MockGenerativeServiceClient:",
        "detail": "tests.test_generative_models",
        "documentation": {}
    },
    {
        "label": "AsyncTests",
        "kind": 6,
        "importPath": "tests.test_generative_models_async",
        "description": "tests.test_generative_models_async",
        "peekOfCode": "class AsyncTests(parameterized.TestCase, unittest.IsolatedAsyncioTestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client_lib._client_manager.clients[\"generative_async\"] = self.client\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)\n            return f\n        self.observed_requests = []\n        self.responses = collections.defaultdict(list)",
        "detail": "tests.test_generative_models_async",
        "documentation": {}
    },
    {
        "label": "simple_response",
        "kind": 2,
        "importPath": "tests.test_generative_models_async",
        "description": "tests.test_generative_models_async",
        "peekOfCode": "def simple_response(text: str) -> protos.GenerateContentResponse:\n    return protos.GenerateContentResponse(\n        {\"candidates\": [{\"content\": {\"parts\": [{\"text\": text}]}}]}\n    )\nclass AsyncTests(parameterized.TestCase, unittest.IsolatedAsyncioTestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client_lib._client_manager.clients[\"generative_async\"] = self.client\n        def add_client_method(f):\n            name = f.__name__",
        "detail": "tests.test_generative_models_async",
        "documentation": {}
    },
    {
        "label": "MockModelClient",
        "kind": 6,
        "importPath": "tests.test_helpers",
        "description": "tests.test_helpers",
        "peekOfCode": "class MockModelClient:\n    def __init__(self, test):\n        self.test = test\n    def get_model(\n        self,\n        request: Union[protos.GetModelRequest, None] = None,\n        *,\n        name=None,\n        timeout=None,\n        retry=None",
        "detail": "tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "HelperTests",
        "kind": 6,
        "importPath": "tests.test_helpers",
        "description": "tests.test_helpers",
        "peekOfCode": "class HelperTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = MockModelClient(self)\n        client._client_manager.clients[\"model\"] = self.client\n        self.observed_requests = []\n        self.observed_retry = []\n        self.observed_timeout = []\n        self.responses = collections.defaultdict(list)\n    @parameterized.named_parameters(\n        [\"None\", None, None, None],",
        "detail": "tests.test_helpers",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_models",
        "description": "tests.test_models",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"model\"] = self.client\n        # TODO(markdaoust): Check if typechecking works better if wee define this as a\n        #                   subclass of `glm.ModelServiceClient`, would pyi files for `glm`. help?\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)\n            return f",
        "detail": "tests.test_models",
        "documentation": {}
    },
    {
        "label": "HERE",
        "kind": 5,
        "importPath": "tests.test_models",
        "description": "tests.test_models",
        "peekOfCode": "HERE = pathlib.Path(__file__).parent\nclass UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"model\"] = self.client\n        # TODO(markdaoust): Check if typechecking works better if wee define this as a\n        #                   subclass of `glm.ModelServiceClient`, would pyi files for `glm`. help?\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)",
        "detail": "tests.test_models",
        "documentation": {}
    },
    {
        "label": "OperationsTests",
        "kind": 6,
        "importPath": "tests.test_operations",
        "description": "tests.test_operations",
        "peekOfCode": "class OperationsTests(parameterized.TestCase):\n    metadata_type = (\n        \"type.googleapis.com/google.ai.generativelanguage.v1beta.CreateTunedModelMetadata\"\n    )\n    result_type = \"type.googleapis.com/google.ai.generativelanguage.v1beta.TunedModel\"\n    def test_end_to_end(self):\n        name = \"my-model\"\n        # Operation is defined here: https://github.com/googleapis/googleapis/blob/master/google/longrunning/operations.proto#L128\n        # It uses `google.protobuf.Any` to encode the metadata and results\n        # `Any` takes a type name and a serialized proto.",
        "detail": "tests.test_operations",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_permission",
        "description": "tests.test_permission",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"retriever\"] = self.client\n        client._client_manager.clients[\"permission\"] = self.client\n        client._client_manager.clients[\"model\"] = self.client\n        self.observed_requests = []\n        self.responses = {}\n        def add_client_method(f):\n            name = f.__name__",
        "detail": "tests.test_permission",
        "documentation": {}
    },
    {
        "label": "AsyncTests",
        "kind": 6,
        "importPath": "tests.test_permission_async",
        "description": "tests.test_permission_async",
        "peekOfCode": "class AsyncTests(parameterized.TestCase, unittest.IsolatedAsyncioTestCase):\n    def setUp(self):\n        self.client = unittest.mock.AsyncMock()\n        client._client_manager.clients[\"retriever_async\"] = self.client\n        client._client_manager.clients[\"permission_async\"] = self.client\n        client._client_manager.clients[\"model\"] = self.client\n        self.observed_requests = []\n        self.responses = {}\n        def add_client_method(f):\n            name = f.__name__",
        "detail": "tests.test_permission_async",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_protos",
        "description": "tests.test_protos",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def test_check_glm_imports(self):\n        for fpath in ROOT.rglob(\"*.py\"):\n            if fpath.name == \"build_docs.py\":\n                continue\n            content = fpath.read_text()\n            for match in re.findall(\"glm\\.\\w+\", content):\n                self.assertIn(\n                    \"Client\",\n                    match,",
        "detail": "tests.test_protos",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "tests.test_protos",
        "description": "tests.test_protos",
        "peekOfCode": "ROOT = pathlib.Path(__file__).parent.parent\nclass UnitTests(parameterized.TestCase):\n    def test_check_glm_imports(self):\n        for fpath in ROOT.rglob(\"*.py\"):\n            if fpath.name == \"build_docs.py\":\n                continue\n            content = fpath.read_text()\n            for match in re.findall(\"glm\\.\\w+\", content):\n                self.assertIn(\n                    \"Client\",",
        "detail": "tests.test_protos",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_responder",
        "description": "tests.test_responder",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\n            \"FunctionLibrary\",\n            responder.FunctionLibrary(\n                tools=protos.Tool(\n                    function_declarations=[\n                        protos.FunctionDeclaration(\n                            name=\"datetime\", description=\"Returns the current UTC date and time.\"\n                        )",
        "detail": "tests.test_responder",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 2,
        "importPath": "tests.test_responder",
        "description": "tests.test_responder",
        "peekOfCode": "def datetime():\n    \"Returns the current UTC date and time.\"\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\n            \"FunctionLibrary\",\n            responder.FunctionLibrary(\n                tools=protos.Tool(\n                    function_declarations=[\n                        protos.FunctionDeclaration(",
        "detail": "tests.test_responder",
        "documentation": {}
    },
    {
        "label": "HERE",
        "kind": 5,
        "importPath": "tests.test_responder",
        "description": "tests.test_responder",
        "peekOfCode": "HERE = pathlib.Path(__file__).parent\nTEST_PNG_PATH = HERE / \"test_img.png\"\nTEST_PNG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.png\"\nTEST_PNG_DATA = TEST_PNG_PATH.read_bytes()\nTEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"",
        "detail": "tests.test_responder",
        "documentation": {}
    },
    {
        "label": "TEST_PNG_PATH",
        "kind": 5,
        "importPath": "tests.test_responder",
        "description": "tests.test_responder",
        "peekOfCode": "TEST_PNG_PATH = HERE / \"test_img.png\"\nTEST_PNG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.png\"\nTEST_PNG_DATA = TEST_PNG_PATH.read_bytes()\nTEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass UnitTests(parameterized.TestCase):",
        "detail": "tests.test_responder",
        "documentation": {}
    },
    {
        "label": "TEST_PNG_URL",
        "kind": 5,
        "importPath": "tests.test_responder",
        "description": "tests.test_responder",
        "peekOfCode": "TEST_PNG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.png\"\nTEST_PNG_DATA = TEST_PNG_PATH.read_bytes()\nTEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(",
        "detail": "tests.test_responder",
        "documentation": {}
    },
    {
        "label": "TEST_PNG_DATA",
        "kind": 5,
        "importPath": "tests.test_responder",
        "description": "tests.test_responder",
        "peekOfCode": "TEST_PNG_DATA = TEST_PNG_PATH.read_bytes()\nTEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [",
        "detail": "tests.test_responder",
        "documentation": {}
    },
    {
        "label": "TEST_JPG_PATH",
        "kind": 5,
        "importPath": "tests.test_responder",
        "description": "tests.test_responder",
        "peekOfCode": "TEST_JPG_PATH = HERE / \"test_img.jpg\"\nTEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\n            \"FunctionLibrary\",",
        "detail": "tests.test_responder",
        "documentation": {}
    },
    {
        "label": "TEST_JPG_URL",
        "kind": 5,
        "importPath": "tests.test_responder",
        "description": "tests.test_responder",
        "peekOfCode": "TEST_JPG_URL = \"https://storage.googleapis.com/generativeai-downloads/data/test_img.jpg\"\nTEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\n            \"FunctionLibrary\",\n            responder.FunctionLibrary(",
        "detail": "tests.test_responder",
        "documentation": {}
    },
    {
        "label": "TEST_JPG_DATA",
        "kind": 5,
        "importPath": "tests.test_responder",
        "description": "tests.test_responder",
        "peekOfCode": "TEST_JPG_DATA = TEST_JPG_PATH.read_bytes()\n# simple test function\ndef datetime():\n    \"Returns the current UTC date and time.\"\nclass UnitTests(parameterized.TestCase):\n    @parameterized.named_parameters(\n        [\n            \"FunctionLibrary\",\n            responder.FunctionLibrary(\n                tools=protos.Tool(",
        "detail": "tests.test_responder",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_retriever",
        "description": "tests.test_retriever",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"retriever\"] = self.client\n        self.observed_requests = []\n        self.responses = {}\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)\n            return f",
        "detail": "tests.test_retriever",
        "documentation": {}
    },
    {
        "label": "AsyncTests",
        "kind": 6,
        "importPath": "tests.test_retriever_async",
        "description": "tests.test_retriever_async",
        "peekOfCode": "class AsyncTests(parameterized.TestCase, unittest.IsolatedAsyncioTestCase):\n    def setUp(self):\n        self.client = unittest.mock.AsyncMock()\n        client_lib._client_manager.clients[\"retriever_async\"] = self.client\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)\n            return f\n        self.observed_requests = []\n        self.responses = collections.defaultdict(list)",
        "detail": "tests.test_retriever_async",
        "documentation": {}
    },
    {
        "label": "SafetyTests",
        "kind": 6,
        "importPath": "tests.test_safety",
        "description": "tests.test_safety",
        "peekOfCode": "class SafetyTests(parameterized.TestCase):\n    \"\"\"Tests are in order with the design doc.\"\"\"\n    @parameterized.named_parameters(\n        [\"block_threshold\", protos.SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE],\n        [\"block_threshold2\", \"medium\"],\n        [\"block_threshold3\", 2],\n        [\"dict\", {\"danger\": \"medium\"}],\n        [\"dict2\", {\"danger\": 2}],\n        [\"dict3\", {\"danger\": protos.SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE}],\n        [",
        "detail": "tests.test_safety",
        "documentation": {}
    },
    {
        "label": "MyClass",
        "kind": 6,
        "importPath": "tests.test_string_utils",
        "description": "tests.test_string_utils",
        "peekOfCode": "class MyClass:\n    a: int\n    b: float\n    c: list[int]\n    d: Any\nclass OperationsTests(parameterized.TestCase):\n    def test_simple(self):\n        m = MyClass(a=1, b=1 / 3, c=[0, 1, 2, 3, 4, 5], d={\"a\": 1, \"b\": 2})\n        result = str(m)\n        expected = textwrap.dedent(",
        "detail": "tests.test_string_utils",
        "documentation": {}
    },
    {
        "label": "OperationsTests",
        "kind": 6,
        "importPath": "tests.test_string_utils",
        "description": "tests.test_string_utils",
        "peekOfCode": "class OperationsTests(parameterized.TestCase):\n    def test_simple(self):\n        m = MyClass(a=1, b=1 / 3, c=[0, 1, 2, 3, 4, 5], d={\"a\": 1, \"b\": 2})\n        result = str(m)\n        expected = textwrap.dedent(\n            \"\"\"\n            MyClass(a=1,\n                    b=0.3333333333333333,\n                    c=[0, 1, 2, 3, 4, 5],\n                    d={'a': 1, 'b': 2})\"\"\"",
        "detail": "tests.test_string_utils",
        "documentation": {}
    },
    {
        "label": "UnitTests",
        "kind": 6,
        "importPath": "tests.test_text",
        "description": "tests.test_text",
        "peekOfCode": "class UnitTests(parameterized.TestCase):\n    def setUp(self):\n        self.client = unittest.mock.MagicMock()\n        client._client_manager.clients[\"text\"] = self.client\n        client._client_manager.clients[\"model\"] = self.client\n        self.observed_requests = []\n        self.responses = {}\n        def add_client_method(f):\n            name = f.__name__\n            setattr(self.client, name, f)",
        "detail": "tests.test_text",
        "documentation": {}
    },
    {
        "label": "TypingExtensionsTests",
        "kind": 6,
        "importPath": "tests.test_typing_extensions",
        "description": "tests.test_typing_extensions",
        "peekOfCode": "class TypingExtensionsTests(absltest.TestCase):\n    \"\"\"Pydantic users need the improved version of TypedDict, from typing_extensions.\n    This is only required for python versions <3.12. Once 3.12 is the lowest supported version we can drop this.\n    ref: https://docs.pydantic.dev/2.3/usage/types/dicts_mapping/\n    > the typing-extensions package is required for Python <3.12\n    \"\"\"\n    def test_no_typing_typed_dict(self):\n        root = pathlib.Path(__file__).parent.parent\n        for fpath in (root / \"google\").rglob(\"*.py\"):\n            source = fpath.read_text()",
        "detail": "tests.test_typing_extensions",
        "documentation": {}
    },
    {
        "label": "TYPING_RE",
        "kind": 5,
        "importPath": "tests.test_typing_extensions",
        "description": "tests.test_typing_extensions",
        "peekOfCode": "TYPING_RE = re.compile(r\"\\btyping\\b.*TypedDict\")\nclass TypingExtensionsTests(absltest.TestCase):\n    \"\"\"Pydantic users need the improved version of TypedDict, from typing_extensions.\n    This is only required for python versions <3.12. Once 3.12 is the lowest supported version we can drop this.\n    ref: https://docs.pydantic.dev/2.3/usage/types/dicts_mapping/\n    > the typing-extensions package is required for Python <3.12\n    \"\"\"\n    def test_no_typing_typed_dict(self):\n        root = pathlib.Path(__file__).parent.parent\n        for fpath in (root / \"google\").rglob(\"*.py\"):",
        "detail": "tests.test_typing_extensions",
        "documentation": {}
    },
    {
        "label": "get_version",
        "kind": 2,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "def get_version():\n    version = {}\n    version_source = (package_root / \"google/generativeai/version.py\").read_text()\n    exec(version_source, version)\n    version = version[\"__version__\"]\n    return version\nversion = get_version()\nif version[0] == \"0\":\n    release_status = \"Development Status :: 4 - Beta\"\nelse:",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "package_root",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "package_root = pathlib.Path(__file__).parent.resolve()\nname = \"google-generativeai\"\ndescription = \"Google Generative AI High level API client library and tools.\"\ndef get_version():\n    version = {}\n    version_source = (package_root / \"google/generativeai/version.py\").read_text()\n    exec(version_source, version)\n    version = version[\"__version__\"]\n    return version\nversion = get_version()",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "name",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "name = \"google-generativeai\"\ndescription = \"Google Generative AI High level API client library and tools.\"\ndef get_version():\n    version = {}\n    version_source = (package_root / \"google/generativeai/version.py\").read_text()\n    exec(version_source, version)\n    version = version[\"__version__\"]\n    return version\nversion = get_version()\nif version[0] == \"0\":",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "description",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "description = \"Google Generative AI High level API client library and tools.\"\ndef get_version():\n    version = {}\n    version_source = (package_root / \"google/generativeai/version.py\").read_text()\n    exec(version_source, version)\n    version = version[\"__version__\"]\n    return version\nversion = get_version()\nif version[0] == \"0\":\n    release_status = \"Development Status :: 4 - Beta\"",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "version = get_version()\nif version[0] == \"0\":\n    release_status = \"Development Status :: 4 - Beta\"\nelse:\n    release_status = \"Development Status :: 5 - Production/Stable\"\ndependencies = [\n    \"google-ai-generativelanguage==0.6.5\",\n    \"google-api-core\",\n    \"google-api-python-client\",\n    \"google-auth>=2.15.0\",  # 2.15 adds API key auth support",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "dependencies",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "dependencies = [\n    \"google-ai-generativelanguage==0.6.5\",\n    \"google-api-core\",\n    \"google-api-python-client\",\n    \"google-auth>=2.15.0\",  # 2.15 adds API key auth support\n    \"protobuf\",\n    \"pydantic\",\n    \"tqdm\",\n    \"typing-extensions\",\n]",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "extras_require",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "extras_require = {\n    \"dev\": [\"absl-py\", \"black\", \"nose2\", \"pandas\", \"pytype\", \"pyyaml\", \"Pillow\", \"ipython\"],\n}\nurl = \"https://github.com/google/generative-ai-python\"\nreadme = (package_root / \"README.md\").read_text()\npackages = [\n    package for package in setuptools.PEP420PackageFinder.find() if package.startswith(\"google\")\n]\nnamespaces = [\"google\"]\nsetuptools.setup(",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "url = \"https://github.com/google/generative-ai-python\"\nreadme = (package_root / \"README.md\").read_text()\npackages = [\n    package for package in setuptools.PEP420PackageFinder.find() if package.startswith(\"google\")\n]\nnamespaces = [\"google\"]\nsetuptools.setup(\n    name=name,\n    version=version,\n    description=description,",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "readme",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "readme = (package_root / \"README.md\").read_text()\npackages = [\n    package for package in setuptools.PEP420PackageFinder.find() if package.startswith(\"google\")\n]\nnamespaces = [\"google\"]\nsetuptools.setup(\n    name=name,\n    version=version,\n    description=description,\n    long_description=readme,",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "packages",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "packages = [\n    package for package in setuptools.PEP420PackageFinder.find() if package.startswith(\"google\")\n]\nnamespaces = [\"google\"]\nsetuptools.setup(\n    name=name,\n    version=version,\n    description=description,\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "namespaces",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "namespaces = [\"google\"]\nsetuptools.setup(\n    name=name,\n    version=version,\n    description=description,\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    author=\"Google LLC\",\n    author_email=\"googleapis-packages@google.com\",\n    license=\"Apache 2.0\",",
        "detail": "setup",
        "documentation": {}
    }
]